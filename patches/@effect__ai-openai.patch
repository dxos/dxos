diff --git a/dist/cjs/OpenAiClient.js b/dist/cjs/OpenAiClient.js
index 793e00f18e5b3c33dc7460b5aaa27f3e0e3a2fbb..93be21fe390bda2f642927758d4fe1caccb8cfa3 100644
--- a/dist/cjs/OpenAiClient.js
+++ b/dist/cjs/OpenAiClient.js
@@ -1,175 +1,253 @@
-"use strict";
+'use strict';
 
-Object.defineProperty(exports, "__esModule", {
-  value: true
+Object.defineProperty(exports, '__esModule', {
+  value: true,
 });
 exports.make = exports.layerConfig = exports.layer = exports.OpenAiClient = void 0;
-var AiResponse = _interopRequireWildcard(require("@effect/ai/AiResponse"));
-var Sse = _interopRequireWildcard(require("@effect/experimental/Sse"));
-var HttpBody = _interopRequireWildcard(require("@effect/platform/HttpBody"));
-var HttpClient = _interopRequireWildcard(require("@effect/platform/HttpClient"));
-var HttpClientRequest = _interopRequireWildcard(require("@effect/platform/HttpClientRequest"));
-var Config = _interopRequireWildcard(require("effect/Config"));
-var Context = _interopRequireWildcard(require("effect/Context"));
-var Effect = _interopRequireWildcard(require("effect/Effect"));
-var _Function = require("effect/Function");
-var Layer = _interopRequireWildcard(require("effect/Layer"));
-var Option = _interopRequireWildcard(require("effect/Option"));
-var Predicate = _interopRequireWildcard(require("effect/Predicate"));
-var Redacted = _interopRequireWildcard(require("effect/Redacted"));
-var Stream = _interopRequireWildcard(require("effect/Stream"));
-var Generated = _interopRequireWildcard(require("./Generated.js"));
-var InternalUtilities = _interopRequireWildcard(require("./internal/utilities.js"));
-var _OpenAiConfig = require("./OpenAiConfig.js");
-function _interopRequireWildcard(e, t) { if ("function" == typeof WeakMap) var r = new WeakMap(), n = new WeakMap(); return (_interopRequireWildcard = function (e, t) { if (!t && e && e.__esModule) return e; var o, i, f = { __proto__: null, default: e }; if (null === e || "object" != typeof e && "function" != typeof e) return f; if (o = t ? n : r) { if (o.has(e)) return o.get(e); o.set(e, f); } for (const t in e) "default" !== t && {}.hasOwnProperty.call(e, t) && ((i = (o = Object.defineProperty) && Object.getOwnPropertyDescriptor(e, t)) && (i.get || i.set) ? o(f, t, i) : f[t] = e[t]); return f; })(e, t); }
+var AiResponse = _interopRequireWildcard(require('@effect/ai/AiResponse'));
+var Sse = _interopRequireWildcard(require('@effect/experimental/Sse'));
+var HttpBody = _interopRequireWildcard(require('@effect/platform/HttpBody'));
+var HttpClient = _interopRequireWildcard(require('@effect/platform/HttpClient'));
+var HttpClientRequest = _interopRequireWildcard(require('@effect/platform/HttpClientRequest'));
+var Config = _interopRequireWildcard(require('effect/Config'));
+var Context = _interopRequireWildcard(require('effect/Context'));
+var Effect = _interopRequireWildcard(require('effect/Effect'));
+var _Function = require('effect/Function');
+var Layer = _interopRequireWildcard(require('effect/Layer'));
+var Option = _interopRequireWildcard(require('effect/Option'));
+var Predicate = _interopRequireWildcard(require('effect/Predicate'));
+var Redacted = _interopRequireWildcard(require('effect/Redacted'));
+var Stream = _interopRequireWildcard(require('effect/Stream'));
+var Generated = _interopRequireWildcard(require('./Generated.js'));
+var InternalUtilities = _interopRequireWildcard(require('./internal/utilities.js'));
+var _OpenAiConfig = require('./OpenAiConfig.js');
+function _interopRequireWildcard(e, t) {
+  if ('function' == typeof WeakMap)
+    var r = new WeakMap(),
+      n = new WeakMap();
+  return (_interopRequireWildcard = function (e, t) {
+    if (!t && e && e.__esModule) return e;
+    var o,
+      i,
+      f = { __proto__: null, default: e };
+    if (null === e || ('object' != typeof e && 'function' != typeof e)) return f;
+    if ((o = t ? n : r)) {
+      if (o.has(e)) return o.get(e);
+      o.set(e, f);
+    }
+    for (const t in e)
+      'default' !== t &&
+        {}.hasOwnProperty.call(e, t) &&
+        ((i = (o = Object.defineProperty) && Object.getOwnPropertyDescriptor(e, t)) && (i.get || i.set)
+          ? o(f, t, i)
+          : (f[t] = e[t]));
+    return f;
+  })(e, t);
+}
 const constDisableValidation = {
-  disableValidation: true
+  disableValidation: true,
 };
 /**
  * @since 1.0.0
  * @category Context
  */
-class OpenAiClient extends /*#__PURE__*/Context.Tag("@effect/ai-openai/OpenAiClient")() {}
+class OpenAiClient extends /*#__PURE__*/ Context.Tag('@effect/ai-openai/OpenAiClient')() {}
 /**
  * @since 1.0.0
  * @category Constructors
  */
 exports.OpenAiClient = OpenAiClient;
-const make = options => Effect.gen(function* () {
-  const httpClient = (yield* HttpClient.HttpClient).pipe(HttpClient.mapRequest(request => request.pipe(HttpClientRequest.prependUrl(options.apiUrl ?? "https://api.openai.com/v1"), options.apiKey ? HttpClientRequest.bearerToken(options.apiKey) : _Function.identity, options.organizationId !== undefined ? HttpClientRequest.setHeader("OpenAI-Organization", Redacted.value(options.organizationId)) : _Function.identity, options.projectId !== undefined ? HttpClientRequest.setHeader("OpenAI-Project", Redacted.value(options.projectId)) : _Function.identity, HttpClientRequest.acceptJson)), options.transformClient ? options.transformClient : _Function.identity);
-  const httpClientOk = HttpClient.filterStatusOk(httpClient);
-  const client = Generated.make(httpClient, {
-    transformClient: client => _OpenAiConfig.OpenAiConfig.getOrUndefined.pipe(Effect.map(config => config?.transformClient ? config.transformClient(client) : client))
-  });
-  const streamRequest = request => httpClientOk.execute(request).pipe(Effect.map(r => r.stream), Stream.unwrapScoped, Stream.decodeText(), Stream.pipeThroughChannel(Sse.makeChannel()), Stream.takeWhile(event => event.data !== "[DONE]"), Stream.map(event => JSON.parse(event.data)));
-  const stream = request => Stream.suspend(() => {
-    const toolCalls = {};
-    let isFirstChunk = false;
-    let toolCallIndex = undefined;
-    let finishReason = "unknown";
-    let usage = {
-      inputTokens: 0,
-      outputTokens: 0,
-      totalTokens: 0,
-      reasoningTokens: 0,
-      cacheReadInputTokens: 0,
-      cacheWriteInputTokens: 0
-    };
-    let metadata = {};
-    return streamRequest(HttpClientRequest.post("/chat/completions", {
-      body: HttpBody.unsafeJson({
-        ...request,
-        stream: true,
-        stream_options: {
-          include_usage: true
-        }
-      })
-    })).pipe(Stream.filterMap(chunk => {
-      const parts = [];
-      // Add response metadata immediately once available
-      if (isFirstChunk) {
-        isFirstChunk = false;
-        parts.push(new AiResponse.MetadataPart({
-          id: chunk.id,
-          model: chunk.model,
-          timestamp: new Date(chunk.created * 1000)
-        }, constDisableValidation));
-      }
-      // Track usage information
-      if (Predicate.isNotNullable(chunk.usage)) {
-        usage = {
-          inputTokens: chunk.usage.prompt_tokens,
-          outputTokens: chunk.usage.completion_tokens,
-          totalTokens: chunk.usage.prompt_tokens + chunk.usage.completion_tokens,
-          reasoningTokens: chunk.usage.completion_tokens_details.reasoning_tokens,
-          cacheReadInputTokens: chunk.usage.prompt_tokens_details.cached_tokens,
-          cacheWriteInputTokens: usage.cacheWriteInputTokens
-        };
-        metadata = {
-          ...metadata,
-          serviceTier: chunk.service_tier,
-          systemFingerprint: chunk.system_fingerprint,
-          acceptedPredictionTokens: chunk.usage.completion_tokens_details.accepted_prediction_tokens,
-          rejectedPredictionTokens: chunk.usage.completion_tokens_details.rejected_prediction_tokens,
-          inputAudioTokens: chunk.usage.prompt_tokens_details.audio_tokens,
-          outputAudioTokens: chunk.usage.completion_tokens_details.audio_tokens
+const make = (options) =>
+  Effect.gen(function* () {
+    const httpClient = (yield* HttpClient.HttpClient).pipe(
+      HttpClient.mapRequest((request) =>
+        request.pipe(
+          HttpClientRequest.prependUrl(options.apiUrl ?? 'https://api.openai.com/v1'),
+          options.apiKey ? HttpClientRequest.bearerToken(options.apiKey) : _Function.identity,
+          options.organizationId !== undefined
+            ? HttpClientRequest.setHeader('OpenAI-Organization', Redacted.value(options.organizationId))
+            : _Function.identity,
+          options.projectId !== undefined
+            ? HttpClientRequest.setHeader('OpenAI-Project', Redacted.value(options.projectId))
+            : _Function.identity,
+          HttpClientRequest.acceptJson,
+        ),
+      ),
+      options.transformClient ? options.transformClient : _Function.identity,
+    );
+    const httpClientOk = HttpClient.filterStatusOk(httpClient);
+    const client = Generated.make(httpClient, {
+      transformClient: (client) =>
+        _OpenAiConfig.OpenAiConfig.getOrUndefined.pipe(
+          Effect.map((config) => (config?.transformClient ? config.transformClient(client) : client)),
+        ),
+    });
+    const streamRequest = (request) =>
+      httpClientOk.execute(request).pipe(
+        Effect.map((r) => r.stream),
+        Stream.unwrapScoped,
+        Stream.decodeText(),
+        Stream.pipeThroughChannel(Sse.makeChannel()),
+        Stream.takeWhile((event) => event.data !== '[DONE]'),
+        Stream.map((event) => JSON.parse(event.data)),
+      );
+    const stream = (request) =>
+      Stream.suspend(() => {
+        const toolCalls = {};
+        let isFirstChunk = false;
+        let toolCallIndex = undefined;
+        let finishReason = 'unknown';
+        let usage = {
+          inputTokens: 0,
+          outputTokens: 0,
+          totalTokens: 0,
+          reasoningTokens: 0,
+          cacheReadInputTokens: 0,
+          cacheWriteInputTokens: 0,
         };
-      }
-      for (let i = 0; i < chunk.choices.length; i++) {
-        const choice = chunk.choices[i];
-        // Track the finish reason for the response
-        if (Predicate.isNotNullable(choice.finish_reason)) {
-          finishReason = InternalUtilities.resolveFinishReason(choice.finish_reason);
-          if (finishReason === "tool-calls" && Predicate.isNotUndefined(toolCallIndex)) {
-            finishToolCall(toolCalls[toolCallIndex], parts);
-          }
-          parts.push(new AiResponse.FinishPart({
-            usage,
-            reason: finishReason,
-            providerMetadata: {
-              [InternalUtilities.ProviderMetadataKey]: metadata
+        let metadata = {};
+        return streamRequest(
+          HttpClientRequest.post('/chat/completions', {
+            body: HttpBody.unsafeJson({
+              ...request,
+              stream: true,
+              stream_options: {
+                include_usage: true,
+              },
+            }),
+          }),
+        ).pipe(
+          Stream.filterMap((chunk) => {
+            const parts = [];
+            // Add response metadata immediately once available
+            if (isFirstChunk) {
+              isFirstChunk = false;
+              parts.push(
+                new AiResponse.MetadataPart(
+                  {
+                    id: chunk.id,
+                    model: chunk.model,
+                    timestamp: new Date(chunk.created * 1000),
+                  },
+                  constDisableValidation,
+                ),
+              );
             }
-          }, constDisableValidation));
-        }
-        // Handle text deltas
-        if (Predicate.isNotNullable(choice.delta.content)) {
-          parts.push(new AiResponse.TextPart({
-            text: choice.delta.content
-          }, constDisableValidation));
-        }
-        // Handle tool call deltas
-        if (Predicate.hasProperty(choice.delta, "tool_calls") && Array.isArray(choice.delta.tool_calls)) {
-          for (const delta of choice.delta.tool_calls) {
-            // Make sure to emit any previous tool calls before starting a new one
-            if (Predicate.isNotUndefined(toolCallIndex) && toolCallIndex !== delta.index) {
-              finishToolCall(toolCalls[toolCallIndex], parts);
-              toolCallIndex = undefined;
-            }
-            if (Predicate.isUndefined(toolCallIndex)) {
-              const toolCall = delta;
-              // All information except arguments are returned with the first tool call delta
-              toolCalls[delta.index] = {
-                ...toolCall,
-                isFinished: false
+            // Track usage information
+            if (Predicate.isNotNullable(chunk.usage)) {
+              usage = {
+                inputTokens: chunk.usage.prompt_tokens,
+                outputTokens: chunk.usage.completion_tokens,
+                totalTokens: chunk.usage.prompt_tokens + chunk.usage.completion_tokens,
+                reasoningTokens: chunk.usage.completion_tokens_details?.reasoning_tokens ?? 0,
+                cacheReadInputTokens: chunk.usage.prompt_tokens_details?.cached_tokens ?? 0,
+                cacheWriteInputTokens: usage.cacheWriteInputTokens,
+              };
+              metadata = {
+                ...metadata,
+                serviceTier: chunk.service_tier,
+                systemFingerprint: chunk.system_fingerprint,
+                acceptedPredictionTokens: chunk.usage.completion_tokens_details?.accepted_prediction_tokens ?? 0,
+                rejectedPredictionTokens: chunk.usage.completion_tokens_details?.rejected_prediction_tokens ?? 0,
+                inputAudioTokens: chunk.usage.prompt_tokens_details?.audio_tokens ?? 0,
+                outputAudioTokens: chunk.usage.completion_tokens_details?.audio_tokens ?? 0,
               };
-              toolCallIndex = delta.index;
-            } else {
-              toolCalls[delta.index].function.arguments += delta.function.arguments;
             }
-          }
-        }
-      }
-      return parts.length === 0 ? Option.none() : Option.some(AiResponse.AiResponse.make({
-        parts
-      }, constDisableValidation));
-    }));
-  });
-  return OpenAiClient.of({
-    client,
-    streamRequest,
-    stream
+            for (let i = 0; i < chunk.choices.length; i++) {
+              const choice = chunk.choices[i];
+              // Track the finish reason for the response
+              if (Predicate.isNotNullable(choice.finish_reason)) {
+                finishReason = InternalUtilities.resolveFinishReason(choice.finish_reason);
+                if (finishReason === 'tool-calls' && Predicate.isNotUndefined(toolCallIndex)) {
+                  finishToolCall(toolCalls[toolCallIndex], parts);
+                }
+                parts.push(
+                  new AiResponse.FinishPart(
+                    {
+                      usage,
+                      reason: finishReason,
+                      providerMetadata: {
+                        [InternalUtilities.ProviderMetadataKey]: metadata,
+                      },
+                    },
+                    constDisableValidation,
+                  ),
+                );
+              }
+              // Handle text deltas
+              if (Predicate.isNotNullable(choice.delta.content)) {
+                parts.push(
+                  new AiResponse.TextPart(
+                    {
+                      text: choice.delta.content,
+                    },
+                    constDisableValidation,
+                  ),
+                );
+              }
+              // Handle tool call deltas
+              if (Predicate.hasProperty(choice.delta, 'tool_calls') && Array.isArray(choice.delta.tool_calls)) {
+                for (const delta of choice.delta.tool_calls) {
+                  // Make sure to emit any previous tool calls before starting a new one
+                  if (Predicate.isNotUndefined(toolCallIndex) && toolCallIndex !== delta.index) {
+                    finishToolCall(toolCalls[toolCallIndex], parts);
+                    toolCallIndex = undefined;
+                  }
+                  if (Predicate.isUndefined(toolCallIndex)) {
+                    const toolCall = delta;
+                    // All information except arguments are returned with the first tool call delta
+                    toolCalls[delta.index] = {
+                      ...toolCall,
+                      isFinished: false,
+                    };
+                    toolCallIndex = delta.index;
+                  } else {
+                    toolCalls[delta.index].function.arguments += delta.function.arguments;
+                  }
+                }
+              }
+            }
+            return parts.length === 0
+              ? Option.none()
+              : Option.some(
+                  AiResponse.AiResponse.make(
+                    {
+                      parts,
+                    },
+                    constDisableValidation,
+                  ),
+                );
+          }),
+        );
+      });
+    return OpenAiClient.of({
+      client,
+      streamRequest,
+      stream,
+    });
   });
-});
 /**
  * @since 1.0.0
  * @category Layers
  */
 exports.make = make;
-const layer = options => Layer.effect(OpenAiClient, make(options));
+const layer = (options) => Layer.effect(OpenAiClient, make(options));
 /**
  * @since 1.0.0
  * @category Layers
  */
 exports.layer = layer;
-const layerConfig = options => {
-  const {
-    transformClient,
-    ...configs
-  } = options;
-  return Config.all(configs).pipe(Effect.flatMap(configs => make({
-    ...configs,
-    transformClient
-  })), Layer.effect(OpenAiClient));
+const layerConfig = (options) => {
+  const { transformClient, ...configs } = options;
+  return Config.all(configs).pipe(
+    Effect.flatMap((configs) =>
+      make({
+        ...configs,
+        transformClient,
+      }),
+    ),
+    Layer.effect(OpenAiClient),
+  );
 };
 // =============================================================================
 // Utilities
@@ -182,11 +260,13 @@ const finishToolCall = (toolCall, parts) => {
   }
   try {
     const params = JSON.parse(toolCall.function.arguments);
-    parts.push(new AiResponse.ToolCallPart({
-      id: toolCall.id,
-      name: toolCall.function.name,
-      params
-    }));
+    parts.push(
+      new AiResponse.ToolCallPart({
+        id: toolCall.id,
+        name: toolCall.function.name,
+        params,
+      }),
+    );
     toolCall.isFinished = true;
     // TODO:
     // eslint-disable-next-line no-empty
diff --git a/dist/esm/OpenAiClient.js b/dist/esm/OpenAiClient.js
index 778289f2f958024640ad5121bee7376bc1ede369..51bb0db6442aa3b9885bdf118140ed6529bcf708 100644
--- a/dist/esm/OpenAiClient.js
+++ b/dist/esm/OpenAiClient.js
@@ -1,165 +1,221 @@
-import * as AiResponse from "@effect/ai/AiResponse";
-import * as Sse from "@effect/experimental/Sse";
-import * as HttpBody from "@effect/platform/HttpBody";
-import * as HttpClient from "@effect/platform/HttpClient";
-import * as HttpClientRequest from "@effect/platform/HttpClientRequest";
-import * as Config from "effect/Config";
-import * as Context from "effect/Context";
-import * as Effect from "effect/Effect";
-import { identity } from "effect/Function";
-import * as Layer from "effect/Layer";
-import * as Option from "effect/Option";
-import * as Predicate from "effect/Predicate";
-import * as Redacted from "effect/Redacted";
-import * as Stream from "effect/Stream";
-import * as Generated from "./Generated.js";
-import * as InternalUtilities from "./internal/utilities.js";
-import { OpenAiConfig } from "./OpenAiConfig.js";
+import * as AiResponse from '@effect/ai/AiResponse';
+import * as Sse from '@effect/experimental/Sse';
+import * as HttpBody from '@effect/platform/HttpBody';
+import * as HttpClient from '@effect/platform/HttpClient';
+import * as HttpClientRequest from '@effect/platform/HttpClientRequest';
+import * as Config from 'effect/Config';
+import * as Context from 'effect/Context';
+import * as Effect from 'effect/Effect';
+import { identity } from 'effect/Function';
+import * as Layer from 'effect/Layer';
+import * as Option from 'effect/Option';
+import * as Predicate from 'effect/Predicate';
+import * as Redacted from 'effect/Redacted';
+import * as Stream from 'effect/Stream';
+import * as Generated from './Generated.js';
+import * as InternalUtilities from './internal/utilities.js';
+import { OpenAiConfig } from './OpenAiConfig.js';
 const constDisableValidation = {
-  disableValidation: true
+  disableValidation: true,
 };
 /**
  * @since 1.0.0
  * @category Context
  */
-export class OpenAiClient extends /*#__PURE__*/Context.Tag("@effect/ai-openai/OpenAiClient")() {}
+export class OpenAiClient extends /*#__PURE__*/ Context.Tag('@effect/ai-openai/OpenAiClient')() {}
 /**
  * @since 1.0.0
  * @category Constructors
  */
-export const make = options => Effect.gen(function* () {
-  const httpClient = (yield* HttpClient.HttpClient).pipe(HttpClient.mapRequest(request => request.pipe(HttpClientRequest.prependUrl(options.apiUrl ?? "https://api.openai.com/v1"), options.apiKey ? HttpClientRequest.bearerToken(options.apiKey) : identity, options.organizationId !== undefined ? HttpClientRequest.setHeader("OpenAI-Organization", Redacted.value(options.organizationId)) : identity, options.projectId !== undefined ? HttpClientRequest.setHeader("OpenAI-Project", Redacted.value(options.projectId)) : identity, HttpClientRequest.acceptJson)), options.transformClient ? options.transformClient : identity);
-  const httpClientOk = HttpClient.filterStatusOk(httpClient);
-  const client = Generated.make(httpClient, {
-    transformClient: client => OpenAiConfig.getOrUndefined.pipe(Effect.map(config => config?.transformClient ? config.transformClient(client) : client))
-  });
-  const streamRequest = request => httpClientOk.execute(request).pipe(Effect.map(r => r.stream), Stream.unwrapScoped, Stream.decodeText(), Stream.pipeThroughChannel(Sse.makeChannel()), Stream.takeWhile(event => event.data !== "[DONE]"), Stream.map(event => JSON.parse(event.data)));
-  const stream = request => Stream.suspend(() => {
-    const toolCalls = {};
-    let isFirstChunk = false;
-    let toolCallIndex = undefined;
-    let finishReason = "unknown";
-    let usage = {
-      inputTokens: 0,
-      outputTokens: 0,
-      totalTokens: 0,
-      reasoningTokens: 0,
-      cacheReadInputTokens: 0,
-      cacheWriteInputTokens: 0
-    };
-    let metadata = {};
-    return streamRequest(HttpClientRequest.post("/chat/completions", {
-      body: HttpBody.unsafeJson({
-        ...request,
-        stream: true,
-        stream_options: {
-          include_usage: true
-        }
-      })
-    })).pipe(Stream.filterMap(chunk => {
-      const parts = [];
-      // Add response metadata immediately once available
-      if (isFirstChunk) {
-        isFirstChunk = false;
-        parts.push(new AiResponse.MetadataPart({
-          id: chunk.id,
-          model: chunk.model,
-          timestamp: new Date(chunk.created * 1000)
-        }, constDisableValidation));
-      }
-      // Track usage information
-      if (Predicate.isNotNullable(chunk.usage)) {
-        usage = {
-          inputTokens: chunk.usage.prompt_tokens,
-          outputTokens: chunk.usage.completion_tokens,
-          totalTokens: chunk.usage.prompt_tokens + chunk.usage.completion_tokens,
-          reasoningTokens: chunk.usage.completion_tokens_details.reasoning_tokens,
-          cacheReadInputTokens: chunk.usage.prompt_tokens_details.cached_tokens,
-          cacheWriteInputTokens: usage.cacheWriteInputTokens
-        };
-        metadata = {
-          ...metadata,
-          serviceTier: chunk.service_tier,
-          systemFingerprint: chunk.system_fingerprint,
-          acceptedPredictionTokens: chunk.usage.completion_tokens_details.accepted_prediction_tokens,
-          rejectedPredictionTokens: chunk.usage.completion_tokens_details.rejected_prediction_tokens,
-          inputAudioTokens: chunk.usage.prompt_tokens_details.audio_tokens,
-          outputAudioTokens: chunk.usage.completion_tokens_details.audio_tokens
+export const make = (options) =>
+  Effect.gen(function* () {
+    const httpClient = (yield* HttpClient.HttpClient).pipe(
+      HttpClient.mapRequest((request) =>
+        request.pipe(
+          HttpClientRequest.prependUrl(options.apiUrl ?? 'https://api.openai.com/v1'),
+          options.apiKey ? HttpClientRequest.bearerToken(options.apiKey) : identity,
+          options.organizationId !== undefined
+            ? HttpClientRequest.setHeader('OpenAI-Organization', Redacted.value(options.organizationId))
+            : identity,
+          options.projectId !== undefined
+            ? HttpClientRequest.setHeader('OpenAI-Project', Redacted.value(options.projectId))
+            : identity,
+          HttpClientRequest.acceptJson,
+        ),
+      ),
+      options.transformClient ? options.transformClient : identity,
+    );
+    const httpClientOk = HttpClient.filterStatusOk(httpClient);
+    const client = Generated.make(httpClient, {
+      transformClient: (client) =>
+        OpenAiConfig.getOrUndefined.pipe(
+          Effect.map((config) => (config?.transformClient ? config.transformClient(client) : client)),
+        ),
+    });
+    const streamRequest = (request) =>
+      httpClientOk.execute(request).pipe(
+        Effect.map((r) => r.stream),
+        Stream.unwrapScoped,
+        Stream.decodeText(),
+        Stream.pipeThroughChannel(Sse.makeChannel()),
+        Stream.takeWhile((event) => event.data !== '[DONE]'),
+        Stream.map((event) => JSON.parse(event.data)),
+      );
+    const stream = (request) =>
+      Stream.suspend(() => {
+        const toolCalls = {};
+        let isFirstChunk = false;
+        let toolCallIndex = undefined;
+        let finishReason = 'unknown';
+        let usage = {
+          inputTokens: 0,
+          outputTokens: 0,
+          totalTokens: 0,
+          reasoningTokens: 0,
+          cacheReadInputTokens: 0,
+          cacheWriteInputTokens: 0,
         };
-      }
-      for (let i = 0; i < chunk.choices.length; i++) {
-        const choice = chunk.choices[i];
-        // Track the finish reason for the response
-        if (Predicate.isNotNullable(choice.finish_reason)) {
-          finishReason = InternalUtilities.resolveFinishReason(choice.finish_reason);
-          if (finishReason === "tool-calls" && Predicate.isNotUndefined(toolCallIndex)) {
-            finishToolCall(toolCalls[toolCallIndex], parts);
-          }
-          parts.push(new AiResponse.FinishPart({
-            usage,
-            reason: finishReason,
-            providerMetadata: {
-              [InternalUtilities.ProviderMetadataKey]: metadata
-            }
-          }, constDisableValidation));
-        }
-        // Handle text deltas
-        if (Predicate.isNotNullable(choice.delta.content)) {
-          parts.push(new AiResponse.TextPart({
-            text: choice.delta.content
-          }, constDisableValidation));
-        }
-        // Handle tool call deltas
-        if (Predicate.hasProperty(choice.delta, "tool_calls") && Array.isArray(choice.delta.tool_calls)) {
-          for (const delta of choice.delta.tool_calls) {
-            // Make sure to emit any previous tool calls before starting a new one
-            if (Predicate.isNotUndefined(toolCallIndex) && toolCallIndex !== delta.index) {
-              finishToolCall(toolCalls[toolCallIndex], parts);
-              toolCallIndex = undefined;
+        let metadata = {};
+        return streamRequest(
+          HttpClientRequest.post('/chat/completions', {
+            body: HttpBody.unsafeJson({
+              ...request,
+              stream: true,
+              stream_options: {
+                include_usage: true,
+              },
+            }),
+          }),
+        ).pipe(
+          Stream.filterMap((chunk) => {
+            const parts = [];
+            // Add response metadata immediately once available
+            if (isFirstChunk) {
+              isFirstChunk = false;
+              parts.push(
+                new AiResponse.MetadataPart(
+                  {
+                    id: chunk.id,
+                    model: chunk.model,
+                    timestamp: new Date(chunk.created * 1000),
+                  },
+                  constDisableValidation,
+                ),
+              );
             }
-            if (Predicate.isUndefined(toolCallIndex)) {
-              const toolCall = delta;
-              // All information except arguments are returned with the first tool call delta
-              toolCalls[delta.index] = {
-                ...toolCall,
-                isFinished: false
+            // Track usage information
+            if (Predicate.isNotNullable(chunk.usage)) {
+              usage = {
+                inputTokens: chunk.usage.prompt_tokens,
+                outputTokens: chunk.usage.completion_tokens,
+                totalTokens: chunk.usage.prompt_tokens + chunk.usage.completion_tokens,
+                reasoningTokens: chunk.usage.completion_tokens_details?.reasoning_tokens ?? 0,
+                cacheReadInputTokens: chunk.usage.prompt_tokens_details?.cached_tokens ?? 0,
+                cacheWriteInputTokens: usage.cacheWriteInputTokens,
+              };
+              metadata = {
+                ...metadata,
+                serviceTier: chunk.service_tier,
+                systemFingerprint: chunk.system_fingerprint,
+                acceptedPredictionTokens: chunk.usage.completion_tokens_details?.accepted_prediction_tokens ?? 0,
+                rejectedPredictionTokens: chunk.usage.completion_tokens_details?.rejected_prediction_tokens ?? 0,
+                inputAudioTokens: chunk.usage.prompt_tokens_details?.audio_tokens ?? 0,
+                outputAudioTokens: chunk.usage.completion_tokens_details?.audio_tokens ?? 0,
               };
-              toolCallIndex = delta.index;
-            } else {
-              toolCalls[delta.index].function.arguments += delta.function.arguments;
             }
-          }
-        }
-      }
-      return parts.length === 0 ? Option.none() : Option.some(AiResponse.AiResponse.make({
-        parts
-      }, constDisableValidation));
-    }));
-  });
-  return OpenAiClient.of({
-    client,
-    streamRequest,
-    stream
+            for (let i = 0; i < chunk.choices.length; i++) {
+              const choice = chunk.choices[i];
+              // Track the finish reason for the response
+              if (Predicate.isNotNullable(choice.finish_reason)) {
+                finishReason = InternalUtilities.resolveFinishReason(choice.finish_reason);
+                if (finishReason === 'tool-calls' && Predicate.isNotUndefined(toolCallIndex)) {
+                  finishToolCall(toolCalls[toolCallIndex], parts);
+                }
+                parts.push(
+                  new AiResponse.FinishPart(
+                    {
+                      usage,
+                      reason: finishReason,
+                      providerMetadata: {
+                        [InternalUtilities.ProviderMetadataKey]: metadata,
+                      },
+                    },
+                    constDisableValidation,
+                  ),
+                );
+              }
+              // Handle text deltas
+              if (Predicate.isNotNullable(choice.delta.content)) {
+                parts.push(
+                  new AiResponse.TextPart(
+                    {
+                      text: choice.delta.content,
+                    },
+                    constDisableValidation,
+                  ),
+                );
+              }
+              // Handle tool call deltas
+              if (Predicate.hasProperty(choice.delta, 'tool_calls') && Array.isArray(choice.delta.tool_calls)) {
+                for (const delta of choice.delta.tool_calls) {
+                  // Make sure to emit any previous tool calls before starting a new one
+                  if (Predicate.isNotUndefined(toolCallIndex) && toolCallIndex !== delta.index) {
+                    finishToolCall(toolCalls[toolCallIndex], parts);
+                    toolCallIndex = undefined;
+                  }
+                  if (Predicate.isUndefined(toolCallIndex)) {
+                    const toolCall = delta;
+                    // All information except arguments are returned with the first tool call delta
+                    toolCalls[delta.index] = {
+                      ...toolCall,
+                      isFinished: false,
+                    };
+                    toolCallIndex = delta.index;
+                  } else {
+                    toolCalls[delta.index].function.arguments += delta.function.arguments;
+                  }
+                }
+              }
+            }
+            return parts.length === 0
+              ? Option.none()
+              : Option.some(
+                  AiResponse.AiResponse.make(
+                    {
+                      parts,
+                    },
+                    constDisableValidation,
+                  ),
+                );
+          }),
+        );
+      });
+    return OpenAiClient.of({
+      client,
+      streamRequest,
+      stream,
+    });
   });
-});
 /**
  * @since 1.0.0
  * @category Layers
  */
-export const layer = options => Layer.effect(OpenAiClient, make(options));
+export const layer = (options) => Layer.effect(OpenAiClient, make(options));
 /**
  * @since 1.0.0
  * @category Layers
  */
-export const layerConfig = options => {
-  const {
-    transformClient,
-    ...configs
-  } = options;
-  return Config.all(configs).pipe(Effect.flatMap(configs => make({
-    ...configs,
-    transformClient
-  })), Layer.effect(OpenAiClient));
+export const layerConfig = (options) => {
+  const { transformClient, ...configs } = options;
+  return Config.all(configs).pipe(
+    Effect.flatMap((configs) =>
+      make({
+        ...configs,
+        transformClient,
+      }),
+    ),
+    Layer.effect(OpenAiClient),
+  );
 };
 // =============================================================================
 // Utilities
@@ -171,11 +227,13 @@ const finishToolCall = (toolCall, parts) => {
   }
   try {
     const params = JSON.parse(toolCall.function.arguments);
-    parts.push(new AiResponse.ToolCallPart({
-      id: toolCall.id,
-      name: toolCall.function.name,
-      params
-    }));
+    parts.push(
+      new AiResponse.ToolCallPart({
+        id: toolCall.id,
+        name: toolCall.function.name,
+        params,
+      }),
+    );
     toolCall.isFinished = true;
     // TODO:
     // eslint-disable-next-line no-empty
