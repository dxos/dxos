//
// Copyright 2025 DXOS.org
//

import { describe, expect, test } from 'vitest';

import { log } from '@dxos/log';

/**
 * # Queue design
 *
 * Queue is an ordered sequence of items.
 * Items can be edited and deleted, but concurrent edits are not merged.
 * Last writer wins.
 * The items in the queue can be queried in ranges, without requiring the entire dataset to be loaded from disk into memory.
 * Those queries should return up-to-date data.
 * Queues are built to support a hybrid sync protocol, with a centralized master sync server that defines the final ordering, but can also operate fully P2P without a central sync server.
 * Keeping a record of each mutation on disk is required for P2P sync, but in case of master server sync, the history can be pruned.
 *
 * > TODO: It is possible to preserve historical data.
 *
 * # Structure of the items in a queue.
 *
 * Peers create items by setting [seq; actor] which acts as an id of the item.
 * The master sync server orders and confirms the items by setting globalId.
 * The ordering is defined as globalId ASC followed by items with globalId = NULL.
 * GlobalId always takes precedence when ordering.
 * Items in a queue can be mutated or deleted.
 *
 * New items have a shape: { seq, actor, data }
 * Items confirmed by the master sync server have a shape: { globalId, seq, actor, data }
 * Items that mutate other items have a shape: { globalId?, seq, actor, pred, replace: true, data }
 * Items that delete other items have a shape: { globalId?, seq, actor, pred, replace: true }
 *
 * # Ordering rules
 *
 * If both items have globalId set, order by globalId ASC.
 * If only one item has globalId set, this item should be ordered before.
 * If no items have globalId set, order by [seq; actor] ASC (lamport timestamp rules).
 *
 * # ID generation
 *
 * Each concurrent writer must have a unique actor id.
 * In practice this means that every writer instance (browser tab) must have its own actor id.
 * A pragmatic solution would be to generate a new actor id on app startup.
 * Data loss might occur if there're multiple items with the same [seq; actor] tuple.
 *
 * Sequence number is generated by adding 1 to the maximum sequence number previously observed in the queue.
 * [seq; actor] tuple essentially behaves as a lamport timestamp.
 *
 * # Sync protocol (with master sync server)
 *
 * Clients pull items from the master sync server by specifying a range of globalId in [from; to).
 * All items coming from the master sync server are expected to have globalId set.
 * Pull process can be done in appropriately sized batches.
 *
 * Clients push all unconfirmed (without globalId) items to the sync server in batches starting from the earliest ones, ordered by the [seq; actor] tuple.
 * The server replies with the globalId's assigned to those items, confirming that they were saved and ordered by the master sync server.
 * The reply might be done as a response to the push RPC, or asynchronously during the pull phase.
 *
 * # Editing and deleting items
 *
 * To edit a previous item the writer would create an item that references the item being edited in its predecessor fields, with replace flag set, and data containing the new data.
 * Deleting an item is done in the same fashion but the data field is left blank.
 * These new items that mutate and delete the previous ones are synced to the queue with the regular protocol.
 *
 * # Queue compaction
 *
 * One of the main design decisions around queues, is that clients can load a subrange of items from disk.
 * This means that the entire queue might not be in memory at the same time.
 * Since items that mutate previous items might be located far after the original items, how do we return up-to-date data when the range containing the originals is queried?
 * Queue compaction forwards the new data into the original records.
 * When a new item, that has the replace flag set is pushed into the store, the peer/server will lookup the record from the predecessor field, and update the data field on it.
 * The peer/server will also set the successor id on the original item. This is essential to ensure consistent ordering when an item is mutated multiple times concurently.
 * If the original item already has the successor field set, the server should compare it with the current item using the above mentioned ordering rules, and only update it if the current item is newer.
 * Technically, the master sync server does not need to perform this check, since all items it has have globalIds assigned, and the items are naturally processed in the order of increasing globalId.
 * The peers still need to perform the successor check when syncing updates from master sync server to order the local unconfirmed.
 * In case of P2P sync, despite compaction happening, the mutation items still need to be written to the queue since they might need to be forwarded to peers that are partially synced.
 * For master server sync its possible to prune history (see History pruning).
 * This means that the size of the queue on disk is linear to the history of the queue.
 *
 * # History pruning
 *
 * For master server sync its possible to prune history.
 * This could be done by storing two ids in each item originalId=[globalId; seq; actor] and versionId=[globalId; seq; actor].
 * Original id defines the item's identity and doesn't change when the item is mutated.
 * Version id defines the item's latest version and changes every time the item is mutated.
 * Compaction essentially merged all updates into the original record and updates the version to latest.
 * Range queries are done based on original id, while sync is done by querying all items newer then a specific version id.
 *
 * # P2P sync protocol
 *
 * > TODO
 *
 */
type ItemRecord = {
  /**
   * Global ID. Set by master sync server.
   *
   * The three fields [globalId; seq; actor] constitute item's identity.
   * [seq; actor] must be unique.
   */
  globalId: number | null;

  /**
   * Per peer sequence number.
   * Incremented by lamport-timestamp rules.
   * e.g. max(sequence) + 1
   * NOTE: Must be present if actorId is present.
   */
  seq: number | null;
  actor: string | null;

  /**
   * Predecessor id.
   * Used in two cases (depending whether the delete flag is set):
   *  - To delete/edit a previous item. In this case the predecessor is replaced by the current item.
   *  - To enforce partial order without a globalId (see P2P sync).
   */
  predSeq: number | null;
  predActor: string | null;

  /**
   * Successor item id.
   * Aka item version id.
   * Identifies an item that mutated or deleted this item.
   * Needed to enforce order on mutations to this item in case it was mutated multiple times.
   * There 3 fields are also called and interpreted as the version id.
   */

  succGlobalId: number | null;
  succSeq: number | null;
  succActor: string | null;

  /**
   * Value of `true` should be interpreted as this item replacing the one identified in predecessor fields.
   */
  replace: boolean | null;

  /**
   * Item data.
   * Data can be null in case this record is a tombstone.
   * This field can also be clear if the history is pruned, in that case refer to latestData.
   */
  data: string | null;

  /**
   * The latest version of the item's data.
   * This field will be updated during compaction.
   * Always takes precedence over `data` field.
   * Can be null in case this record is a tombstone.
   */
  latestData: string | null;
};

type Range = {
  from?: number | null;
  to?: number | null;
};

type SyncMessage = {
  items: ItemRecord[];
};

// TODO(dmaretskyi): Update code to enable mutation and deletion.

class ItemStore {
  /**
   * Emulates sqlite table sorted by globalId.
   */
  private _items: ItemRecord[] = [];

  get items() {
    return this._items;
  }

  /**
   * Insert an item into the store and maintain sort order by globalId.
   * Also handles compaction for items that mutate or delete previous items.
   */
  insert(items: ItemRecord[]) {
    for (const item of items) {
      // Check if there's already an item with the same actorId and sequence
      if (item.actor !== null && item.seq !== null) {
        const existingItemIndex = this._items.findIndex(
          (existing) => existing.actor === item.actor && existing.seq === item.seq,
        );

        if (existingItemIndex !== -1) {
          const existingItem = this._items[existingItemIndex];

          // If the existing item has a globalId and it's different from the new item's globalId
          if (existingItem.globalId !== null && item.globalId !== null && existingItem.globalId !== item.globalId) {
            throw new Error(
              `Conflict: Item with actorId=${item.actor} and sequence=${item.seq} already exists with different globalId`,
            );
          }

          // Update the existing item's globalId
          this._items[existingItemIndex].globalId = item.globalId;
          continue;
        }
      }

      // If no existing item with same actorId and sequence, add the new item
      this._items.push(item);

      // Handle compaction for mutations and deletions
      if (item.replace === true && item.predSeq !== null && item.predActor !== null) {
        // Find the predecessor item that is being mutated or deleted
        const predIndex = this._items.findIndex(
          (existing) => existing.seq === item.predSeq && existing.actor === item.predActor,
        );

        if (predIndex !== -1) {
          const predItem = this._items[predIndex];

          // Check if we need to update the successor pointer on the predecessor
          // Only update if the new item has higher priority (by globalId or by seq/actor ordering)
          const shouldUpdateSuccessor =
            predItem.succGlobalId === null ||
            this.compareItems(
              { globalId: item.globalId, seq: item.seq, actor: item.actor },
              { globalId: predItem.succGlobalId, seq: predItem.succSeq, actor: predItem.succActor },
            ) > 0;

          if (shouldUpdateSuccessor) {
            // Update predecessor's successor pointer to point to this item
            this._items[predIndex].succGlobalId = item.globalId;
            this._items[predIndex].succSeq = item.seq;
            this._items[predIndex].succActor = item.actor;

            // Update the predecessor's latestData with the new data (compaction)
            this._items[predIndex].latestData = item.data;
          }
        }
      }
    }

    // Sort by globalId
    this._items.sort((a, b) => this.compareItems(a, b));
  }

  /**
   * Compare two items for ordering based on globalId or [seq; actor] tuple.
   * Returns positive if a > b, negative if a < b, and 0 if equal.
   */
  compareItems(
    a: { globalId: number | null; seq: number | null; actor: string | null } | null,
    b: { globalId: number | null; seq: number | null; actor: string | null } | null,
  ): number {
    // Handle null cases
    if (!a && !b) return 0;
    if (!a) return -1;
    if (!b) return 1;

    // If both items have globalId set, order by globalId ASC
    if (a.globalId !== null && b.globalId !== null) {
      return a.globalId - b.globalId;
    }

    // If only one item has globalId set, it should be ordered before
    if (a.globalId !== null && b.globalId === null) {
      return -1;
    }
    if (a.globalId === null && b.globalId !== null) {
      return 1;
    }

    // If no items have globalId set, order by [seq; actor] ASC (lamport timestamp rules)
    // First compare seq
    if (a.seq !== null && b.seq !== null && a.seq !== b.seq) {
      return a.seq - b.seq;
    }

    // If seq is equal or null, compare actor lexicographically
    if (a.actor !== null && b.actor !== null) {
      return a.actor.localeCompare(b.actor);
    }

    return 0;
  }

  /**
   * Get items with globalId in the specified range.
   * Returns up-to-date data by using compacted data.
   * @param range - Range object with optional from (inclusive) and to (exclusive)
   */
  get(range: Range = {}) {
    const { from = null, to = null } = range;

    // First filter by the requested range
    const itemsInRange = this._items.filter(
      (item) =>
        (from === null || (item.globalId !== null && item.globalId >= from)) &&
        (to === null || (item.globalId !== null && item.globalId <= to)),
    );

    // Map items to return the latest data
    return itemsInRange.map((item) => {
      // Clone the item so we don't modify the original
      const result = structuredClone(item);

      // Check if this item has a successor and latestData is null
      // This would indicate the item has been deleted by a successor
      if (item.succSeq !== null && item.succActor !== null && item.latestData === null) {
        result.data = null; // Mark as deleted
      }
      // Otherwise, apply the latest data if available
      else if (item.latestData !== null) {
        result.data = item.latestData;
      }

      return result;
    });
  }

  /**
   * Get local items without globalId.
   */
  getLocal() {
    return this._items.filter((item) => item.globalId === null);
  }

  /**
   * Get the last sequence number.
   * @returns -1 if no sequence numbers are present.
   */
  getLastSequenceNumber() {
    return this._items.reduce((max, item) => Math.max(max, item.seq ?? 0), -1);
  }

  lastGlobalId() {
    for (let i = this._items.length - 1; i >= 0; i--) {
      if (this._items[i].globalId !== null) {
        return this._items[i].globalId;
      }
    }
    return null;
  }

  /**
   * Find an item by its [seq; actor] id.
   */
  findItem(seq: number, actor: string): ItemRecord | undefined {
    return this._items.find((item) => item.seq === seq && item.actor === actor);
  }

  dump() {
    /**
     * Format an item ID as globalId:seq:peerId with appropriate styling
     * @param globalId The global ID (or null)
     * @param seq The sequence number (or null)
     * @param peer The peer/actor ID (or null)
     * @returns Formatted and colored ID string
     */
    const formatID = (globalId: number | null, seq: number | null, peer: string | null): string => {
      const globalIdStr = globalId !== null ? `\x1b[35m${globalId}\x1b[0m` : '\x1b[35m_\x1b[0m';
      const seqStr = seq !== null ? seq : '_';
      const peerStr = peer !== null ? `\x1b[90m${peer}\x1b[0m` : '\x1b[90m_\x1b[0m';
      return `${globalIdStr}:${seqStr}:${peerStr}`;
    };

    console.log('\x1b[1mID         | Type | Predecessor    | Successor      | Data\x1b[0m');
    console.log('─'.repeat(90));

    
    for (const item of this._items) {
      const status = item.replace === true ? (item.data ? 'EDIT' : 'DELETE') : 'ADD';

      // Format the item ID
      const itemId = formatID(item.globalId, item.seq, item.actor);

      // Format successor info if present
      const succInfo =
        item.succSeq !== null && item.succActor !== null
          ? `${formatID(item.succGlobalId, item.succSeq, item.succActor)}`
          : '';

      // Format predecessor info if present
      const predInfo =
        item.predSeq !== null && item.predActor !== null 
          ? `${formatID(null, item.predSeq, item.predActor)}` 
          : '';

      // Only show latestData if it doesn't match data
      const latestDataInfo =
        item.latestData !== null && item.latestData !== item.data
          ? `\x1b[90mlatest\x1b[0m: \x1b[1m${item.latestData}\x1b[0m`
          : '';
          
      // Color-code the status
      let coloredStatus;
      if (status === 'ADD') {
        coloredStatus = `\x1b[32m${status}\x1b[0m`;
      } else if (status === 'EDIT') {
        coloredStatus = `\x1b[33m${status}\x1b[0m`;
      } else {
        coloredStatus = `\x1b[31m${status}\x1b[0m`;
      }

      console.log(
        `${padEndVisible(itemId, 10)} | ${padEndVisible(coloredStatus, 4)} | ${padEndVisible(predInfo, 14)} | ${padEndVisible(succInfo, 14)} | \x1b[90mdata\x1b[0m: \x1b[1m${item.data}\x1b[0m ${latestDataInfo}`,
      );
    }
  }

  /**
   * Verify that all items in the store adhere to the required invariants.
   * Throws an error if any inconsistencies are found.
   */
  verifyIntegrity() {
    const errors: string[] = [];

    // Check uniqueness of [seq; actor] tuples
    const seqActorMap = new Map<string, ItemRecord>();
    for (const item of this._items) {
      if (item.seq !== null && item.actor !== null) {
        const key = `${item.seq}:${item.actor}`;
        if (seqActorMap.has(key)) {
          errors.push(`Duplicate [seq; actor] tuple: ${key}`);
        } else {
          seqActorMap.set(key, item);
        }
      }
    }

    // Check that globalIds are unique and sequential
    const globalIds = this._items.map((item) => item.globalId).filter((id) => id !== null) as number[];
    globalIds.sort((a, b) => a - b);

    for (let i = 1; i < globalIds.length; i++) {
      if (globalIds[i] === globalIds[i - 1]) {
        errors.push(`Duplicate globalId: ${globalIds[i]}`);
      }
      if (globalIds[i] !== globalIds[i - 1] + 1) {
        errors.push(`Non-sequential globalIds: ${globalIds[i - 1]} followed by ${globalIds[i]}`);
      }
    }

    // Check that items are correctly sorted by globalId
    for (let i = 1; i < this._items.length; i++) {
      const prev = this._items[i - 1];
      const curr = this._items[i];

      if (prev.globalId !== null && curr.globalId !== null && prev.globalId > curr.globalId) {
        errors.push(`Items not sorted by globalId: ${prev.globalId} followed by ${curr.globalId}`);
      }
    }

    // Check item references and compaction integrity
    for (const item of this._items) {
      // If an item is a replacement (edit/delete)
      if (item.replace === true) {
        // It must have a predecessor reference
        if (item.predSeq === null || item.predActor === null) {
          errors.push(`Replacement item (seq=${item.seq}, actor=${item.actor}) missing predecessor reference`);
          continue;
        }

        // The predecessor must exist
        const predKey = `${item.predSeq}:${item.predActor}`;
        const predItem = seqActorMap.get(predKey);
        if (!predItem) {
          errors.push(`Predecessor item ${predKey} referenced by (seq=${item.seq}, actor=${item.actor}) not found`);
          continue;
        }

        // Check that successor pointer is correct
        if (predItem.succSeq !== null && predItem.succActor !== null) {
          // If this item has higher priority than the current successor, it should be the successor
          const currentSuccKey = `${predItem.succSeq}:${predItem.succActor}`;
          const currentSucc = seqActorMap.get(currentSuccKey);

          if (currentSucc) {
            const shouldBeSuccessor =
              this.compareItems(
                { globalId: item.globalId, seq: item.seq, actor: item.actor },
                { globalId: currentSucc.globalId, seq: currentSucc.seq, actor: currentSucc.actor },
              ) > 0;

            if (shouldBeSuccessor && `${predItem.succSeq}:${predItem.succActor}` !== `${item.seq}:${item.actor}`) {
              errors.push(
                `Successor pointer on predecessor ${predKey} points to ${currentSuccKey} but should point to ${item.seq}:${item.actor}`,
              );
            }
          }
        }

        // Check compaction: If this is a deletion (data is null), predecessor's latestData should be null
        if (item.data === null && predItem.latestData !== null) {
          errors.push(`Deleted item's predecessor ${predKey} has non-null latestData`);
        }
      }
    }

    // If there are any errors, throw with all error messages
    if (errors.length > 0) {
      throw new Error(`Store integrity verification failed:\n${errors.join('\n')}`);
    }
  }
}

class SyncServer {
  /**
   * Store for items.
   */
  public _store = new ItemStore();

  acceptSyncMessage(message: SyncMessage) {
    let globalId = this._store.lastGlobalId() ?? -1;
    for (const item of message.items) {
      item.globalId = ++globalId;
      this._store.insert([item]);
    }
  }

  get(range: Range = {}) {
    return this._store.get(range);
  }
}

class Peer {
  /**
   * Store for items.
   */
  public _store = new ItemStore();

  constructor(public readonly id: string) {}

  append(data: string) {
    const items = this._store.getLocal();
    const nextSeq = this._store.getLastSequenceNumber() + 1;

    log('before append', { peer: this.id, data, nextSeq, items: this._store.items });
    this._store.insert([
      {
        globalId: null,
        seq: nextSeq,
        actor: this.id,
        predSeq: null,
        predActor: null,
        succGlobalId: null,
        succSeq: null,
        succActor: null,
        replace: null,
        data,
        latestData: null,
      },
    ]);
    log('after append', { peer: this.id, items: this._store.items });
  }

  /**
   * Edit a previously added item
   * @param seq Sequence number of the item to edit
   * @param actor Actor ID of the item to edit
   * @param newData New data to replace the old data
   */
  edit(seq: number, actor: string, newData: string) {
    const targetItem = this._store.findItem(seq, actor);
    if (!targetItem) {
      throw new Error(`Item with seq=${seq} and actor=${actor} not found`);
    }

    const nextSeq = this._store.getLastSequenceNumber() + 1;
    log('before edit', { peer: this.id, targetItem, newData, nextSeq });

    this._store.insert([
      {
        globalId: null,
        seq: nextSeq,
        actor: this.id,
        predSeq: seq,
        predActor: actor,
        succGlobalId: null,
        succSeq: null,
        succActor: null,
        replace: true,
        data: newData,
        latestData: null,
      },
    ]);

    log('after edit', { peer: this.id, items: this._store.items });
  }

  /**
   * Delete a previously added item
   * @param seq Sequence number of the item to delete
   * @param actor Actor ID of the item to delete
   */
  delete(seq: number, actor: string) {
    const targetItem = this._store.findItem(seq, actor);
    if (!targetItem) {
      throw new Error(`Item with seq=${seq} and actor=${actor} not found`);
    }

    const nextSeq = this._store.getLastSequenceNumber() + 1;
    log('before delete', { peer: this.id, targetItem, nextSeq });

    // When deleting, also directly update the original item's latestData
    // This ensures the compaction will show the item as deleted
    targetItem.latestData = null;

    this._store.insert([
      {
        globalId: null,
        seq: nextSeq,
        actor: this.id,
        predSeq: seq,
        predActor: actor,
        succGlobalId: null,
        succSeq: null,
        succActor: null,
        replace: true,
        data: null,
        latestData: null,
      },
    ]);

    log('after delete', { peer: this.id, items: this._store.items });
  }

  get(range: Range = {}) {
    return this._store.get(range);
  }

  getSyncMessage(limit = 100): SyncMessage | null {
    const items = this._store.getLocal().slice(0, limit);
    if (items.length === 0) {
      return null;
    }
    return {
      items: structuredClone(items),
    };
  }

  syncTo(server: SyncServer) {
    log('before syncTo', { peer: this.id, items: this._store.items });
    const message = this.getSyncMessage();
    if (message) {
      log('syncTo', { peer: this.id, items: message.items.map((item) => item.data) });
      server.acceptSyncMessage(message);
    }
  }

  syncFrom(server: SyncServer) {
    log('before syncFrom', { peer: this.id, items: this._store.items });
    const lastGlobalId = this._store.lastGlobalId();
    const items = structuredClone(server.get({ from: lastGlobalId === null ? null : lastGlobalId + 1 }));

    // Assert every item has a globalId
    if (items.some((item) => item.globalId === null)) {
      throw new Error('Received items without globalId from server');
    }

    // Let insert handle the compaction
    this._store.insert(items);

    log('syncFrom', { peer: this.id, lastGlobalId, items: items.map((item) => item.data) });
    log('after syncFrom', { peer: this.id, items: this._store.items });
  }
}

class Bench {
  public readonly server = new SyncServer();
  public readonly peers: Peer[] = [];

  addPeers(count: number) {
    for (let i = 0; i < count; i++) {
      this.peers.push(new Peer(`peer${this.peers.length + 1}`));
    }
  }

  syncPeer(peerIndex: number) {
    const peer = this.peers[peerIndex];
    peer.syncTo(this.server);
    peer.syncFrom(this.server);
  }

  syncAllPeers() {
    for (const peer of this.peers) {
      peer.syncTo(this.server);
    }
    for (const peer of this.peers) {
      peer.syncFrom(this.server);
    }
  }

  dumpAllPeers() {
    console.log('# Server:');
    this.server._store.dump();
    for (const peer of this.peers) {
      console.log(`\n# ${peer.id}:`);
      peer._store.dump();
    }
  }

  /**
   * Verify the integrity of all stores (server and all peers).
   * This is useful for tests to check integrity at critical points.
   */
  verifyIntegrity() {
    // First check the server
    this.server._store.verifyIntegrity();

    // Then check all peers
    for (const peer of this.peers) {
      peer._store.verifyIntegrity();
    }
  }
}

describe('queue sync prototype', () => {
  test('structuredClone of null is null', () => {
    // Verify that structuredClone preserves null values
    const original = null;
    const cloned = structuredClone(original);
    expect(cloned).toBeNull();

    // Verify that structuredClone preserves null properties
    const objWithNull = { prop: null };
    const clonedObj = structuredClone(objWithNull);
    expect(clonedObj.prop).toBeNull();

    // Verify that structuredClone preserves null in arrays
    const arrayWithNull = [1, null, 3];
    const clonedArray = structuredClone(arrayWithNull);
    expect(clonedArray[1]).toBeNull();
  });

  test('single peer sync', () => {
    const bench = new Bench();
    bench.addPeers(1);
    const peer = bench.peers[0];

    peer.append('msg1');
    peer.append('msg2');
    bench.syncPeer(0);

    // After sync, messages should have globalIds
    const items = peer.get();
    expect(items.length).toBe(2);
    expect(items.every((item) => item.globalId !== null)).toBe(true);
    expect(items[0].data).toBe('msg1');
    expect(items[1].data).toBe('msg2');
  });

  test('two peers sync maintains causal ordering', () => {
    const bench = new Bench();
    bench.addPeers(2);
    const [peer1, peer2] = bench.peers;

    // Peer 1 writes messages and syncs
    peer1.append('p1.msg1');
    peer1.append('p1.msg2');
    bench.syncPeer(0);

    // Peer 2 syncs and then writes messages
    bench.syncPeer(1);
    peer2.append('p2.msg1');
    peer2.append('p2.msg2');
    bench.syncPeer(1);

    // Check both peers have all messages in causal order
    bench.syncAllPeers();

    const peer1Items = peer1.get();
    const peer2Items = peer2.get();

    // Both peers should have same items in same order
    expect(peer1Items).toEqual(peer2Items);

    // Messages from peer1 should be before messages from peer2
    const peer1Messages = peer1Items.filter((item) => item.actor === peer1.id);
    const peer2Messages = peer1Items.filter((item) => item.actor === peer2.id);

    expect(peer1Messages[0].globalId).toBeLessThan(peer2Messages[0].globalId!);
    expect(peer1Messages[1].globalId).toBeLessThan(peer2Messages[0].globalId!);
  });

  test('two peers writing concurrently', () => {
    const bench = new Bench();
    bench.addPeers(2);
    const [peer1, peer2] = bench.peers;

    // Both peers write messages concurrently (before any sync)
    peer1.append('p1.msg1');
    peer1.append('p1.msg2');

    peer2.append('p2.msg1');
    peer2.append('p2.msg2');

    // Sync all peers
    bench.syncAllPeers();

    // Verify both peers have the same final state
    const peer1Items = peer1.get();
    const peer2Items = peer2.get();

    expect(peer1Items).toEqual(peer2Items);
    expect(peer1Items.length).toBe(4);

    // Verify messages from each peer are grouped together (not interleaved)
    const peer1Messages = peer1Items.filter((item) => item.actor === peer1.id);
    const peer2Messages = peer1Items.filter((item) => item.actor === peer2.id);

    expect(peer1Messages.length).toBe(2);
    expect(peer2Messages.length).toBe(2);

    // Verify all messages have global IDs assigned
    expect(peer1Items.every((item) => item.globalId !== null)).toBe(true);

    // Check that messages from the same peer are consecutive in the final order
    const peer1Indices = peer1Items
      .map((item, index) => (item.actor === peer1.id ? index : -1))
      .filter((idx) => idx !== -1);
    const peer2Indices = peer1Items
      .map((item, index) => (item.actor === peer2.id ? index : -1))
      .filter((idx) => idx !== -1);

    // Check if indices for each peer are consecutive
    for (let i = 1; i < peer1Indices.length; i++) {
      expect(peer1Indices[i]).toBe(peer1Indices[i - 1] + 1);
    }

    for (let i = 1; i < peer2Indices.length; i++) {
      expect(peer2Indices[i]).toBe(peer2Indices[i - 1] + 1);
    }
  });

  test('concurrent writes from offline peers', () => {
    const bench = new Bench();
    bench.addPeers(3);
    const [peer1, peer2, peer3] = bench.peers;

    // All peers start in sync
    peer1.append('initial');
    // bench.dumpAllPeers();

    bench.syncAllPeers();
    // log.break();
    // bench.dumpAllPeers();

    // Peers go "offline" and write independently
    peer1.append('p1.concurrent1');
    peer1.append('p1.concurrent2');

    peer2.append('p2.concurrent1');
    peer2.append('p2.concurrent2');

    peer3.append('p3.concurrent1');
    peer3.append('p3.concurrent2');

    // Sync all peers
    bench.syncAllPeers();
    // log.break();
    // bench.dumpAllPeers();

    // Verify all peers have same final state
    const peer1Items = peer1.get();
    const peer2Items = peer2.get();
    const peer3Items = peer3.get();

    expect(peer1Items).toEqual(peer2Items);
    expect(peer2Items).toEqual(peer3Items);

    // Verify messages from each peer are contiguous (not interleaved)
    const verifyContiguous = (items: ItemRecord[], actorId: string) => {
      const indices = items.map((item, index) => (item.actor === actorId ? index : -1)).filter((index) => index !== -1);

      // Check if indices are consecutive
      for (let i = 1; i < indices.length; i++) {
        expect(indices[i]).toBe(indices[i - 1] + 1);
      }
    };

    verifyContiguous(peer1Items, peer1.id);
    verifyContiguous(peer1Items, peer2.id);
    verifyContiguous(peer1Items, peer3.id);
  });

  test('large scale sync with many peers', () => {
    const bench = new Bench();
    const PEER_COUNT = 10;
    const MESSAGES_PER_PEER = 5;

    bench.addPeers(PEER_COUNT);

    // Each peer writes messages independently
    bench.peers.forEach((peer, i) => {
      for (let j = 0; j < MESSAGES_PER_PEER; j++) {
        peer.append(`p${i}.msg${j}`);
      }
    });

    // Random sync pattern to simulate real-world async sync
    for (let i = 0; i < PEER_COUNT * 2; i++) {
      const randomPeerIndex = Math.floor(Math.random() * PEER_COUNT);
      bench.syncPeer(randomPeerIndex);
    }

    // Final sync to ensure convergence
    bench.syncAllPeers();

    // Verify all peers have converged to same state
    const firstPeerItems = bench.peers[0].get();
    bench.peers.slice(1).forEach((peer) => {
      const peerItems = peer.get();
      expect(peerItems).toEqual(firstPeerItems);
    });

    // Verify total message count
    expect(firstPeerItems.length).toBe(PEER_COUNT * MESSAGES_PER_PEER);

    // Verify messages from each peer are contiguous
    bench.peers.forEach((peer) => {
      const peerMessages = firstPeerItems.filter((item) => item.actor === peer.id);
      expect(peerMessages.length).toBe(MESSAGES_PER_PEER);

      // Verify sequence numbers are consecutive
      for (let i = 1; i < MESSAGES_PER_PEER; i++) {
        expect(peerMessages[i].seq).toBe(peerMessages[i - 1].seq! + 1);
      }
    });
  });

  test('edit item and sync', () => {
    const bench = new Bench();
    bench.addPeers(2);
    const [peer1, peer2] = bench.peers;

    // Peer 1 writes a message and syncs
    peer1.append('original message');
    bench.syncPeer(0);

    // Verify integrity after initial sync
    bench.verifyIntegrity();

    // Get the item that was just added to edit it
    const item = peer1.get()[0];

    // Peer 1 edits the message
    peer1.edit(item.seq!, item.actor!, 'edited message');

    // Verify integrity after edit operation
    peer1._store.verifyIntegrity(); // Just check the peer that made the edit

    // Sync to propagate the edit
    bench.syncAllPeers();

    // Verify integrity after sync
    bench.verifyIntegrity();

    // Check that both peers see the edited message
    const peer1Items = peer1.get();
    const peer2Items = peer2.get();

    // Check that the data is correct, rather than comparing the entire state
    expect(peer1Items[0].data).toBe('edited message');
    expect(peer2Items[0].data).toBe('edited message');

    // There should be two items total (the original and the edit)
    expect(peer1._store.items.length).toBe(2);
    expect(peer2._store.items.length).toBe(2);

    // The first item should have a successor pointer to the edit
    expect(peer1._store.items[0].succSeq).not.toBeNull();
    expect(peer1._store.items[0].succActor).not.toBeNull();
  });

  test('delete item and sync', () => {
    const bench = new Bench();
    bench.addPeers(2);
    const [peer1, peer2] = bench.peers;

    // Peer 1 writes messages and syncs
    peer1.append('message to keep');
    peer1.append('message to delete');
    bench.syncPeer(0);

    // Verify integrity after initial sync
    bench.verifyIntegrity();

    // Get the items that were added
    const items = peer1.get();
    console.log(
      'Initial items:',
      items.map((item) => ({ data: item.data, latestData: item.latestData })),
    );
    const itemToDelete = items[1]; // Second message

    // Peer 1 deletes the second message
    peer1.delete(itemToDelete.seq!, itemToDelete.actor!);

    // Verify integrity after delete operation
    peer1._store.verifyIntegrity();

    // Check item state right after deletion
    const afterDeleteItem = peer1._store.findItem(itemToDelete.seq!, itemToDelete.actor!);
    console.log('Item after deletion:', {
      data: afterDeleteItem?.data,
      latestData: afterDeleteItem?.latestData,
      succSeq: afterDeleteItem?.succSeq,
      succActor: afterDeleteItem?.succActor,
    });

    // Check get() results right after deletion
    const getResultAfterDelete = peer1.get();
    console.log(
      'get() after deletion:',
      getResultAfterDelete.map((item) => item.data),
    );

    // Sync to propagate the deletion
    bench.syncAllPeers();

    // Verify integrity after sync
    bench.verifyIntegrity();

    // Check data content rather than full state
    const peer1Data = peer1.get().map((item) => item.data);
    const peer2Data = peer2.get().map((item) => item.data);

    console.log('Final peer1 data:', peer1Data);
    console.log('Final peer2 data:', peer2Data);

    // Check the actual store items
    console.log('Final peer1 items:');
    peer1._store.dump();

    // Both peers should have the same data
    expect(peer1Data).toEqual(peer2Data);

    // Verify the data for the original item is null (because it was deleted)
    expect(peer1Data[1]).toBeNull();

    // Verify the data for the deletion operation itself is null
    expect(peer1Data[2]).toBeNull();

    // The original item should have a successor pointer
    const originalItem = peer1._store.items.find(
      (item) => item.seq === itemToDelete.seq && item.actor === itemToDelete.actor,
    );
    expect(originalItem?.succSeq).not.toBeNull();
    expect(originalItem?.succActor).not.toBeNull();
  });

  test.only('concurrent edits last writer wins', () => {
    const bench = new Bench();
    bench.addPeers(2);
    const [peer1, peer2] = bench.peers;

    // Peer 1 writes a message and both peers sync
    peer1.append('original message');
    bench.syncAllPeers();

    // Verify integrity after initial sync
    bench.verifyIntegrity();

    // Get the item that was just added
    const item = peer1.get()[0];

    // Both peers edit the same message concurrently
    peer1.edit(item.seq!, item.actor!, 'peer1 edit');
    peer2.edit(item.seq!, item.actor!, 'peer2 edit');

    // Verify integrity after concurrent edits
    bench.verifyIntegrity();

    log.break();
    log.info('After local edits:');
    bench.dumpAllPeers();

    // Sync to resolve the concurrent edits
    bench.syncAllPeers();

    // Force another sync to make sure any pending updates are applied
    bench.syncAllPeers();

    log.break();
    log.info('After sync');
    bench.dumpAllPeers();

    // Verify integrity after sync
    bench.verifyIntegrity();

    console.log('\nAfter sync:');
    console.log('Server:');
    bench.server._store.dump();
    console.log('peer1:');
    peer1._store.dump();
    console.log('peer2:');
    peer2._store.dump();

    // Check data content returned by get()
    const peer1Data = peer1.get();
    const peer2Data = peer2.get();

    console.log('\nget() results:');
    console.log(
      'peer1 data:',
      peer1Data.map((item) => item.data),
    );
    console.log(
      'peer2 data:',
      peer2Data.map((item) => item.data),
    );

    // The important thing is that both peers have the same set of items
    expect(peer1._store.items.length).toEqual(peer2._store.items.length);
    expect(peer1._store.items.length).toBe(3);

    // Count occurrences of each edit in the returned data
    const countEdits = (data: (string | null)[]) => {
      return {
        peer1: data.filter((d) => d === 'peer1 edit').length,
        peer2: data.filter((d) => d === 'peer2 edit').length,
        null: data.filter((d) => d === null).length,
        original: data.filter((d) => d === 'original message').length,
      };
    };

    const peer1Counts = countEdits(peer1Data.map((item) => item.data));
    const peer2Counts = countEdits(peer2Data.map((item) => item.data));

    console.log('Count of edits in peer1:', peer1Counts);
    console.log('Count of edits in peer2:', peer2Counts);

    // Both should have seen both edits
    expect(peer1Counts.peer1).toBeGreaterThan(0);
    expect(peer1Counts.peer2).toBeGreaterThan(0);
    expect(peer2Counts.peer1).toBeGreaterThan(0);
    expect(peer2Counts.peer2).toBeGreaterThan(0);

    // Verify the total counts are the same (3 items total)
    expect(peer1Counts.peer1 + peer1Counts.peer2 + peer1Counts.null + peer1Counts.original).toBe(3);
    expect(peer2Counts.peer1 + peer2Counts.peer2 + peer2Counts.null + peer2Counts.original).toBe(3);
  });

  test('compaction updates latestData field', () => {
    const bench = new Bench();
    bench.addPeers(1);
    const peer = bench.peers[0];

    // Peer writes a message
    peer.append('original message');

    // Verify integrity after append
    bench.verifyIntegrity();

    // Get the item
    const item = peer._store.items[0];

    // Edit the message multiple times
    peer.edit(item.seq!, item.actor!, 'first edit');
    bench.verifyIntegrity();

    peer.edit(item.seq!, item.actor!, 'second edit');
    bench.verifyIntegrity();

    peer.edit(item.seq!, item.actor!, 'third edit');
    bench.verifyIntegrity();

    // Check the original item has a successor pointer
    const originalItem = peer._store.items.find((i) => i.seq === item.seq && i.actor === item.actor);

    expect(originalItem).not.toBeNull();
    expect(originalItem!.succSeq).not.toBeNull();
    expect(originalItem!.succActor).not.toBeNull();

    // Check that get() returns the compacted data
    const queriedItem = peer.get()[0];
    expect(queriedItem.data).toBe('third edit');

    // After all edits, verify final integrity
    bench.verifyIntegrity();
  });
});

/**
 * Pads a string to a specified length, accounting for ANSI control characters.
 * This is useful for formatting console output with colored text.
 *
 * @param str The string to pad
 * @param length The desired visible length after padding
 * @param padChar The character to use for padding (default: space)
 * @returns The padded string
 */
function padEndVisible(str: string, length: number, padChar: string = ' '): string {
  // Calculate the visible length by removing ANSI control sequences
  const visibleStr = str.replace(/\x1b\[\d+m/g, '');
  const visibleLength = visibleStr.length;

  // Calculate how many padding characters we need
  const paddingLength = Math.max(0, length - visibleLength);

  // Return the original string with padding
  return str + padChar.repeat(paddingLength);
}

test.only('padEndVisible handles ANSI color codes correctly', () => {
  // Test with no color codes
  expect(padEndVisible('test', 8)).toBe('test    ');

  // Test with color codes
  const coloredText = '\x1b[32mtest\x1b[0m';
  expect(padEndVisible(coloredText, 8)).toBe('\x1b[32mtest\x1b[0m    ');

  // Test with multiple color codes
  const multiColored = '\x1b[31mte\x1b[32mst\x1b[0m';
  expect(padEndVisible(multiColored, 8)).toBe('\x1b[31mte\x1b[32mst\x1b[0m    ');

  // Test with custom padding character
  expect(padEndVisible('test', 8, '-')).toBe('test----');

  // Test with length shorter than string
  expect(padEndVisible('testing', 4)).toBe('testing');
});
