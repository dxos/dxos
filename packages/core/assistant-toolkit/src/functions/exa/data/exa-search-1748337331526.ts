//
// Copyright 2025 DXOS.org
//

export default {
  requestId: '0dc12e344fa649884456960ca1a54954',
  autopromptString: 'PKM software artificial intelligence integration open source projects',
  resolvedSearchType: 'neural',
  results: [
    {
      id: 'https://github.com/subspace-ai/subspace',
      title: 'GitHub - subspace-ai/subspace: PKM + REPL + AI',
      url: 'https://github.com/subspace-ai/subspace',
      publishedDate: '2023-03-23T16:02:40.000Z',
      author: 'subspace-ai',
      score: 0.7530648708343506,
      text: "subspace.ai - PKM + REPL + AI \n The long-term goal of subspace is to be/have three things: \n \n PKM (Personal Knowledge Management system) like Roam Research or Tana. \n REPL-like (Read Evaluate Print Loop) capabilities. Should be able to execute individual code cells in the JVM backend and rendered in the frontend with Electric. Similar behaviour can be achieved with other languages via Jupyter kernels (or GraalVM Polyglot) and JavaScript. \n AI (Artificial Intelligence) integrations. Should be integrated with LLMs - e.g. write GPT queries in subspace, and incorporate the response to your personal knowledge base as a new node. Intelligent search and LLM-based summaries and reasoning over the existing knowledge base (Retrieval Oriented Generation, RAG). \n \n The overall design should be open-ended, allowing for easy forking and providing custom node types / rendering functions. The goal is not to be just a storage of information, but a control panel for commonly used workflows. So that you can create convenient shortcuts and informative output views with Clojure + Electric. Since you persist which actions you took over time, you can search for past outputs and interleave these with your personal notes. Later query your knowledge base with RAG in natural language, or query it with GPT by exposing subspace knowledge base as an API to GPT. \n For example, additional customizations and use cases could be: \n \n Intelligent work log for day to day coding. \n Wrappers for any babashka / shell scripts you already have. \n Wrapper functions to MLOps platform (or some other task manager) to trigger jobs, query stats and logs from past train runs. Build dashboards as subspace nodes from the result of such queries with Electric+HTML. \n Wrappers for common Kubernetes / AWS / GCP commands. Build ad hoc UIs on top of your cluster that make sense to you. \n Wrappers that pull the contents of arxiv documents as subspace nodes. \n Spaced repetition learning of content (of nodes which you mark to be remembered). \n \n UI/UX \n There will be two types of UI elements: pages and nodes. Pages contain nodes, and nodes can nest other nodes. Both pages and nodes are referencable (meaning you can link to them and the page/node will get a backreference). \n Each node contains some media, and possibly subnodes. \n Media can be: \n \n Text, numeric, Markdown \n Image, video, audio \n Flexible spreadsheet tesserrae \n code block, which can be executed in a jupyter kernel (runs once) \n code block containing an e/fn (runs continuously when on the page) \n \n Executing an e/fn is the most powerful and flexible thing to do. It can pull data in from other nodes on the page or in the graph, and displays its own little UI within its boundaries. Crucially, when upstream info changes, your e/fn's output gets recomputed. Running tesserrae is also very powerful; you can think of subspace as a non-grid tesserae that can also embed tesserae. \n Subnodes can be organised either by indenting or tiling. \n \n Indente",
      image:
        'https://opengraph.githubassets.com/734547dbba15cefe41b9ad9cd97ba2ac489aeebd18945d54dbf7b1931b5ed980/subspace-ai/subspace',
      favicon: 'https://github.com/fluidicon.png',
    },
    {
      id: 'https://github.com/khoj-ai/khoj',
      title:
        'GitHub - khoj-ai/khoj: Your AI second brain. Self-hostable. Get answers from the web or your docs. Build custom agents, schedule automations, do deep research. Turn any online or local LLM into your personal, autonomous AI (gpt, claude, gemini, llama, qwen, mistral). Get started - free.',
      url: 'https://github.com/khoj-ai/khoj',
      publishedDate: '2021-08-16T01:48:44.000Z',
      author: 'khoj-ai',
      score: 0.33666935563087463,
      text: "\n \n \n \n \n Your AI second brain \n \n \n \n ğŸ New \n \n Start any message with /research to try out the experimental research mode with Khoj. \n Anyone can now create custom agents with tunable personality, tools and knowledge bases. \n Read about Khoj's excellent performance on modern retrieval and reasoning benchmarks. \n \n \n Overview \n Khoj is a personal AI app to extend your capabilities. It smoothly scales up from an on-device personal AI to a cloud-scale enterprise AI. \n \n Chat with any local or online LLM (e.g llama3, qwen, gemma, mistral, gpt, claude, gemini, deepseek). \n Get answers from the internet and your docs (including image, pdf, markdown, org-mode, word, notion files). \n Access it from your Browser, Obsidian, Emacs, Desktop, Phone or Whatsapp. \n Create agents with custom knowledge, persona, chat model and tools to take on any role. \n Automate away repetitive research. Get personal newsletters and smart notifications delivered to your inbox. \n Find relevant docs quickly and easily using our advanced semantic search. \n Generate images, talk out loud, play your messages. \n Khoj is open-source, self-hostable. Always. \n Run it privately on your computer or try it on our cloud app. \n \n \n See it in action \n \n Go to https://app.khoj.dev to see Khoj live. \n Full feature list \n You can see the full feature list here. \n Self-Host \n To get started with self-hosting Khoj, read the docs. \n Enterprise \n Khoj is available as a cloud service, on-premises, or as a hybrid solution. To learn more about Khoj Enterprise, visit our website. \n Frequently Asked Questions (FAQ) \n Q: Can I use Khoj without self-hosting? \n Yes! You can use Khoj right away at https://app.khoj.dev â€” no setup required. \n Q: What kinds of documents can Khoj read? \n Khoj supports a wide variety: PDFs, Markdown, Notion, Word docs, org-mode files, and more. \n Q: How can I make my own agent? \n Check out this blog post for a step-by-step guide to custom agents.\nFor more questions, head over to our Discord! \n Contributors \n Cheers to our awesome contributors! ğŸ‰ \n \n \n Made with contrib.rocks. \n Interested in Contributing? \n Khoj is open source. It is sustained by the community and weâ€™d love for you to join it! Whether youâ€™re a coder, designer, writer, or enthusiast, thereâ€™s a place for you. \n Why Contribute? \n \n Make an Impact: Help build, test and improve a tool used by thousands to boost productivity. \n Learn &amp; Grow: Work on cutting-edge AI, LLMs, and semantic search technologies. \n \n You can help us build new features, improve the project documentation, report issues and fix bugs. If you're a developer, please see our Contributing Guidelines and check out good first issues to work on. \n",
      image: 'https://repository-images.githubusercontent.com/396569538/533a8bf7-385f-427b-a03f-76795fd938ed',
      favicon: 'https://github.com/fluidicon.png',
    },
    {
      id: 'https://github.com/paulbricman/conceptarium',
      title: 'GitHub - paulbricman/conceptarium: A fluid medium for storing, relating, and surfacing thoughts.',
      url: 'https://github.com/paulbricman/conceptarium',
      publishedDate: '2021-08-12T04:45:29.000Z',
      author: 'paulbricman',
      score: 0.3376504182815552,
      text: "\n ğŸ’¡ Conceptarium \n The conceptarium is an experimental personal knowledge base designed to weave AI capabilities into knowledge work. Its main features include: \n \n powerful multi-modal search across ideas \n sharing microverses of knowledge with peers \n ranking items by Anki-like activation, so as to promote serendipity \n \n Installation \n Docker \n After installing docker and docker-compose, run: \n # install with:\ncurl -fsS https://raw.githubusercontent.com/paulbricman/conceptarium/main/docker-compose.yml -o docker-compose.yml\nmkdir knowledge\ndocker-compose up -d\n# stop with:\ndocker-compose stop\n# update with:\ndocker-compose stop\ndocker-compose rm -f\ndocker-compose pull\ndocker-compose up -d\n \n Note that you'll have to wait a bit initially for the models to be downloaded in the docker container. Use docker logs &lt;backend container ID&gt; or watch the process's memory for feedback on that. Or just try using it until it via the API or UI until it works (see usage). \n Source \n After pulling this repo run: \n python3 -m pip install -r frontend/requirements.txt\npython3 -m pip install -r backend/requirements.txt\nstreamlit run frontend/main.py\n# in a separate session:\ncd backend\npython3 -m uvicorn main:app --reload\n# update by pulling from repo again\n \n Missing dependencies? Please have a look at frontend/Dockerfile and backend/Dockerfile. ARM architecture (e.g. Raspberry Pi)? Remove the torch entries from requirements.txt, and install a custom-built version. \n Usage \n The web app should then be available at localhost:8501, while the API at localhost:8000 (with docs at localhost:8000/docs). The backend component takes a few minutes to get the ML models at first. \n To access your local instance, enter the conceptarium URL (i.e. localhost:8000 if you ran from source, backend.docker:8000 if you used docker), and your desired token. Remember your token, as you'll have to use it to authenticate in future sessions. \n",
      image:
        'https://opengraph.githubassets.com/2b454d3e4b9d69c65d465d8ec6609b3b61f34b83f1f8eece471806be32e710bc/paulbricman/conceptarium',
      favicon: 'https://github.com/fluidicon.png',
    },
    {
      id: 'https://github.com/mfakih/Pomegranate-PKM',
      title:
        'GitHub - mfakih/Pomegranate-PKM: Pomegranate PKM is a new open source web-based cross-platform work and knowledge management application for productive and prolific people. PKM features text-based commands for adding, updating and searching records, thus providing powerful tools to manage information. It also allows the user to build up the navigation menu using saved searches.',
      url: 'https://github.com/mfakih/Pomegranate-PKM',
      publishedDate: '2014-03-17T06:28:12.000Z',
      author: 'mfakih',
      score: 0.7761150002479553,
      text: 'Pomegranate-PKM \n Pomegranate PKM is a new open source web-based cross-platform work and knowledge management application for productive and prolific people. \n PKM features text-based commands for adding, updating and searching records, thus providing powerful tools to manage information. It also allows the user to build up the navigation menu using saved searches. \n \n Pomegranate PKM manages: \n \n Goals, tasks, and plans \n Journal and indicators \n Writings and notes \n Resources (books, articles, news, presentations, audiobooks, documentaries, movies etc),and book excerpts, mainly book chapters. \n Documents e.g. Word documents, Excels \n People \n \n In technical terms, Pomegranate PKM is a combination of: \n \n Document management system \n Content management system \n Research index cards and reference management \n Bug tracking systems, applied for the software development and self development \n Lightweight project management \n Powerful task management \n Time tracking \n Blog (e.g. WordPress) client \n \n My in-progress book at LeanPub outlines the motivations, design principles and the features of Pomegranate PKM. \n',
      image:
        'https://opengraph.githubassets.com/d4afbe16f55b89cbdd3344472df483147de49f6a8a136bd1da7af7e568c16908/mfakih/Pomegranate-PKM',
      favicon: 'https://github.com/fluidicon.png',
    },
    {
      id: 'https://github.com/mfakih294/Nibras-PKM',
      title:
        'GitHub - mfakih294/Nibras-PKM: A web-based self-hosted open-source system for the long-term management of personal information. It targets the needs of advanced users with serious information management needs. It is accompanied with an Android application that syncs the bookmarked records over local Wifi network.',
      url: 'https://github.com/mfakih294/Nibras-PKM',
      publishedDate: '2019-09-14T02:05:28.000Z',
      author: 'mfakih294',
      score: 0.7633954882621765,
      text: "Nibras PKM \n Nibras PKM is a web-based self-hosted open source system for\nthe long-term management of personal information.\nIt is a combination of a web-based application\nintended for desktop use and where all the records are entered,\nand an Android mobile reader application. \n \n Local \n The user has full control over his/her data, without the need for a (fast) internet connection, and without all the distractions and information overload that the internet can cause. \n Open source \n The user has control over the system itself too, especially when using it on the long term to manage the important personal information and files. \n Comprehensize \n It manages resources (articles, books, documents), notes, writings, tasks, goals, journal, planner, payments, indicators, and (study) courses and departments. \n Powerful \n It was designed with large amounts of information in mind. In current usage, it manages dozens of thousands of records. With its commands and saved searches, it makes easy to navigate through all the information. \n Main Features \n \n Flexible text-based commands to add, update and search records, which provides powerful ways to manage information. \n Saved searches to save searches for later use. \n Ability to display records on calendars and Kanban boards. \n Full-text search of all record fields. \n Simple file system integration so to greatly reduce the need to organize files manually. \n \n Documentation \n User's guide is available online at https://mfakih294.github.io/Nibras-PKM/. \n Releases \n Nibras PKM is hosted on GitHub https://github.com/mfakih294/Nibras-PKM. \n Quick start guide \n Running Nibras requires three simple steps: \n \n Download the bundle file corresponding to your platform, e.g. nibras-bundle-windows.zip from the releases page on Github. \n Extract the zipped file to a location of your choice on your local disk. \n Launch Nibras by double clicking on ./scripts/start file. \n \n Once Nibras has finished launching, a message like the one below will appear. \n * Nibras has launched. You can access it from: * \n * https://localhost:1441/ * \n Go to https://localhost:1441/ using Firefox or Chrome. On the login page, enter nibras for username and nibras for the password. \n Notes: \n \n As it has a self-signed certificate, you need to accept and bypass the security warning that shows up at the beginning. \n On Linux, you need to make the files inside ./scripts and ./tomcat/bin folders executable (chmod +x *). \n To stop Nibras, you can close this window, or press ctrl+c in it, or run ./scripts/stop script. \n \n Technical details \n \n Nibras is developed in Grails framework 3.3.10, a dynamic framework on top of the Java platform. \n Grails applications run on any platform that can run Java 8 and later, so practically all platforms, including Windows, Linux, Mac. \n For production use, Nibras uses MySQL 5+ for its database, and the file system to store the files of the records. To testing and demonstration, it can run with h2 database, with zero ex",
      image:
        'https://opengraph.githubassets.com/5e45c614cd8441100a4acd0e48d8b9c15984b51e816d4d4683436dd3be25c813/mfakih294/Nibras-PKM',
      favicon: 'https://github.com/fluidicon.png',
    },
    {
      id: 'https://github.com/reorproject/reor',
      title: 'GitHub - reorproject/reor: Private & local AI personal knowledge management app for high entropy people.',
      url: 'https://github.com/reorproject/reor',
      publishedDate: '2023-11-27T01:30:44.000Z',
      author: 'reorproject',
      text: 'Reor Project \n \nPrivate &amp; local AI personal knowledge management app. \n \n \n \n \n \n \n ğŸ“¢ Announcement \n We are now on Discord! Our team is shipping very quickly right now so sharing â¤ï¸feedbackâ¤ï¸ with us will really help shape the product ğŸš€ \n \n About \n Reor is an AI-powered desktop note-taking app: it automatically links related notes, answers questions on your notes and provides semantic search. Everything is stored locally and you can edit your notes with an Obsidian-like markdown editor. \n The hypothesis of the project is that AI tools for thought should run models locally by default. Reor stands on the shoulders of the giants Ollama, Transformers.js &amp; LanceDB to enable both LLMs and embedding models to run locally: \n \n Every note you write is chunked and embedded into an internal vector database. \n Related notes are connected automatically via vector similarity. \n LLM-powered Q&amp;A does RAG on your corpus of notes. \n Everything can be searched semantically. \n \n One way to think about Reor is as a RAG app with two generators: the LLM and the human. In Q&amp;A mode, the LLM is fed retrieved context from the corpus to help answer a query. Similarly, in editor mode, the human can toggle the sidebar to reveal related notes "retrieved" from the corpus. This is quite a powerful way of "augmenting" your thoughts by cross-referencing ideas in a current note against related ideas from your corpus. \n Getting Started \n \n Download from reorproject.org or releases. Mac, Linux &amp; Windows are all supported. \n Install like a normal App. \n \n Running local models \n Reor interacts directly with Ollama which means you can download and run models locally right from inside Reor. Head to Settings-&gt;Add New Local LLM then enter the name of the model you want Reor to download. You can find available models here. \n You can also connect to an OpenAI-compatible API like Oobabooga, Ollama or OpenAI itself! \n Importing notes from other apps \n Reor works within a single directory in the filesystem. You choose the directory on first boot.\nTo import notes/files from another app, you\'ll need to populate that directory manually with markdown files. Note that if you have frontmatter in your markdown files it may not parse correctly. Integrations with other apps are hopefully coming soon! \n Building from source \n Make sure you have nodejs installed. \n Clone repo \n git clone https://github.com/reorproject/reor.git\n \n Install dependencies \n Run for dev \n Build \n Interested in contributing? \n We are always on the lookout for contributors keen on building the future of knowledge management. Have a feature idea? Want to squash a bug? Want to improve some styling? We\'d love to hear it. Check out our issues page and the contributing guide to get started. \n License \n AGPL-3.0 license. See LICENSE for details. \n Reor means "to think" in Latin. \n',
      image:
        'https://opengraph.githubassets.com/101249afc41e6b8729eca3c619d4c08c5c67288ab4126de16c59c1ab97c5492c/reorproject/reor',
      favicon: 'https://github.com/fluidicon.png',
    },
    {
      id: 'https://github.com/memex-life/memex',
      title:
        'GitHub - memex-life/memex: Your second brain for the web browsing. An AI powered Chrome extension that constructs personal knowledge base for you.',
      url: 'https://github.com/memex-life/memex',
      publishedDate: '2023-03-16T23:48:35.000Z',
      author: 'memex-life',
      score: 0.34730345010757446,
      text: 'Memex \n Your second brain for web browsing. Picture possessing the ultimate ability of total recall. \n \n Overview \n This project aims to create a browser extension that acts like a personal memex machine.\nIt will keep track of everything you browse online to build your own knowledge base.\nThen it will use AI to retrieve that knowledge whenever you need it. \n What is a Memex? \n \n Consider a future device for individual use, which is a sort of mechanized private file and library. It needs a name, and, to coin one at random, â€œmemexâ€ will do. A memex is a device in which an individual stores all his books, records, and communications, and which is mechanized so that it may be consulted with exceeding speed and flexibility. It is an enlarged intimate supplement to his memory. \n--- â€œAs We May Thinkâ€ Vannevar Bush (1945) \n \n Features \n \n Seamlessly captures content and metadata from your web browsing. \n Constructs your own personalized knowledge base on your local device \n Retrive knowledge with power of AI. \n \n How it works \n When you browse the web, this extension will inject a script to capture the text content on the pages you visit. It will send that content to the backend service-worker for processing\nThe service-worker will break the content into pieces and store it in a database.\nThe popup page acts as a chat interface to answer your questions using the information in the database. \n Getting Started \n Build &amp; import Extension \n Build extension files into dist/ folder \n npm install\nnpm run build # or npm run watch \n Load extension \n Start the Kownledge Base server \n Currently the LangchainJs has not yet support browser runtime. The extension still needs a backend server as Knowledge Base implementaion. \n set environments: \n export TOKENIZERS_PARALLELISM=false\nexport OPENAI_API_KEY=&lt;your-api-key&gt;\ncd server\nFLASK_APP=server flask run\n \n Start using \n Once you have completed the above steps, you can start using the Memex browser extension to enhance your web browsing experience. \n \n As you browse the web, the extension will automatically capture and store the text content from the web pages you visit, along with their metadata, in your personalized knowledge base. \n When you need to retrieve information or recall something from your browsing history, simply open the chat interface by clicking on the Memex extension icon. Type your question or query into the chat interface and press Enter or click the Send button. The Memex extension will use AI to search your knowledge base and provide you with the most relevant information based on your query. \n \n',
      image:
        'https://opengraph.githubassets.com/aa7966b46e8bb10410af6cdb5af62c9095d99c4b9d17683b246641b8a1291746/memex-life/memex',
      favicon: 'https://github.com/fluidicon.png',
    },
    {
      id: 'https://github.com/samkeen/knowling',
      title:
        'GitHub - samkeen/knowling: A desktop notes application leveraging AI designed for Personal Knowledge Management (PKM)',
      url: 'https://github.com/samkeen/knowling',
      publishedDate: '2024-03-08T03:28:38.000Z',
      author: 'samkeen',
      score: 0.8010122776031494,
      text: 'Knowling \n A desktop notes application designed for Personal Knowledge Management (PKM) \n \n Knowling aims to provide users with an intuitive platform for gathering and organizing knowledge from various research\nsources. By leveraging AI, Knowling assists users in categorizing their notes and highlighting connections between them,\nthereby enhancing the overall management of their personal knowledge store. \n Features \n \n Fast Performance: Knowling is developed using Rust and JavaScript, ensuring a responsive and efficient user\nexperience. \n WSIWIG Markdown Editor: A What-You-See-Is-What-You-Get (WSIWIG) Markdown editor for seamless and straightforward\nnote-taking. \n Simple, Uncluttered UI: The user interface is designed to be minimalistic and distraction-free, allowing users to\nfocus on their content. \n Export/Import Notes: Easily export and import notes to manage your knowledge base across different devices and\nformats. \n AI Integration: AI is integrated to empower users by automatically categorizing notes and identifying meaningful\nconnections between them. \n Open Source: Knowling is open source and licensed under the Apache 2.0 license, encouraging community\ncontributions\nand\ntransparency. \n \n Current Development Status \n Knowling is currently in the early stages of development, with a minimal feature set. We are actively working on\nexpanding the application\'s capabilities and enhancing its functionality. We welcome you to check out the open feature\nrequests and encourage you to open new ones if you have any suggestions or ideas. \n \n Open Issues \n Project view \n \n We hope you find Knowling valuable for managing your personal knowledge. If you have any feedback or encounter any\nissues, please don\'t hesitate to reach out or contribute to the project. \n Why the name Knowling: Knowling is a play on the words "Knowledge" and "Knolling", a process of arranging objects to\ncreate clean and organized\nspaces. This reflects our goal of helping users keep their knowledge organized and easily accessible. \n \n \n Developing Knowling \n Knowling is built atop Tauri 1.x \n Project setup \n npm install\nnpm run tauri dev\n \n Development \n Build \n https://tauri.app/v1/api/cli/ \n Development follows the common practices of developing a Tauri application. \n Debugging in RustRover \n https://tauri.app/v1/guides/debugging/rustrover/ \n',
      image:
        'https://opengraph.githubassets.com/68a818dd653e6084907d244111f983fe2b2367dcfb8eed93ebece179892ae74c/samkeen/knowling',
      favicon: 'https://github.com/fluidicon.png',
    },
    {
      id: 'https://github.com/whl1207/Knowledge',
      title: 'GitHub - whl1207/Knowledge: Distributed Multi-View Intelligent Knowledge Management Platform',
      url: 'https://github.com/whl1207/Knowledge',
      publishedDate: '2023-08-26T03:26:41.000Z',
      author: 'whl1207',
      score: 0.35489749908447266,
      text: 'AI-KM Intelligent Knowledge Management Platform \n Overview \n AI-KM (Artificial Intelligence Knowledge Management) is a next-generation knowledge management platform that integrates cutting-edge AI technologies. Leveraging large language models and knowledge graph technologies, it helps individuals and organizations achieve efficient knowledge organization, in-depth analysis, and intelligent application. \n \n Core Value \n \n Intelligent Knowledge Processing: Automatically parses, queries, and associates knowledge content \n Multi-dimensional Visualization: Provides 6 view modes to present knowledge relationships \n Open Model Integration: Supports seamless switching between mainstream open-source large language models via Ollama \n Enterprise-grade Security: All data processing is performed locally \n \n Key Features \n 1. Core Technical Architecture \n \n \n Multi-model Integration Engine \n \n Supports mainstream large language models deployed via the Ollama framework \n Base models: Deepseek-R1, qwen3, LLaMA3.3, QWQ \n Embedding models: nomic-embed-text, bge-m3, mxbai-embed-large \n Multimodal models: Gemma3, Mistral-Small 3.1 \n \n \n \n Enhanced Retrieval System \n \n RAG (Retrieval-Augmented Generation) architecture \n Supports knowledge base preprocessing (default segmentation by 2 line breaks) \n Supports similarity calculations for various embedding models \n Supports hidden information inference in knowledge bases (default: deducing potential user queries) and knowledge fragment keyword editing \n Supports custom retrieval thresholds (can set knowledge base retrieval thresholds based on cosine similarity, quantity, characters, etc.) \n Explainable analysis and debugging of retrieval results, displaying similarity information for each knowledge fragment \n Supports cosine similarity calculation and MDS dimensionality reduction-based similarity calculation \n \n \n \n Visual Workflow Engine \n \n Drag-and-drop AI processing pipeline construction \n Includes 3+ pre-built node templates \n Supports workflow import/export \n \n \n \n Markdown Document Editing \n \n Deep Markdown parsing and editing \n Document structure analysis (heading hierarchy recognition) \n Code block processing \n \n \n \n Multi-view Knowledge Display Module \n \n \n \n Multi-platform Packaging &amp; Deployment \n \n Electron-based packaging for Windows, Linux, macOS, and other platform clients \n \n \n \n Installation &amp; Deployment \n System Requirements \n \n OS: Windows 10+/macOS 12+/Linux (Ubuntu 20.04+) \n Hardware:\n \n Minimum: 8GB RAM, 4-core CPU, 10GB storage \n Recommended: 16GB+ RAM, dedicated GPU, 50GB+ storage \n \n \n \n Development Environment Setup \n # Install dependencies \nnpm install\n # Run in development mode \nnpm run dev\n # Build Windows client \nnpm run build\n # Generate installation package \n AI-KM æ™ºèƒ½çŸ¥è¯†ç®¡ç†å¹³å° \n æ¦‚è¿° \n AI-KMï¼ˆArtificial Intelligence Knowledge Managementï¼‰æ˜¯ä¸€ä¸ªé›†æˆäº†å‰æ²¿AIæŠ€æœ¯çš„ä¸‹ä¸€ä»£çŸ¥è¯†ç®¡ç†å¹³å°ï¼Œé€šè¿‡å¤§è¯­è¨€æ¨¡å‹å’ŒçŸ¥è¯†å›¾è°±æŠ€æœ¯ï¼Œå¸®åŠ©ä¸ªäººå’Œç»„ç»‡å®ç°çŸ¥è¯†çš„é«˜æ•ˆç»„ç»‡ã€æ·±åº¦åˆ†æå’Œæ™ºèƒ½åº”ç”¨ã€‚ \n æ ¸å¿ƒä»·å€¼ \n \n æ™ºèƒ½çŸ¥è¯†å¤„ç† ï¼šè‡ªåŠ¨è§£æã€æŸ¥è¯¢å’Œå…³è”çŸ¥è¯†å†…å®¹ \n å¤šç»´åº¦å¯è§†åŒ– ï¼šæä¾›6ç§è§†å›¾æ¨¡å¼å‘ˆç°çŸ¥è¯†å…³ç³» \n å¼€æ”¾æ¨¡å‹é›†æˆ ï¼šå¯ä»¥é€šè¿‡ollamaæ”¯æŒä¸»æµå¼€æº',
      image:
        'https://opengraph.githubassets.com/fc9354a52086145d1cf60e2b9c3d386a3be8fa44e2e00cbb13cd2b1af09973b7/whl1207/Knowledge',
      favicon: 'https://github.com/fluidicon.png',
    },
    {
      id: 'https://github.com/putaodoudou/kmagent',
      title:
        'GitHub - putaodoudou/kmagent: KMAgent (Knowledge Management Agent)ï¼ŒåŸºäºè¯­ä¹‰å…ƒçš„æ™ºèƒ½çŸ¥è¯†ç®¡ç†GTDå·¥å…·ï¼Œä¸ªäººæ™ºèƒ½åŠ©ç†ã€‚',
      url: 'https://github.com/putaodoudou/kmagent',
      publishedDate: '2018-06-05T09:11:21.000Z',
      author: 'putaodoudou',
      score: 0.35521113872528076,
      text: 'KMAgent-ä¸ªäººæ™ºèƒ½åŠ©ç† \n \n ä¸ªäºº çŸ¥è¯†æ™ºèƒ½åŠ©ç†ï¼ˆKMAgent, Knowledge Management Agentï¼‰--ä¸“æ³¨æ™ºèƒ½çŸ¥è¯†ç®¡ç†GTD å¤šå…ƒèåˆåˆ›æ–° å‘æ‰¬ä¼ æ‰¿æ™ºæ…§ï¼ \n KMAgent ä»¥ ä¸ªäººçŸ¥è¯†ç®¡ç† GTD åº”ç”¨ä¸ºä¸»çš„å·¥å…·æ•ˆç‡è½¯ä»¶ã€‚åŸºäºäº¤äº’åŒº+æ–‡æ¡£çš„ååŒå­¦ä¹ å·¥ä½œç©ºé—´ï¼Œä¸“æ³¨äºè¯­ä¹‰è®¡ç®—ã€çŸ¥è¯†å·¥ç¨‹ï¼Œè‡´åŠ›äºé€šè¿‡è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨å­¦ä¹ ã€çŸ¥è¯†å›¾è°±ç­‰äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œç®€åŒ–çŸ¥è¯†å¢å¼ºè®¤çŸ¥ã€èåˆæ”¯æŒä¼˜ç§€æ–¹æ³•è®ºæ¨¡æ¿ï¼Œè¾…åŠ©é«˜æ•ˆå­¦ä¹ å·¥ä½œï¼Œæ‰©å±•ä¸ªäººèƒ½åŠ›ï¼Œç±»ä¼¼é’¢é“ä¾ çš„ã€è´¾ç»´æ–¯ã€‘ã€‚ä»¥å¼€æºé¡¹ç›®çš„å½¢å¼ç»“åˆäº§å­¦ç ”ï¼Œæ”¯æŒç¤¾ç¾¤ååŒç§¯ç´¯åˆ›æ–°ï¼ŒèŠ‚çœæ—¶é—´ç²¾åŠ›ï¼Œä»çŸ¥è¯†ä¸­æŒ–æ˜æ™ºæ…§ã€‚æ‚¨çš„ç§äººçŸ¥è¯†å¼•æ“ã€ç§˜ä¹¦ã€æ™ºå‹ã€æ™ºå›Šå›¢ã€‚ \n è¯·æŸ¥çœ‹ç½‘ç«™ http://kmagent.com è·å–ç›¸å…³å®‰è£…æŒ‡å—åŠä½¿ç”¨è¯´æ˜ã€‚ \n ä¸ºä»€ä¹ˆWhy? \n \n ç‰¹åˆ«é‡è¦çš„ä¸¤ä¸ªèƒ½åŠ›ï¼š1ã€åˆ¶é€ å·¥å…·ï¼›2ã€å¯»æ±‚åˆä½œã€‚ \n \n æ™ºèƒ½æ—¶ä»£ï¼Œä¿¡æ¯çˆ†ç‚¸ï¼ŒçŸ¥è¯†åŒ®ä¹ï¼Œè¾…åŠ©åšå‡æ³•ï¼ååŒåˆä½œï¼Œé™ä½ä¿¡æ¯ç†µï¼Œæé«˜æ™ºå•†ï¼Œæç®€æ™ºèƒ½çŸ¥è¯†ç®¡ç†ï¼ \n \n \n çŸ¥è¯†è´¢å¯Œ ï¼Œç§¯ç´¯çŸ¥è¯†èƒœè¿‡ç§¯ç´¯é‡‘é’±ï¼ŒçŸ¥è¯†æ˜¯äººç±»è¿›æ­¥çš„é˜¶æ¢¯ã€‚æ˜¯ä¸ªäººåŠä¼ä¸šçš„æ ¸å¿ƒç«äº‰åŠ›ï¼ \n åŒ–ç¹ä¸ºç®€ ï¼Œå‘ç°æ¨¡å¼åŒ–ç¹ä¸ºç®€ï¼ŒæŒ–æ˜æœ¬è´¨åŠå…³è”ï¼ŒçŸ¥å…¶ç„¶çŸ¥å…¶æ‰€ä»¥ç„¶ï¼Œä¿ƒè¿›èåˆåˆ›æ–°ã€‚ \n äººç±»æ™ºèƒ½ ï¼ŒæŒ–æ˜éšæ€§çŸ¥è¯†ã€ç†è§£äººç±»å¤šå…ƒæ™ºèƒ½ï¼Œå‘æ˜åˆ©ç”¨å¤§è„‘æ½œåŠ›ï¼ŒæŒ‘æˆ˜è®¤çŸ¥æé™ã€‚ \n çŸ¥è¯†ä¼ æ’­ ï¼Œé™æ€æ–‡æœ¬ä¹¦ç±çš„ç¼ºé™·ã€æ¢ç´¢æ–°çš„çŸ¥è¯†å­˜å‚¨å±•ç¤ºåˆ†äº«æ–¹å¼ï¼Œå»ºç«‹é«˜æ•ˆæ²Ÿé€šååŒä¸ç§¯ç´¯åˆ†äº«çš„åŸºç¡€ã€‚ \n å®ç°åº”å¯¹äººå·¥æ™ºèƒ½ ï¼ŒçŸ¥è¯†ä¸æ™ºèƒ½ç›¸è¾…ç›¸æˆï¼ŒçŸ¥è¯†ç®¡ç†ä½œä¸ºæ ¸å¿ƒç¯èŠ‚ï¼Œæ‰¿ä¸Šå¯ä¸‹å½¢æˆé—­ç¯ï¼Œç¤¾ç¾¤ååŒç§¯ç´¯åˆ›æ–°ã€‚ \n é‡æ–°é€ è½®å­ ï¼Œä¸ºè‡ªå·±å¼€å‘ä¸€ä¸ªå·¥å…·ï¼Œè‡ªç„¶äº¤äº’é™ä½å·¥å…·å­¦ä¹ ä½¿ç”¨æˆæœ¬ï¼Œæ”¯æŒå­¦ä¹ å·¥ä½œç”Ÿæ´»ã€‚ \n ä½œä¸ºäº‹ä¸š ï¼Œå€¼å¾—å¥‹æ–—åå¹´çš„äº‹ä¸šã€‚ \n \n Do something diferent, make a change! \n \n ã€äº§å“ç®€ä»‹ã€‘äº§å“åŸå‹æ­£ç«é€Ÿå¼€å‘ä¸­ï¼ \n \n æ˜¯ä»¥æ–‡æ¡£+äº¤äº’åŒºä¸ºä¸­å¿ƒçš„åŠŸèƒ½é›†æˆï¼Œèµ„æºäº‹åŠ¡è¡Œä¸ºçš„ååŒæ™ºèƒ½ç®¡ç†GTDã€‚é¦–å…ˆç”¨äºååŒå»ºç«‹æ ¸å¿ƒæ¦‚å¿µç†è®ºä½“ç³»ï¼ŒçŸ¥è¯†ç®¡ç†ä¸šåŠ¡å»ºæ¨¡ï¼Œç§¯ç´¯åˆ†äº«èµ„æºçŸ¥è¯†æŠ€æœ¯ï¼Œåº”ç”¨äºKMã€ITã€AIã€æ•°å­¦ç›¸å…³é¢†åŸŸçŸ¥è¯†çš„å­¦ä¹ æ•´ç†ã€‚ \n \n åŠŸèƒ½åŠç‰¹æ€§ï¼š \n \n å¤šåª’ä½“æ— é™ç”»æ¿ã€å®æ—¶ååŒæ–‡æœ¬å¯¼å›¾ç¼–è¾‘å™¨ï¼Œå¯Œæ–‡æœ¬å’Œ Markdown æ‰©å±•ç¼–è¾‘ã€‚ \n æ”¯æŒæœ¬ä½“å»ºæ¨¡ã€é˜…è¯»ç¬”è®°ã€çµæ„Ÿä¾¿ç­¾ã€æ€ç»´å¯¼å›¾ã€å„ç±»æ¨¡æ¿ã€‚ \n åˆ’è¯ç¿»è¯‘çŸ¥è¯†è§£é‡Šã€æœç´¢ã€ç™¾ç§‘å­—å…¸ã€‚ \n çŸ¥è¯†å¯è§†åŒ–ï¼Œå¤šå±‚æ¬¡ç²’åº¦ç»´åº¦å»å†—ä½™ï¼Œæµ“ç¼©æ‘˜è¦ã€ç”Ÿæˆåšå®¢ã€‚ \n çŸ¥è¯†å¯¼å…¥å¯¼å‡ºã€Web çŸ¥è¯†æŠ½å–é›†æˆã€‚ \n èµ„æºç®¡ç†ã€å…¬å…±+ä¸ªäºº+é¢†åŸŸçŸ¥è¯†å›¾è°±ã€‚ \n æ”¶è—è®¢é˜…è¯„è®ºåˆ†äº«ã€è¯é¢˜è¯¾ç¨‹å°ç»„ç­çº§åœˆå­ã€‚ \n é¡¹ç›®äº‹åŠ¡çš„PDCAã€GTDï¼Œæ—¥å†æ—¥ç¨‹å®‰æ’æé†’ã€‚ \n å³æ—¶é€šä¿¡ã€å®æ—¶ååŒã€é¡¹ç›®åˆä½œã€ç§¯åˆ†ç³»ç»Ÿã€‚ \n ä¸ªæ€§åŒ–è‡ªå­¦ä¹ èŠå¤©æœºå™¨äººã€è™šæ‹Ÿå½¢è±¡ã€è¯­éŸ³è¯†åˆ«ç”Ÿæˆã€äº‹åŠ¡ä»£ç†ã€ä¸»åŠ¨æ¨èæé†’å¼•å¯¼è¾…åŠ©ã€‚ \n è‡ªç„¶è¯­è¨€äº¤äº’ã€è¯­ä¹‰åŒ–ã€å“åº”å¼ç”Ÿæˆå¼ã€æ–‡æœ¬åŒ–ã€å¯è§†åŒ–ã€æè‡´æ²‰æµ¸ä½“éªŒã€‚ \n é«˜çº§åŠŸèƒ½ï¼šè‡ªå®šä¹‰é…ç½®ã€æ’ä»¶ã€å‘½ä»¤è¡Œã€é¢†åŸŸè¯­è¨€ã€‚ \n \n è¾…åŠ©æ‚¨è¿›è¡Œæç®€æ™ºèƒ½çŸ¥è¯†ç®¡ç†ï¼šçŸ¥è¯†å¯è§†åŒ–åˆ›ä½œå±•ç¤ºï¼Œç®€åŒ–ç»“æ„åŒ–å·²æœ‰çŸ¥è¯†èµ„æºï¼Œå»ºç«‹çŸ¥è¯†ä½“ç³»ã€‚æ·±å…¥æœ¬è´¨ç†è§£çŸ¥è¯†ã€æ•´ä½“é«˜æ•ˆåˆä½œå­¦ä¹ ã€‚ä¸ªäººäº‹åŠ¡çš„ç®¡ç†ã€åŸåˆ™æ–¹æ³•è®ºä¹ æƒ¯çš„å…»æˆã€‚è¯­ä¹‰è®¡ç®—ï¼Œè¾…åŠ©æ¨ç†ã€ä»¿çœŸã€é¢„æµ‹ã€å†³ç­–ã€‚èŠå¤©è§£é—·å¯å‘ã€‚ \n å¾ˆé«˜å…´æ‚¨ ä¸‹è½½è¯•ç”¨ å¹¶ å›é¦ˆä½¿ç”¨æƒ…å†µ ã€‚ \n \n éšç€å¼€å‘è¿›å±•ï¼Œä¼šåŠæ—¶åˆ—å‡ºæœ€æ–°ç‰¹æ€§ã€æ–°åŠŸèƒ½åŠæ”¹è¿›æƒ…å†µã€‚æŸ¥çœ‹ v0.1 -&gt; v1.0 å‡çº§ä¿¡æ¯ ï¼Œè·å–æ›´å¤šäº§å“å‡çº§ä¿¡æ¯ ã€‚ \n ã€å‚ä¸è´¡çŒ®ã€‘ \n \n æˆ‘ä»¬æ˜¯ä¸€ä¸ªååŒå­¦ä¹ å‹ç»„ç»‡ï¼Œä»¥å¼€æºé¡¹ç›®ä¸ºä¸­å¿ƒï¼Œç»“åˆäº§å­¦ç ”ï¼Œç†è®ºæŠ€æœ¯çŸ¥è¯†èƒ½åŠ›å®è·µé—­ç¯æ­£åé¦ˆè¿­ä»£ç§¯ç´¯çš„è¿‡ç¨‹ï¼Œäººä¸äººä¸æœºå™¨æœºå™¨çš„åˆä½œå­¦ä¹ ï¼é¡¹ç›®å¤„äºåˆæœŸè§„åˆ’é˜¶æ®µï¼Œ æ¬¢è¿å„ä½æœ‰å¿—ä¹‹å£«çš„åŠ å…¥ï¼ \n \n åŸºäºå…±åŒä¿¡å¿µã€ç»Ÿä¸€åŸºç¡€ã€ååŒæœºåˆ¶ï¼Œè‡ªç”±åˆ†å·¥åˆä½œçš„å·¥ä½œç»„ï¼Œå¯é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªæ¨¡å—å‚ä¸åˆä½œå­¦ä¹ åŠå¼€å‘ï¼Œæ ¹æ® è§„åˆ™ è®°å½•è´¡çŒ®ç§¯åˆ†ï¼ŒæŒ‰è´¡çŒ®åˆ†é…å¥–åŠ±ï¼Œæœªæ¥è‹¥ç›ˆåˆ©å¯åˆ†çº¢ï¼Œæ¶Œç°é›†ä½“æ™ºæ…§ï¼æ¬¢è¿æ¯ä¸ªäººè´¡çŒ®åŠ›é‡ã€æ”¶è·ç§¯åˆ†æœ‹å‹çŸ¥è¯†å·¥å…·æŠ€æœ¯ã€‚ \n ã€å€¼å¾—åŠ å…¥ã€‘çŸ¥è¯†æ”¹å˜å‘½è¿ï¼Œåˆ›æ–°æ”¹å˜ä¸–ç•Œï¼æ”¹å˜è‡ªå·±ä»å¿ƒè€Œä¸ºï¼Œä¸å¿˜åˆå¿ƒæ–¹å¾—å§‹ç»ˆï¼ \n å¤šç§è´¡çŒ®æ–¹å¼ \n \n å¯å‚ä¸ç†è®ºç ”ç©¶ã€ä¸šåŠ¡å»ºæ¨¡ã€æŠ€æœ¯å¼€å‘ã€é¡¹ç›®ç®¡ç†ã€è¿è¥ã€æŠ•èµ„ã€è¯•ç”¨åˆ†äº«æ¨å¹¿ã€‚ \n æäº¤æˆ–æŠ•ç¥¨æ–°åŠŸèƒ½ç‰¹æ€§éœ€æ±‚ ProductPains \n å·¥å…·ä½¿ç”¨ æƒ…å†µåé¦ˆ \n \n æ¬¢è¿æäº¤ pull requests åŠ issue ã€‚ \n è‹¥è´¡çŒ®æºç è¯·é˜…è¯»éµå¾ª ç¼–ç¨‹é£æ ¼ åŠ è´¡çŒ®è¯´æ˜æ–‡æ¡£ ã€‚ \n è‡´è°¢ \n ã€æºè®¡åˆ’ã€‘KMAgent å½“å‰æ˜¯ä¸€ä¸ªå…¬å¼€ç¤¾ç¾¤å’Œå…è´¹è½¯ä»¶ï¼Œæ„Ÿè°¢æ‰€æœ‰ä¿ƒè¿›å…¶å‘å±•çš„ è´¡çŒ®è€… å’Œ [æ·±åº¦ç”¨æˆ·]( https://github.com/kmagent/ kmagent/fans.md)ã€‚ã€æèµ ã€‘å¦‚æœæ‚¨è®¤åŒæˆ‘ä»¬è¯·æ”¯æŒæˆ‘ä»¬å¿«é€ŸæŒç»­å‘å±•ã€‚ \n ä¸»è¦æ¨¡å— \n ã€æ ¸å¿ƒé‡ç‚¹ã€‘æ™ºèƒ½ä½“è¯­ä¹‰å…ƒæ ¸å¿ƒæŠ½è±¡ã€è®¤çŸ¥å»ºæ¨¡ã€çŸ¥è¯†å›¾è°±ã€æ™ºèƒ½çŸ¥è¯†ç®¡ç†GTDè§£å†³æ–¹æ¡ˆã€äº§å“è®¾è®¡å¼€å‘ï¼Œç¤¾ç¾¤è¿è¥ååŒç§¯ç´¯åˆ›æ–°ã€‚ï¼ˆæ™ºèƒ½åŸºç¡€-&gt;æ™ºèƒ½æ ¸-&gt;æ™ºèƒ½å—-&gt;æ™ºèƒ½ä½“ï¼‰ç¾¤ä½“æ™ºèƒ½-&gt;é€šç”¨æ™ºèƒ½ï¼Œæ¨¡æ‹Ÿ-&gt;è¶…è¶Šã€‚æ¨¡å—ï¼škm-thory km-engine km-onto km-agents km-sys km-uiã€km-graphã€‚ \n ã€é¢†åŸŸåŠæŠ€æœ¯ã€‘æ™ºèƒ½çŸ¥è¯†ç®¡ç†ï¼ˆé¢†åŸŸå»ºæ¨¡ï¼‰ã€æœºå™¨å­¦ä¹ ï¼ˆtensorflowï¼‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLTKã€hanlpï¼‰ã€çŸ¥è¯†å›¾è°±ï¼ˆå›¾æ•°æ®åº“neo4jåˆ†å¸ƒå¼å­˜å‚¨cephï¼‰ã€é¢†åŸŸè¯­è¨€ï¼ˆDSLï¼‰ã€è¯­ä¹‰ç½‘ï¼ˆOWLï¼‰ã€webçŸ¥è¯†å‘ç°ï¼ˆçˆ¬è™«ï¼‰ã€æ£€ç´¢ï¼ˆluceneï¼‰æ¨ç†æ¨èã€å¤šagenté›†ç¾¤æ™ºèƒ½ï¼ˆæ¶æ„ï¼‰ã€äººæœºäº¤äº’UIï¼ˆvue.jsã€bootstrapã€æ•°æ®å¯è§†åŒ–ï¼‰ã€Webç½‘ç«™ï¼ˆkeystoneï¼‰ã€æ¡Œé¢ï¼ˆwebkitã€electronï¼‰ã€ç§»åŠ¨ï¼ˆweexï¼‰ã€å¤§æ•°æ®ï¼ˆsparkï¼‰ã€è™šæ‹ŸåŒ–äº‘è®¡ç®—ï¼ˆMesosã€dockerã€Kubernetesï¼‰ã€å®‰å…¨ç½‘ç»œé€šä¿¡åŠ å¯†æƒé™è®¤è¯ï¼ˆopenSSLï¼‰ã€è½¯ä»¶å·¥ç¨‹ï¼ˆé¡¹ç›®å¼€å‘ç®¡ç†ï¼‰ã€åŒºå—é“¾ã€VRã€ä»£ç ç”Ÿæˆã€è®¤çŸ¥å¿ƒç†ã€å¤æ‚ç³»ç»Ÿã€çŸ¥è¯†å…±äº«åè®®äº§æƒã€ç¤¾ç¾¤ä½“éªŒç»æµã€‚ \n ã€å·¥ä½œåˆ†è§£ã€‘ å…³é”®åœ¨äº ï¼šç»Ÿä¸€è®¤è¯†ã€å·¥å…·æ”¯æŒã€æœ‰æ•ˆç§¯ç´¯å¯æŒç»­å‘å±•ã€‚ \n \n ä¸šåŠ¡å»ºæ¨¡ï¼ˆæ™ºèƒ½çŸ¥è¯†ç®¡ç†GTDç†è®ºä½“ç³»ï¼‰ï¼šæ ¸å¿ƒæŠ½è±¡æ¨¡å‹ï¼Œäººæ€§å»ºæ¨¡ã€‚ \n äº§å“è®¾è®¡ï¼ˆä¸ªäººæ™ºèƒ½åŠ©ç†ï¼‰ï¼šäº§å“è§„åˆ’ã€è™šæ‹Ÿå½¢è±¡UIè®¾è®¡ã€ç«å“åˆ†æã€‚ å‚è€ƒäº§å“ ï¼šprotegeã€vscodeã€quipã€knowledgebuilderã€metacademyã€wikiã€CSDNçŸ¥è¯†åº“ã€sketchboardã€feedlyã€onenoteç”»æ¿ã€foxmailã€äº¬ä¸œé˜…è¯»ã€qqéŸ³ä¹ã€NetLogoã€flyinglogicã€sourceinsightã€å¹•å¸ƒã€Ankiã€wolframalphaã€‚ \n æŠ€æœ¯æ¶æ„ï¼ˆé€šç”¨æ™ºèƒ½ç³»ç»Ÿï¼‰ï¼šåˆ†å¸ƒå¼è®¡ç®—å­˜å‚¨å¤šæ™ºèƒ½ä½“ååŒç³»ç»Ÿï¼šæ™®é€‚ç½‘æ ¼è¯­ä¹‰äººç±»è®¡ç®—ã€‚å…¨å¹³å°ã€å¾®æœåŠ¡ã€æ ¸å¿ƒç®—æ³•ã€æŠ€æœ¯é€‰å‹ã€æµ‹è¯•éƒ¨ç½²ã€‚C++ã€Pythonã€jsã€HTMLã€‚ \n å•†ä¸šè®¡åˆ’ï¼ˆSaaS è½¯ä»¶å³æœåŠ¡ï¼‰ï¼šä»¥è½¯ä»¶äº§å“ä¸ºä¸­å¿ƒçš„å¢å€¼æœåŠ¡ã€å“ç‰Œè¿è¥æ¨å¹¿è¥é”€ã€‚ \n é¡¹ç›®ç®¡ç†ï¼ˆå°ä»£ä»·è¾¾åˆ°ç›®çš„ï¼‰ï¼šæ•æ·è¿­ä»£ã€è¿‡ç¨‹æ”¹è¿›ã€é…ç½®ç®¡ç†ã€‚ \n ç¤¾ç¾¤å»ºè®¾ï¼ˆåˆ©ç›Šå…±åŒä½“è”ç›Ÿï¼‰ï¼šæ–‡åŒ–ç†å¿µé›†ä½“æ™ºæ…§ã€æ‰©å¤§å½±å“ã€‚ \n çŸ¥è¯†åˆ›ä½œï¼ˆçŸ¥è¯†ç®¡ç†ç­‰é¢†åŸŸçŸ¥è¯†ï¼‰ï¼šçŸ¥è¯†ç®¡',
      image:
        'https://opengraph.githubassets.com/935c4954d4a340aff679b550e201df566a4f53b442922a997e8a83570a564195/putaodoudou/kmagent',
      favicon: 'https://github.com/fluidicon.png',
    },
  ],
  costDollars: {
    total: 0.015,
    search: {
      neural: 0.005,
    },
    contents: {
      text: 0.01,
    },
  },
};
