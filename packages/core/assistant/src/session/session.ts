//
// Copyright 2025 DXOS.org
//

import { type AiError, AiLanguageModel, type AiResponse, type AiTool, AiToolkit } from '@effect/ai';
import { Chunk, type Context, Effect, Option, Queue, type Schema, Stream } from 'effect';

import {
  type AiInputPreprocessingError,
  AiParser,
  AiPreprocessor,
  type AiToolNotFoundError,
  ToolExecutionService,
  ToolResolverService,
  callTools,
  getToolCalls,
} from '@dxos/ai';
import { type Blueprint } from '@dxos/blueprints';
import { todo } from '@dxos/debug';
import { Obj } from '@dxos/echo';
import { log } from '@dxos/log';
import { type ContentBlock, DataType } from '@dxos/schema';
import { isNotFalsy } from '@dxos/util';

import { type AiAssistantError } from '../errors';

import { formatSystemPrompt, formatUserPrompt } from './format';

export type AiSessionOptions = {};

export type SessionRunParams<Tools extends AiTool.Any> = {
  prompt: string;
  system?: string;
  history?: DataType.Message[];
  objects?: Obj.Any[]; // TODO(burdon): Meta only (typename and id -- write to binder).
  blueprints?: Blueprint.Blueprint[];
  toolkit?: AiToolkit.AiToolkit<Tools>;
};

/**
 * Contains message history, tools, current context.
 * Current context means the state of the app, time of day, and other contextual information.
 * It makes requests to the model, its a state machine.
 * It keeps track of the current goal.
 * It manages the context window.
 * Tracks the success criteria of reaching the goal, exposing metrics (stretch).
 * Could be run locally in the app or remotely.
 * Could be personal or shared.
 */
export class AiSession {
  // TODO(burdon): Review this.
  private readonly _semaphore = Effect.runSync(Effect.makeSemaphore(1));

  /** Blocks streaming from the model during the session. */
  public readonly blockQueue = Effect.runSync(Queue.unbounded<Option.Option<ContentBlock.Any>>());

  /** Complete messages fired during the session, both from the model and from the user. */
  public readonly messageQueue = Effect.runSync(Queue.unbounded<DataType.Message>());

  /** Unparsed events from the underlying generation stream. */
  public readonly eventQueue = Effect.runSync(Queue.unbounded<AiResponse.Part>());

  /** Pending messages (incl. the current user request). */
  private _pending: DataType.Message[] = [];

  /** Prior history from queue. */
  private _history: DataType.Message[] = [];

  constructor(private readonly _options: AiSessionOptions = {}) {}

  /**
   * Runs the AI model loop interacting with tools and artifacts.
   * @returns The messages generated by the session, including the user's prompt.
   */
  // TODO(dmaretskyi): Toolkit context doesn't get added to the effect type.
  run = <Tools extends AiTool.Any>(
    params: SessionRunParams<Tools>,
  ): Effect.Effect<
    DataType.Message[],
    AiAssistantError | AiInputPreprocessingError | AiToolNotFoundError | AiError.AiError,
    AiLanguageModel.AiLanguageModel | ToolResolverService | ToolExecutionService | AiTool.ToHandler<Tools>
  > =>
    Effect.gen(this, function* () {
      // Create toolkit.
      const toolkit: AiToolkit.ToHandler<Tools> = yield* createToolkit(params);

      // Generate system prompt.
      // TODO(budon): Dynamically resolve template variables.
      const system = yield* formatSystemPrompt(params);
      console.log(system);

      // Generate user prompt.
      const promptMessages = yield* formatUserPrompt(params);
      yield* this.messageQueue.offer(promptMessages);

      this._history = [...(params.history ?? [])];
      this._pending = [promptMessages];

      // Potential tool-use loop.
      do {
        log.info('request', {
          prompt: promptMessages,
          system: { snippet: [system.slice(0, 32), '...', system.slice(-32)].join(''), length: system.length },
          pending: this._pending.length,
          history: this._history.length,
          objects: params.objects?.length ?? 0,
          toolkit: Object.values(toolkit.tools).map((tool: AiTool.Any) => tool.name),
        });

        // Generate the prompt and make request.
        const prompt = yield* AiPreprocessor.preprocessAiInput([...this._history, ...this._pending]);
        const blocks = yield* AiLanguageModel.streamText({
          prompt,
          system,
          toolkit,
          // TODO(burdon): Despite this flag, the model still calls tools.
          disableToolCallResolution: true,
        }).pipe(
          AiParser.parseResponse({
            onBlock: (block) => this.blockQueue.offer(Option.some(block)),
            onPart: (part) => this.eventQueue.offer(part),
          }),
          Stream.runCollect,
          Effect.map(Chunk.toArray),
        );

        // TODO(burdon): Comment.
        yield* this.blockQueue.offer(Option.none());

        // Create response message.
        const response = Obj.make(DataType.Message, {
          created: new Date().toISOString(),
          sender: { role: 'assistant' },
          blocks,
        });
        this._pending.push(response);
        yield* this.messageQueue.offer(response);

        // Parse response for tool calls.
        const toolCalls = getToolCalls(response);
        if (toolCalls.length === 0) {
          break;
        }

        // TODO(burdon): Error handling?
        const toolResults = yield* callTools(toolkit, toolCalls);
        const toolResultsMessage = Obj.make(DataType.Message, {
          created: new Date().toISOString(),
          sender: { role: 'user' },
          blocks: toolResults,
        });

        this._pending.push(toolResultsMessage);
        yield* this.messageQueue.offer(toolResultsMessage);
      } while (true);

      // The queues shutting down signals to stream consumers that the session has completed and no more messages are coming.
      yield* Queue.shutdown(this.eventQueue);
      yield* Queue.shutdown(this.blockQueue);
      yield* Queue.shutdown(this.messageQueue);

      log.info('done', { pending: this._pending.length });
      return this._pending;
    }).pipe(this._semaphore.withPermits(1), Effect.withSpan('AiSession.run'));

  // TODO(burdon): Implement.
  async runStructured<S extends Schema.Schema.AnyNoContext>(
    _schema: S,
    _options: SessionRunParams<AiTool.Any>,
  ): Promise<Schema.Schema.Type<S>> {
    return todo();
    // const parser = structuredOutputParser(schema);
    // const result = await this.run({
    //   ...options,
    //   executableTools: [...(options.executableTools ?? []), parser.tool],
    // });
    // return parser.getResult(result);
  }
}

/**
 * Build a combined toolkit from the blueprint tools and the provided toolkit.
 */
const createToolkit = <Tools extends AiTool.Any>({
  toolkit,
  blueprints = [],
}: Pick<SessionRunParams<Tools>, 'toolkit' | 'blueprints'>) =>
  Effect.gen(function* () {
    const blueprintToolkit = yield* ToolResolverService.resolveToolkit(blueprints.flatMap(({ tools }) => tools));
    const blueprintToolkitHandler: Context.Context<AiTool.ToHandler<AiTool.Any>> = yield* blueprintToolkit.toContext(
      ToolExecutionService.handlersFor(blueprintToolkit),
    );

    return yield* AiToolkit.merge(...[toolkit, blueprintToolkit].filter(isNotFalsy)).pipe(
      Effect.provide(blueprintToolkitHandler),
    ) as Effect.Effect<AiToolkit.ToHandler<any>, never, AiTool.ToHandler<Tools>>;
  });
