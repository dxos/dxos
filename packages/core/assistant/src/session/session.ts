//
// Copyright 2025 DXOS.org
//

import { Chunk, Context, Effect, Option, Schema, Stream, Struct } from 'effect';

import {
  createTool,
  getToolCalls,
  runTool,
  structuredOutputParser,
  ToolResult,
  type AgentStatus,
  type AiInputPreprocessingError,
  type ExecutableTool,
  type GenerateRequest,
  type GenerationStream,
  type ToolId,
  type ToolResolver,
} from '@dxos/ai';
import { type ArtifactDefinition } from '@dxos/artifact';
import { Event } from '@dxos/async';
import { Obj } from '@dxos/echo';
import { ObjectVersion } from '@dxos/echo-db';
import { type ObjectId } from '@dxos/echo-schema';
import { log } from '@dxos/log';

import { AiParser, AiPreprocessor } from '@dxos/ai';
import { todo } from '@dxos/debug';
import { DataType, type ContentBlock } from '@dxos/schema';
import { AiLanguageModel, type AiError, type AiResponse, type AiTool, type AiToolkit } from '@effect/ai';
import { AiAssistantError } from '../errors';
import { invariant } from '@dxos/invariant';

/**
 * Contains message history, tools, current context.
 * Current context means the state of the app, time of day, and other contextual information.
 * It makes requests to the model, its a state machine.
 * It keeps track of the current goal.
 * It manages the context window.
 * Tracks the success criteria of reaching the goal, exposing metrics (stretch)
 * Could be run locally in the app or remotely.
 * Could be personal or shared.
 */

/**
 * Resolves artifact ids to their versions.
 * Used to give the model a sense of the changes to the artifacts made by users during the conversation.
 * The artifacts versions are pinned in the history, and whenever the artifact changes in-between assistant's steps,
 * a diff is inserted into the conversation.
 *
 * Can be optionally provided to the session run call.
 */
// TODO(dmaretskyi): Convert to Context.Reference
export class ArtifactDiffResolver extends Context.Tag('ArtifactDiffResolver')<
  ArtifactDiffResolver,
  ArtifactDiffResolver.Service
>() {}

export namespace ArtifactDiffResolver {
  export type Service = {
    resolve: (artifacts: { id: ObjectId; lastVersion: ObjectVersion }[]) => Promise<
      Map<
        ObjectId,
        {
          version: ObjectVersion;
          diff?: string;
        }
      >
    >;
  };
}

export type SessionRunOptions<Tools extends AiTool.Any> = {
  prompt: string;
  history: DataType.Message[];

  // TODO(dmaretskyi): Blueprints.

  toolkit?: AiToolkit.ToHandler<Tools>;
  systemPrompt?: string;
};

export type AiSessionOptions = {};

export class AISession {
  /** Pending messages (incl. the current user request). */
  private _pending: DataType.Message[] = [];

  /** Current streaming response. */
  private _stream: GenerationStream | undefined;

  /** Prior history from queue. */
  private _history: DataType.Message[] = [];

  /**
   * New message.
   */
  public readonly message = new Event<DataType.Message>();

  /**
   * Complete block added to Message.
   */
  public readonly block = new Event<ContentBlock.Any>();

  /**
   * Update partial block (while streaming).
   */
  public readonly update = new Event<ContentBlock.Any>();

  /**
   * Unparsed events from the underlying generation stream.
   */
  public readonly streamEvent = new Event<AiResponse.Part>();

  /**
   * User prompt or tool result.
   */
  public readonly userMessage = new Event<DataType.Message>();

  /**
   * Agent self-reporting its status.
   * Triggered by the model.
   */
  public readonly statusReport = new Event<AgentStatus>();

  /**
   * Emits when the session is done.
   */
  public readonly done = new Event<void>();

  private readonly _semaphore = Effect.runSync(Effect.makeSemaphore(1));

  constructor(private readonly _options: AiSessionOptions = {}) {}

  /**
   * Runs the AI model loop interacting with tools and artifacts.
   * @param options - The session options.
   * @returns The messages generated by the session, including the user's prompt.
   */
  // TODO(dmaretskyi): Toolkit context doesn't get added to the effect type.
  run = <Tools extends AiTool.Any>(
    options: SessionRunOptions<Tools>,
  ): Effect.Effect<
    DataType.Message[],
    AiAssistantError | AiInputPreprocessingError | AiError.AiError,
    AiLanguageModel.AiLanguageModel | AiTool.Context<Tools>
  > =>
    Effect.gen(this, function* () {
      this._history = [...options.history];

      const promptMessages = yield* this._formatUserPrompt(options.prompt, options.history);
      this._pending = [promptMessages];
      this.userMessage.emit(promptMessages);

      do {
        log('request', {
          pending: this._pending.length,
          history: this._history.length,
          tools: (Object.values(options.toolkit?.tools ?? {}) as AiTool.Any[]).map((tool: AiTool.Any) => tool.name),
        });

        const prompt = yield* AiPreprocessor.preprocessAiInput([...this._history, ...this._pending]);

        // Open request stream.
        // this._stream = await options.client.execStream({
        //   ...(options.generationOptions ?? {}),
        //   // TODO(burdon): Rename messages or separate history/message.
        //   history: [...this._history, ...this._pending],
        //   tools,
        //   systemPrompt:
        //     options.systemPrompt ??
        //     createBaseInstructions({
        //       availableArtifacts: [...requiredArtifactIds],
        //       operationModel: this._options.operationModel,
        //     }),
        // });
        const blocks = yield* AiLanguageModel.streamText({
          prompt,
          toolkit: options.toolkit,
          system: 'You are a helpful assistant.',
          disableToolCallResolution: true,
        }).pipe(AiParser.parseGptStream(), Stream.runCollect, Effect.map(Chunk.toArray));
        const response = Obj.make(DataType.Message, {
          sender: {
            role: 'assistant',
          },
          blocks,
          created: new Date().toISOString(),
        });
        this._pending.push(response);

        const toolCalls = getToolCalls(response);
        if (toolCalls.length === 0) {
          break;
        }

        const toolkit = options.toolkit;
        if (!toolkit) {
          return yield* Effect.dieMessage('Toolkit is required to run the session.');
        }
        invariant(
          !Effect.isEffect(toolkit),
          'Toolkit must be resolved to a handler before being passed to the session.',
        );

        const toolResults: ContentBlock.ToolResult[] = yield* Effect.forEach(toolCalls, (toolCall) =>
          runTool(toolkit, toolCall),
        );
        this._pending.push(
          Obj.make(DataType.Message, {
            sender: {
              role: 'user',
            },
            blocks: toolResults,
            created: new Date().toISOString(),
          }),
        );
      } while (true);

      return this._pending;
    }).pipe(this._semaphore.withPermits(1), Effect.withSpan('AISession.run'));

  async runStructured<S extends Schema.Schema.AnyNoContext>(
    schema: S,
    options: SessionRunOptions<AiTool.Any>,
  ): Promise<Schema.Schema.Type<S>> {
    return todo();
    // const parser = structuredOutputParser(schema);
    // const result = await this.run({
    //   ...options,
    //   executableTools: [...(options.executableTools ?? []), parser.tool],
    // });
    // return parser.getResult(result);
  }

  private _formatUserPrompt = (prompt: string, history: DataType.Message[]) =>
    Effect.gen(function* () {
      const prelude: ContentBlock.Any[] = [];

      // TODO(dmaretskyi): Evaluate other approaches as `serviceOption` isn't represented in the type system.
      const artifactDiffResolver = yield* Effect.serviceOption(ArtifactDiffResolver);
      if (Option.isSome(artifactDiffResolver)) {
        const versions = gatherObjectVersions(history);

        const artifactDiff = yield* Effect.tryPromise({
          try: () =>
            artifactDiffResolver.value.resolve(
              [...versions.entries()].map(([id, version]) => ({ id, lastVersion: version })),
            ),
          catch: AiAssistantError.wrap('Artifact diff resolution error'),
        });

        log.info('vision', {
          artifactDiff,
          versions,
        });

        for (const [id, { version }] of [...artifactDiff.entries()]) {
          if (ObjectVersion.equals(version, versions.get(id)!)) {
            artifactDiff.delete(id);
            continue;
          }

          prelude.push({ _tag: 'artifactPin', objectId: id, version });
        }
        if (artifactDiff.size > 0) {
          prelude.push(createArtifactUpdateBlock(artifactDiff));
        }
      }

      return Obj.make(DataType.Message, {
        sender: { role: 'user' },
        blocks: [...prelude, { _tag: 'text', text: prompt }],
        created: new Date().toUTCString(),
      });
    });

  abort(): void {
    this._stream?.abort();
  }
}

const gatherObjectVersions = (messages: DataType.Message[]): Map<ObjectId, ObjectVersion> => {
  const artifactIds = new Map<ObjectId, ObjectVersion>();
  for (const message of messages) {
    for (const block of message.blocks) {
      if (block._tag === 'artifactPin') {
        artifactIds.set(block.objectId, block.version as ObjectVersion);
      }
    }
  }

  return artifactIds;
};

const createArtifactUpdateBlock = (
  artifactDiff: Map<ObjectId, { version: ObjectVersion; diff?: string }>,
): ContentBlock.Any => {
  return {
    _tag: 'text',
    // TODO(dmaretskyi): Does this need to be a special content-block?
    disposition: 'artifact-update',
    text: `
      The following artifacts have been updated since the last message:
      ${[...artifactDiff.entries()]
        .map(([id, { diff }]) => `<changed-artifact id="${id}">${diff ? `\n${diff}` : ''}</changed-artifact>`)
        .join('\n')}
    `,
  };
};
