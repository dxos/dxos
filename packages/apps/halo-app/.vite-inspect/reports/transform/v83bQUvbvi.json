{"resolvedId":"/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/lib/_stream_readable.js","transforms":[{"name":"vite:load-fallback","result":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n'use strict';\n\nmodule.exports = Readable;\n/*<replacement>*/\n\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n/*<replacement>*/\n\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function EElistenerCount(emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\n\n\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n\nvar Buffer = require('buffer').Buffer;\n\nvar OurUint8Array = global.Uint8Array || function () {};\n\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\n\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n/*<replacement>*/\n\n\nvar debugUtil = require('util');\n\nvar debug;\n\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function debug() {};\n}\n/*</replacement>*/\n\n\nvar BufferList = require('./internal/streams/buffer_list');\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nvar _require = require('./internal/streams/state'),\n    getHighWaterMark = _require.getHighWaterMark;\n\nvar _require$codes = require('../errors').codes,\n    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n    ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_STREAM_UNSHIFT_AFTER_END_EVENT = _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT; // Lazy loaded to improve the startup performance.\n\n\nvar StringDecoder;\nvar createReadableStreamAsyncIterator;\nvar from;\n\nrequire('inherits')(Readable, Stream);\n\nvar errorOrDestroy = destroyImpl.errorOrDestroy;\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn); // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (Array.isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream, isDuplex) {\n  Duplex = Duplex || require('./_stream_duplex');\n  options = options || {}; // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode; // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n\n  this.highWaterMark = getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex); // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false; // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n\n  this.sync = true; // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n  this.paused = true; // Should close be emitted on destroy. Defaults to true.\n\n  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'end' (and potentially 'finish')\n\n  this.autoDestroy = !!options.autoDestroy; // has it been destroyed\n\n  this.destroyed = false; // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n\n  this.defaultEncoding = options.defaultEncoding || 'utf8'; // the number of writers that are awaiting a drain event in .pipe()s\n\n  this.awaitDrain = 0; // if true, a maybeReadMore has been scheduled\n\n  this.readingMore = false;\n  this.decoder = null;\n  this.encoding = null;\n\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n  if (!(this instanceof Readable)) return new Readable(options); // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the ReadableState constructor, at least with V8 6.5\n\n  var isDuplex = this instanceof Duplex;\n  this._readableState = new ReadableState(options, this, isDuplex); // legacy\n\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined) {\n      return false;\n    }\n\n    return this._readableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._readableState.destroyed = value;\n  }\n});\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\n\nReadable.prototype._destroy = function (err, cb) {\n  cb(err);\n}; // Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\n\n\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n}; // Unshift should *always* be something directly out of read()\n\n\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  debug('readableAddChunk', chunk);\n  var state = stream._readableState;\n\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n\n    if (er) {\n      errorOrDestroy(stream, er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF());\n      } else if (state.destroyed) {\n        return false;\n      } else {\n        state.reading = false;\n\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n      maybeReadMore(stream, state);\n    }\n  } // We can push more data if we are below the highWaterMark.\n  // Also, if we have no data yet, we can stand some more bytes.\n  // This is to work around cases where hwm=0, such as the repl.\n\n\n  return !state.ended && (state.length < state.highWaterMark || state.length === 0);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    state.awaitDrain = 0;\n    stream.emit('data', chunk);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n    if (state.needReadable) emitReadable(stream);\n  }\n\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);\n  }\n\n  return er;\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n}; // backwards compatibility.\n\n\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  var decoder = new StringDecoder(enc);\n  this._readableState.decoder = decoder; // If setEncoding(null), decoder.encoding equals utf8\n\n  this._readableState.encoding = this._readableState.decoder.encoding; // Iterate over current buffer to convert already stored Buffers:\n\n  var p = this._readableState.buffer.head;\n  var content = '';\n\n  while (p !== null) {\n    content += decoder.write(p.data);\n    p = p.next;\n  }\n\n  this._readableState.buffer.clear();\n\n  if (content !== '') this._readableState.buffer.push(content);\n  this._readableState.length = content.length;\n  return this;\n}; // Don't raise the hwm > 1GB\n\n\nvar MAX_HWM = 0x40000000;\n\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    // TODO(ronag): Throw ERR_VALUE_OUT_OF_RANGE.\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n\n  return n;\n} // This function is designed to be inlinable, so please take care when making\n// changes to the function body.\n\n\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  } // If we're asking for more than the current hwm, then raise the hwm.\n\n\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n; // Don't have enough\n\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n\n  return state.length;\n} // you can override either this method, or the async _read(n) below.\n\n\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n  if (n !== 0) state.emittedReadable = false; // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n\n  if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state); // if we've ended, and we're now clear, then finish it up.\n\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  } // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n  // if we need a readable event, then we need to do some reading.\n\n\n  var doRead = state.needReadable;\n  debug('need readable', doRead); // if we currently have less than the highWaterMark, then also read some\n\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  } // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n\n\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true; // if the length is currently zero, then we *need* a readable event.\n\n    if (state.length === 0) state.needReadable = true; // call internal read method\n\n    this._read(state.highWaterMark);\n\n    state.sync = false; // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = state.length <= state.highWaterMark;\n    n = 0;\n  } else {\n    state.length -= n;\n    state.awaitDrain = 0;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true; // If we tried to read() past the EOF, then emit end on the next tick.\n\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  debug('onEofChunk');\n  if (state.ended) return;\n\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n\n  state.ended = true;\n\n  if (state.sync) {\n    // if we are sync, wait until next tick to emit the data.\n    // Otherwise we risk emitting data in the flow()\n    // the readable code triggers during a read() call\n    emitReadable(stream);\n  } else {\n    // emit 'readable' now to make sure it gets picked up.\n    state.needReadable = false;\n\n    if (!state.emittedReadable) {\n      state.emittedReadable = true;\n      emitReadable_(stream);\n    }\n  }\n} // Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\n\n\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  debug('emitReadable', state.needReadable, state.emittedReadable);\n  state.needReadable = false;\n\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    process.nextTick(emitReadable_, stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  var state = stream._readableState;\n  debug('emitReadable_', state.destroyed, state.length, state.ended);\n\n  if (!state.destroyed && (state.length || state.ended)) {\n    stream.emit('readable');\n    state.emittedReadable = false;\n  } // The stream needs another readable event if\n  // 1. It is not flowing, as the flow mechanism will take\n  //    care of it.\n  // 2. It is not ended.\n  // 3. It is below the highWaterMark, so we can schedule\n  //    another readable later.\n\n\n  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;\n  flow(stream);\n} // at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\n\n\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    process.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  // Attempt to read more data if we should.\n  //\n  // The conditions for reading more data are (one of):\n  // - Not enough data buffered (state.length < state.highWaterMark). The loop\n  //   is responsible for filling the buffer with enough data if such data\n  //   is available. If highWaterMark is 0 and we are not in the flowing mode\n  //   we should _not_ attempt to buffer any extra data. We'll get more data\n  //   when the stream consumer calls read() instead.\n  // - No data in the buffer, and the stream is in flowing mode. In this mode\n  //   the loop below is responsible for ensuring read() is called. Failing to\n  //   call read here would abort the flow and there's no other mechanism for\n  //   continuing the flow if the stream consumer has just subscribed to the\n  //   'data' event.\n  //\n  // In addition to the above conditions to keep reading data, the following\n  // conditions prevent the data from being read:\n  // - The stream has ended (state.ended).\n  // - There is already a pending 'read' operation (state.reading). This is a\n  //   case where the the stream has called the implementation defined _read()\n  //   method, but they are processing the call asynchronously and have _not_\n  //   called push() with new data. In this case we skip performing more\n  //   read()s. The execution ends in this method again after the _read() ends\n  //   up calling push() with more data.\n  while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {\n    var len = state.length;\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length) // didn't get any data, stop spinning.\n      break;\n  }\n\n  state.readingMore = false;\n} // abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\n\n\nReadable.prototype._read = function (n) {\n  errorOrDestroy(this, new ERR_METHOD_NOT_IMPLEMENTED('_read()'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) process.nextTick(endFn);else src.once('end', endFn);\n  dest.on('unpipe', onunpipe);\n\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  } // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n\n\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n  var cleanedUp = false;\n\n  function cleanup() {\n    debug('cleanup'); // cleanup event handlers once the pipe is broken\n\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n    cleanedUp = true; // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  src.on('data', ondata);\n\n  function ondata(chunk) {\n    debug('ondata');\n    var ret = dest.write(chunk);\n    debug('dest.write', ret);\n\n    if (ret === false) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', state.awaitDrain);\n        state.awaitDrain++;\n      }\n\n      src.pause();\n    }\n  } // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n\n\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) errorOrDestroy(dest, er);\n  } // Make sure our error handler is attached before userland ones.\n\n\n  prependListener(dest, 'error', onerror); // Both close and finish should trigger unpipe, but only once.\n\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n\n  dest.once('close', onclose);\n\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  } // tell the dest that it's being piped to\n\n\n  dest.emit('pipe', src); // start the flow if it hasn't been started already.\n\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function pipeOnDrainFunctionResult() {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = {\n    hasUnpiped: false\n  }; // if we're not piping anywhere, then do nothing.\n\n  if (state.pipesCount === 0) return this; // just one destination.  most common case.\n\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n    if (!dest) dest = state.pipes; // got a match.\n\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  } // slow case. multiple pipe destinations.\n\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, {\n        hasUnpiped: false\n      });\n    }\n\n    return this;\n  } // try to find the right one.\n\n\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n  dest.emit('unpipe', this, unpipeInfo);\n  return this;\n}; // set up data events if they are asked for\n// Ensure readable listeners eventually get something\n\n\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n  var state = this._readableState;\n\n  if (ev === 'data') {\n    // update readableListening so that resume() may be a no-op\n    // a few lines down. This is needed to support once('readable').\n    state.readableListening = this.listenerCount('readable') > 0; // Try start flowing on next tick if stream isn't explicitly paused\n\n    if (state.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.flowing = false;\n      state.emittedReadable = false;\n      debug('on readable', state.length, state.reading);\n\n      if (state.length) {\n        emitReadable(this);\n      } else if (!state.reading) {\n        process.nextTick(nReadingNextTick, this);\n      }\n    }\n  }\n\n  return res;\n};\n\nReadable.prototype.addListener = Readable.prototype.on;\n\nReadable.prototype.removeListener = function (ev, fn) {\n  var res = Stream.prototype.removeListener.call(this, ev, fn);\n\n  if (ev === 'readable') {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n\n  return res;\n};\n\nReadable.prototype.removeAllListeners = function (ev) {\n  var res = Stream.prototype.removeAllListeners.apply(this, arguments);\n\n  if (ev === 'readable' || ev === undefined) {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n\n  return res;\n};\n\nfunction updateReadableListening(self) {\n  var state = self._readableState;\n  state.readableListening = self.listenerCount('readable') > 0;\n\n  if (state.resumeScheduled && !state.paused) {\n    // flowing needs to be set to true now, otherwise\n    // the upcoming resume will not flow.\n    state.flowing = true; // crude way to check if we should resume\n  } else if (self.listenerCount('data') > 0) {\n    self.resume();\n  }\n}\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n} // pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\n\n\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n\n  if (!state.flowing) {\n    debug('resume'); // we flow only if there is no one listening\n    // for readable, but we still have to call\n    // resume()\n\n    state.flowing = !state.readableListening;\n    resume(this, state);\n  }\n\n  state.paused = false;\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    process.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  debug('resume', state.reading);\n\n  if (!state.reading) {\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n\n  if (this._readableState.flowing !== false) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n\n  this._readableState.paused = true;\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n\n  while (state.flowing && stream.read() !== null) {\n    ;\n  }\n} // wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\n\n\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n  stream.on('end', function () {\n    debug('wrapped end');\n\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk); // don't skip over falsy values in objectMode\n\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  }); // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function methodWrap(method) {\n        return function methodWrapReturnFunction() {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  } // proxy certain important events.\n\n\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  } // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n\n\n  this._read = function (n) {\n    debug('wrapped _read', n);\n\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nif (typeof Symbol === 'function') {\n  Readable.prototype[Symbol.asyncIterator] = function () {\n    if (createReadableStreamAsyncIterator === undefined) {\n      createReadableStreamAsyncIterator = require('./internal/streams/async_iterator');\n    }\n\n    return createReadableStreamAsyncIterator(this);\n  };\n}\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.highWaterMark;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState && this._readableState.buffer;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableFlowing', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.flowing;\n  },\n  set: function set(state) {\n    if (this._readableState) {\n      this._readableState.flowing = state;\n    }\n  }\n}); // exposed for testing purposes only.\n\nReadable._fromList = fromList;\nObject.defineProperty(Readable.prototype, 'readableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.length;\n  }\n}); // Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\n\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.first();else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = state.buffer.consume(n, state.decoder);\n  }\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n  debug('endReadable', state.endEmitted);\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    process.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  debug('endReadableNT', state.endEmitted, state.length); // Check that we didn't get one last unshift.\n\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n\n    if (state.autoDestroy) {\n      // In case of duplex streams we need a way to detect\n      // if the writable side is ready for autoDestroy as well\n      var wState = stream._writableState;\n\n      if (!wState || wState.autoDestroy && wState.finished) {\n        stream.destroy();\n      }\n    }\n  }\n}\n\nif (typeof Symbol === 'function') {\n  Readable.from = function (iterable, opts) {\n    if (from === undefined) {\n      from = require('./internal/streams/from');\n    }\n\n    return from(Readable, iterable, opts);\n  };\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n\n  return -1;\n}","start":1670465469239,"end":1670465469391},{"name":"vite:react-babel","result":"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n'use strict';\n\nmodule.exports = Readable;\n/*<replacement>*/\n\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n/*<replacement>*/\n\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function EElistenerCount(emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\n\n\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n\nvar Buffer = require('buffer').Buffer;\n\nvar OurUint8Array = global.Uint8Array || function () {};\n\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\n\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n/*<replacement>*/\n\n\nvar debugUtil = require('util');\n\nvar debug;\n\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function debug() {};\n}\n/*</replacement>*/\n\n\nvar BufferList = require('./internal/streams/buffer_list');\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nvar _require = require('./internal/streams/state'),\n    getHighWaterMark = _require.getHighWaterMark;\n\nvar _require$codes = require('../errors').codes,\n    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n    ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_STREAM_UNSHIFT_AFTER_END_EVENT = _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT; // Lazy loaded to improve the startup performance.\n\n\nvar StringDecoder;\nvar createReadableStreamAsyncIterator;\nvar from;\n\nrequire('inherits')(Readable, Stream);\n\nvar errorOrDestroy = destroyImpl.errorOrDestroy;\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn); // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (Array.isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream, isDuplex) {\n  Duplex = Duplex || require('./_stream_duplex');\n  options = options || {}; // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode; // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n\n  this.highWaterMark = getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex); // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false; // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n\n  this.sync = true; // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n  this.paused = true; // Should close be emitted on destroy. Defaults to true.\n\n  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'end' (and potentially 'finish')\n\n  this.autoDestroy = !!options.autoDestroy; // has it been destroyed\n\n  this.destroyed = false; // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n\n  this.defaultEncoding = options.defaultEncoding || 'utf8'; // the number of writers that are awaiting a drain event in .pipe()s\n\n  this.awaitDrain = 0; // if true, a maybeReadMore has been scheduled\n\n  this.readingMore = false;\n  this.decoder = null;\n  this.encoding = null;\n\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n  if (!(this instanceof Readable)) return new Readable(options); // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the ReadableState constructor, at least with V8 6.5\n\n  var isDuplex = this instanceof Duplex;\n  this._readableState = new ReadableState(options, this, isDuplex); // legacy\n\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined) {\n      return false;\n    }\n\n    return this._readableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._readableState.destroyed = value;\n  }\n});\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\n\nReadable.prototype._destroy = function (err, cb) {\n  cb(err);\n}; // Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\n\n\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n}; // Unshift should *always* be something directly out of read()\n\n\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  debug('readableAddChunk', chunk);\n  var state = stream._readableState;\n\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n\n    if (er) {\n      errorOrDestroy(stream, er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF());\n      } else if (state.destroyed) {\n        return false;\n      } else {\n        state.reading = false;\n\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n      maybeReadMore(stream, state);\n    }\n  } // We can push more data if we are below the highWaterMark.\n  // Also, if we have no data yet, we can stand some more bytes.\n  // This is to work around cases where hwm=0, such as the repl.\n\n\n  return !state.ended && (state.length < state.highWaterMark || state.length === 0);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    state.awaitDrain = 0;\n    stream.emit('data', chunk);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n    if (state.needReadable) emitReadable(stream);\n  }\n\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);\n  }\n\n  return er;\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n}; // backwards compatibility.\n\n\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  var decoder = new StringDecoder(enc);\n  this._readableState.decoder = decoder; // If setEncoding(null), decoder.encoding equals utf8\n\n  this._readableState.encoding = this._readableState.decoder.encoding; // Iterate over current buffer to convert already stored Buffers:\n\n  var p = this._readableState.buffer.head;\n  var content = '';\n\n  while (p !== null) {\n    content += decoder.write(p.data);\n    p = p.next;\n  }\n\n  this._readableState.buffer.clear();\n\n  if (content !== '') this._readableState.buffer.push(content);\n  this._readableState.length = content.length;\n  return this;\n}; // Don't raise the hwm > 1GB\n\n\nvar MAX_HWM = 0x40000000;\n\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    // TODO(ronag): Throw ERR_VALUE_OUT_OF_RANGE.\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n\n  return n;\n} // This function is designed to be inlinable, so please take care when making\n// changes to the function body.\n\n\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  } // If we're asking for more than the current hwm, then raise the hwm.\n\n\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n; // Don't have enough\n\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n\n  return state.length;\n} // you can override either this method, or the async _read(n) below.\n\n\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n  if (n !== 0) state.emittedReadable = false; // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n\n  if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state); // if we've ended, and we're now clear, then finish it up.\n\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  } // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n  // if we need a readable event, then we need to do some reading.\n\n\n  var doRead = state.needReadable;\n  debug('need readable', doRead); // if we currently have less than the highWaterMark, then also read some\n\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  } // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n\n\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true; // if the length is currently zero, then we *need* a readable event.\n\n    if (state.length === 0) state.needReadable = true; // call internal read method\n\n    this._read(state.highWaterMark);\n\n    state.sync = false; // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = state.length <= state.highWaterMark;\n    n = 0;\n  } else {\n    state.length -= n;\n    state.awaitDrain = 0;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true; // If we tried to read() past the EOF, then emit end on the next tick.\n\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  debug('onEofChunk');\n  if (state.ended) return;\n\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n\n  state.ended = true;\n\n  if (state.sync) {\n    // if we are sync, wait until next tick to emit the data.\n    // Otherwise we risk emitting data in the flow()\n    // the readable code triggers during a read() call\n    emitReadable(stream);\n  } else {\n    // emit 'readable' now to make sure it gets picked up.\n    state.needReadable = false;\n\n    if (!state.emittedReadable) {\n      state.emittedReadable = true;\n      emitReadable_(stream);\n    }\n  }\n} // Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\n\n\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  debug('emitReadable', state.needReadable, state.emittedReadable);\n  state.needReadable = false;\n\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    process.nextTick(emitReadable_, stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  var state = stream._readableState;\n  debug('emitReadable_', state.destroyed, state.length, state.ended);\n\n  if (!state.destroyed && (state.length || state.ended)) {\n    stream.emit('readable');\n    state.emittedReadable = false;\n  } // The stream needs another readable event if\n  // 1. It is not flowing, as the flow mechanism will take\n  //    care of it.\n  // 2. It is not ended.\n  // 3. It is below the highWaterMark, so we can schedule\n  //    another readable later.\n\n\n  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;\n  flow(stream);\n} // at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\n\n\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    process.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  // Attempt to read more data if we should.\n  //\n  // The conditions for reading more data are (one of):\n  // - Not enough data buffered (state.length < state.highWaterMark). The loop\n  //   is responsible for filling the buffer with enough data if such data\n  //   is available. If highWaterMark is 0 and we are not in the flowing mode\n  //   we should _not_ attempt to buffer any extra data. We'll get more data\n  //   when the stream consumer calls read() instead.\n  // - No data in the buffer, and the stream is in flowing mode. In this mode\n  //   the loop below is responsible for ensuring read() is called. Failing to\n  //   call read here would abort the flow and there's no other mechanism for\n  //   continuing the flow if the stream consumer has just subscribed to the\n  //   'data' event.\n  //\n  // In addition to the above conditions to keep reading data, the following\n  // conditions prevent the data from being read:\n  // - The stream has ended (state.ended).\n  // - There is already a pending 'read' operation (state.reading). This is a\n  //   case where the the stream has called the implementation defined _read()\n  //   method, but they are processing the call asynchronously and have _not_\n  //   called push() with new data. In this case we skip performing more\n  //   read()s. The execution ends in this method again after the _read() ends\n  //   up calling push() with more data.\n  while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {\n    var len = state.length;\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length) // didn't get any data, stop spinning.\n      break;\n  }\n\n  state.readingMore = false;\n} // abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\n\n\nReadable.prototype._read = function (n) {\n  errorOrDestroy(this, new ERR_METHOD_NOT_IMPLEMENTED('_read()'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) process.nextTick(endFn);else src.once('end', endFn);\n  dest.on('unpipe', onunpipe);\n\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  } // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n\n\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n  var cleanedUp = false;\n\n  function cleanup() {\n    debug('cleanup'); // cleanup event handlers once the pipe is broken\n\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n    cleanedUp = true; // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  src.on('data', ondata);\n\n  function ondata(chunk) {\n    debug('ondata');\n    var ret = dest.write(chunk);\n    debug('dest.write', ret);\n\n    if (ret === false) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', state.awaitDrain);\n        state.awaitDrain++;\n      }\n\n      src.pause();\n    }\n  } // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n\n\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) errorOrDestroy(dest, er);\n  } // Make sure our error handler is attached before userland ones.\n\n\n  prependListener(dest, 'error', onerror); // Both close and finish should trigger unpipe, but only once.\n\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n\n  dest.once('close', onclose);\n\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  } // tell the dest that it's being piped to\n\n\n  dest.emit('pipe', src); // start the flow if it hasn't been started already.\n\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function pipeOnDrainFunctionResult() {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = {\n    hasUnpiped: false\n  }; // if we're not piping anywhere, then do nothing.\n\n  if (state.pipesCount === 0) return this; // just one destination.  most common case.\n\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n    if (!dest) dest = state.pipes; // got a match.\n\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  } // slow case. multiple pipe destinations.\n\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, {\n        hasUnpiped: false\n      });\n    }\n\n    return this;\n  } // try to find the right one.\n\n\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n  dest.emit('unpipe', this, unpipeInfo);\n  return this;\n}; // set up data events if they are asked for\n// Ensure readable listeners eventually get something\n\n\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n  var state = this._readableState;\n\n  if (ev === 'data') {\n    // update readableListening so that resume() may be a no-op\n    // a few lines down. This is needed to support once('readable').\n    state.readableListening = this.listenerCount('readable') > 0; // Try start flowing on next tick if stream isn't explicitly paused\n\n    if (state.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.flowing = false;\n      state.emittedReadable = false;\n      debug('on readable', state.length, state.reading);\n\n      if (state.length) {\n        emitReadable(this);\n      } else if (!state.reading) {\n        process.nextTick(nReadingNextTick, this);\n      }\n    }\n  }\n\n  return res;\n};\n\nReadable.prototype.addListener = Readable.prototype.on;\n\nReadable.prototype.removeListener = function (ev, fn) {\n  var res = Stream.prototype.removeListener.call(this, ev, fn);\n\n  if (ev === 'readable') {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n\n  return res;\n};\n\nReadable.prototype.removeAllListeners = function (ev) {\n  var res = Stream.prototype.removeAllListeners.apply(this, arguments);\n\n  if (ev === 'readable' || ev === undefined) {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n\n  return res;\n};\n\nfunction updateReadableListening(self) {\n  var state = self._readableState;\n  state.readableListening = self.listenerCount('readable') > 0;\n\n  if (state.resumeScheduled && !state.paused) {\n    // flowing needs to be set to true now, otherwise\n    // the upcoming resume will not flow.\n    state.flowing = true; // crude way to check if we should resume\n  } else if (self.listenerCount('data') > 0) {\n    self.resume();\n  }\n}\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n} // pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\n\n\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n\n  if (!state.flowing) {\n    debug('resume'); // we flow only if there is no one listening\n    // for readable, but we still have to call\n    // resume()\n\n    state.flowing = !state.readableListening;\n    resume(this, state);\n  }\n\n  state.paused = false;\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    process.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  debug('resume', state.reading);\n\n  if (!state.reading) {\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n\n  if (this._readableState.flowing !== false) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n\n  this._readableState.paused = true;\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n\n  while (state.flowing && stream.read() !== null) {\n    ;\n  }\n} // wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\n\n\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n  stream.on('end', function () {\n    debug('wrapped end');\n\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk); // don't skip over falsy values in objectMode\n\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  }); // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function methodWrap(method) {\n        return function methodWrapReturnFunction() {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  } // proxy certain important events.\n\n\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  } // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n\n\n  this._read = function (n) {\n    debug('wrapped _read', n);\n\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nif (typeof Symbol === 'function') {\n  Readable.prototype[Symbol.asyncIterator] = function () {\n    if (createReadableStreamAsyncIterator === undefined) {\n      createReadableStreamAsyncIterator = require('./internal/streams/async_iterator');\n    }\n\n    return createReadableStreamAsyncIterator(this);\n  };\n}\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.highWaterMark;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState && this._readableState.buffer;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableFlowing', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.flowing;\n  },\n  set: function set(state) {\n    if (this._readableState) {\n      this._readableState.flowing = state;\n    }\n  }\n}); // exposed for testing purposes only.\n\nReadable._fromList = fromList;\nObject.defineProperty(Readable.prototype, 'readableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.length;\n  }\n}); // Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\n\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.first();else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = state.buffer.consume(n, state.decoder);\n  }\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n  debug('endReadable', state.endEmitted);\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    process.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  debug('endReadableNT', state.endEmitted, state.length); // Check that we didn't get one last unshift.\n\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n\n    if (state.autoDestroy) {\n      // In case of duplex streams we need a way to detect\n      // if the writable side is ready for autoDestroy as well\n      var wState = stream._writableState;\n\n      if (!wState || wState.autoDestroy && wState.finished) {\n        stream.destroy();\n      }\n    }\n  }\n}\n\nif (typeof Symbol === 'function') {\n  Readable.from = function (iterable, opts) {\n    if (from === undefined) {\n      from = require('./internal/streams/from');\n    }\n\n    return from(Readable, iterable, opts);\n  };\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n\n  return -1;\n}","start":1670465469391,"end":1670465469391,"order":"pre"},{"name":"commonjs","result":"import * as commonjsHelpers from \"\u0000commonjsHelpers.js\";\nimport require$$0 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/events@3.3.0/node_modules/events/events.js?commonjs-proxy\";\nimport require$$1 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/lib/internal/streams/stream-browser.js?commonjs-proxy\";\nimport require$$2 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js?commonjs-proxy\";\nimport require$$3 from \"\\u0000__vite-browser-external?commonjs-proxy\";\nimport { __require as require$$4 } from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/lib/internal/streams/buffer_list.js?commonjs-wrapped\";\nimport require$$5 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/lib/internal/streams/destroy.js?commonjs-proxy\";\nimport require$$6 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/lib/internal/streams/state.js?commonjs-proxy\";\nimport require$$7 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/errors-browser.js?commonjs-proxy\";\nimport require$$8 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/inherits@2.0.4/node_modules/inherits/inherits_browser.js?commonjs-proxy\";\nimport { __require as require$$9 } from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/lib/_stream_duplex.js?commonjs-wrapped\";\nimport require$$10 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/string_decoder@1.3.0/node_modules/string_decoder/lib/string_decoder.js?commonjs-proxy\";\nimport { __require as require$$11 } from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/lib/internal/streams/async_iterator.js?commonjs-wrapped\";\nimport { __require as require$$12 } from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/lib/internal/streams/from-browser.js?commonjs-wrapped\";\n\nvar _stream_readable;\nvar hasRequired_stream_readable;\n\nfunction require_stream_readable () {\n\tif (hasRequired_stream_readable) return _stream_readable;\n\thasRequired_stream_readable = 1;\n\t// Copyright Joyent, Inc. and other Node contributors.\n\t//\n\t// Permission is hereby granted, free of charge, to any person obtaining a\n\t// copy of this software and associated documentation files (the\n\t// \"Software\"), to deal in the Software without restriction, including\n\t// without limitation the rights to use, copy, modify, merge, publish,\n\t// distribute, sublicense, and/or sell copies of the Software, and to permit\n\t// persons to whom the Software is furnished to do so, subject to the\n\t// following conditions:\n\t//\n\t// The above copyright notice and this permission notice shall be included\n\t// in all copies or substantial portions of the Software.\n\t//\n\t// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n\t// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n\t// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n\t// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n\t// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n\t// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n\t// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\t'use strict';\n\n\t_stream_readable = Readable;\n\t/*<replacement>*/\n\n\tvar Duplex;\n\t/*</replacement>*/\n\n\tReadable.ReadableState = ReadableState;\n\t/*<replacement>*/\n\n\tvar EE = require$$0.EventEmitter;\n\n\tvar EElistenerCount = function EElistenerCount(emitter, type) {\n\t  return emitter.listeners(type).length;\n\t};\n\t/*</replacement>*/\n\n\t/*<replacement>*/\n\n\n\tvar Stream = require$$1;\n\t/*</replacement>*/\n\n\n\tvar Buffer = require$$2.Buffer;\n\n\tvar OurUint8Array = commonjsHelpers.commonjsGlobal.Uint8Array || function () {};\n\n\tfunction _uint8ArrayToBuffer(chunk) {\n\t  return Buffer.from(chunk);\n\t}\n\n\tfunction _isUint8Array(obj) {\n\t  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n\t}\n\t/*<replacement>*/\n\n\n\tvar debugUtil = require$$3;\n\n\tvar debug;\n\n\tif (debugUtil && debugUtil.debuglog) {\n\t  debug = debugUtil.debuglog('stream');\n\t} else {\n\t  debug = function debug() {};\n\t}\n\t/*</replacement>*/\n\n\n\tvar BufferList = require$$4();\n\n\tvar destroyImpl = require$$5;\n\n\tvar _require = require$$6,\n\t    getHighWaterMark = _require.getHighWaterMark;\n\n\tvar _require$codes = require$$7.codes,\n\t    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n\t    ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,\n\t    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n\t    ERR_STREAM_UNSHIFT_AFTER_END_EVENT = _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT; // Lazy loaded to improve the startup performance.\n\n\n\tvar StringDecoder;\n\tvar createReadableStreamAsyncIterator;\n\tvar from;\n\n\trequire$$8(Readable, Stream);\n\n\tvar errorOrDestroy = destroyImpl.errorOrDestroy;\n\tvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\n\tfunction prependListener(emitter, event, fn) {\n\t  // Sadly this is not cacheable as some libraries bundle their own\n\t  // event emitter implementation with them.\n\t  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn); // This is a hack to make sure that our error handler is attached before any\n\t  // userland ones.  NEVER DO THIS. This is here only because this code needs\n\t  // to continue to work with older versions of Node.js that do not include\n\t  // the prependListener() method. The goal is to eventually remove this hack.\n\n\t  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (Array.isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n\t}\n\n\tfunction ReadableState(options, stream, isDuplex) {\n\t  Duplex = Duplex || require$$9();\n\t  options = options || {}; // Duplex streams are both readable and writable, but share\n\t  // the same options object.\n\t  // However, some cases require setting options to different\n\t  // values for the readable and the writable sides of the duplex stream.\n\t  // These options can be provided separately as readableXXX and writableXXX.\n\n\t  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag. Used to make read(n) ignore n and to\n\t  // make all the buffer merging and length checks go away\n\n\t  this.objectMode = !!options.objectMode;\n\t  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode; // the point at which it stops calling _read() to fill the buffer\n\t  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n\n\t  this.highWaterMark = getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex); // A linked list is used to store data chunks instead of an array because the\n\t  // linked list can remove elements from the beginning faster than\n\t  // array.shift()\n\n\t  this.buffer = new BufferList();\n\t  this.length = 0;\n\t  this.pipes = null;\n\t  this.pipesCount = 0;\n\t  this.flowing = null;\n\t  this.ended = false;\n\t  this.endEmitted = false;\n\t  this.reading = false; // a flag to be able to tell if the event 'readable'/'data' is emitted\n\t  // immediately, or on a later tick.  We set this to true at first, because\n\t  // any actions that shouldn't happen until \"later\" should generally also\n\t  // not happen before the first read call.\n\n\t  this.sync = true; // whenever we return null, then we set a flag to say\n\t  // that we're awaiting a 'readable' event emission.\n\n\t  this.needReadable = false;\n\t  this.emittedReadable = false;\n\t  this.readableListening = false;\n\t  this.resumeScheduled = false;\n\t  this.paused = true; // Should close be emitted on destroy. Defaults to true.\n\n\t  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'end' (and potentially 'finish')\n\n\t  this.autoDestroy = !!options.autoDestroy; // has it been destroyed\n\n\t  this.destroyed = false; // Crypto is kind of old and crusty.  Historically, its default string\n\t  // encoding is 'binary' so we have to make this configurable.\n\t  // Everything else in the universe uses 'utf8', though.\n\n\t  this.defaultEncoding = options.defaultEncoding || 'utf8'; // the number of writers that are awaiting a drain event in .pipe()s\n\n\t  this.awaitDrain = 0; // if true, a maybeReadMore has been scheduled\n\n\t  this.readingMore = false;\n\t  this.decoder = null;\n\t  this.encoding = null;\n\n\t  if (options.encoding) {\n\t    if (!StringDecoder) StringDecoder = require$$10.StringDecoder;\n\t    this.decoder = new StringDecoder(options.encoding);\n\t    this.encoding = options.encoding;\n\t  }\n\t}\n\n\tfunction Readable(options) {\n\t  Duplex = Duplex || require$$9();\n\t  if (!(this instanceof Readable)) return new Readable(options); // Checking for a Stream.Duplex instance is faster here instead of inside\n\t  // the ReadableState constructor, at least with V8 6.5\n\n\t  var isDuplex = this instanceof Duplex;\n\t  this._readableState = new ReadableState(options, this, isDuplex); // legacy\n\n\t  this.readable = true;\n\n\t  if (options) {\n\t    if (typeof options.read === 'function') this._read = options.read;\n\t    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\t  }\n\n\t  Stream.call(this);\n\t}\n\n\tObject.defineProperty(Readable.prototype, 'destroyed', {\n\t  // making it explicit this property is not enumerable\n\t  // because otherwise some prototype manipulation in\n\t  // userland will fail\n\t  enumerable: false,\n\t  get: function get() {\n\t    if (this._readableState === undefined) {\n\t      return false;\n\t    }\n\n\t    return this._readableState.destroyed;\n\t  },\n\t  set: function set(value) {\n\t    // we ignore the value if the stream\n\t    // has not been initialized yet\n\t    if (!this._readableState) {\n\t      return;\n\t    } // backward compatibility, the user is explicitly\n\t    // managing destroyed\n\n\n\t    this._readableState.destroyed = value;\n\t  }\n\t});\n\tReadable.prototype.destroy = destroyImpl.destroy;\n\tReadable.prototype._undestroy = destroyImpl.undestroy;\n\n\tReadable.prototype._destroy = function (err, cb) {\n\t  cb(err);\n\t}; // Manually shove something into the read() buffer.\n\t// This returns true if the highWaterMark has not been hit yet,\n\t// similar to how Writable.write() returns true if you should\n\t// write() some more.\n\n\n\tReadable.prototype.push = function (chunk, encoding) {\n\t  var state = this._readableState;\n\t  var skipChunkCheck;\n\n\t  if (!state.objectMode) {\n\t    if (typeof chunk === 'string') {\n\t      encoding = encoding || state.defaultEncoding;\n\n\t      if (encoding !== state.encoding) {\n\t        chunk = Buffer.from(chunk, encoding);\n\t        encoding = '';\n\t      }\n\n\t      skipChunkCheck = true;\n\t    }\n\t  } else {\n\t    skipChunkCheck = true;\n\t  }\n\n\t  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n\t}; // Unshift should *always* be something directly out of read()\n\n\n\tReadable.prototype.unshift = function (chunk) {\n\t  return readableAddChunk(this, chunk, null, true, false);\n\t};\n\n\tfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n\t  debug('readableAddChunk', chunk);\n\t  var state = stream._readableState;\n\n\t  if (chunk === null) {\n\t    state.reading = false;\n\t    onEofChunk(stream, state);\n\t  } else {\n\t    var er;\n\t    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n\n\t    if (er) {\n\t      errorOrDestroy(stream, er);\n\t    } else if (state.objectMode || chunk && chunk.length > 0) {\n\t      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n\t        chunk = _uint8ArrayToBuffer(chunk);\n\t      }\n\n\t      if (addToFront) {\n\t        if (state.endEmitted) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());else addChunk(stream, state, chunk, true);\n\t      } else if (state.ended) {\n\t        errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF());\n\t      } else if (state.destroyed) {\n\t        return false;\n\t      } else {\n\t        state.reading = false;\n\n\t        if (state.decoder && !encoding) {\n\t          chunk = state.decoder.write(chunk);\n\t          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n\t        } else {\n\t          addChunk(stream, state, chunk, false);\n\t        }\n\t      }\n\t    } else if (!addToFront) {\n\t      state.reading = false;\n\t      maybeReadMore(stream, state);\n\t    }\n\t  } // We can push more data if we are below the highWaterMark.\n\t  // Also, if we have no data yet, we can stand some more bytes.\n\t  // This is to work around cases where hwm=0, such as the repl.\n\n\n\t  return !state.ended && (state.length < state.highWaterMark || state.length === 0);\n\t}\n\n\tfunction addChunk(stream, state, chunk, addToFront) {\n\t  if (state.flowing && state.length === 0 && !state.sync) {\n\t    state.awaitDrain = 0;\n\t    stream.emit('data', chunk);\n\t  } else {\n\t    // update the buffer info.\n\t    state.length += state.objectMode ? 1 : chunk.length;\n\t    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\t    if (state.needReadable) emitReadable(stream);\n\t  }\n\n\t  maybeReadMore(stream, state);\n\t}\n\n\tfunction chunkInvalid(state, chunk) {\n\t  var er;\n\n\t  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n\t    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);\n\t  }\n\n\t  return er;\n\t}\n\n\tReadable.prototype.isPaused = function () {\n\t  return this._readableState.flowing === false;\n\t}; // backwards compatibility.\n\n\n\tReadable.prototype.setEncoding = function (enc) {\n\t  if (!StringDecoder) StringDecoder = require$$10.StringDecoder;\n\t  var decoder = new StringDecoder(enc);\n\t  this._readableState.decoder = decoder; // If setEncoding(null), decoder.encoding equals utf8\n\n\t  this._readableState.encoding = this._readableState.decoder.encoding; // Iterate over current buffer to convert already stored Buffers:\n\n\t  var p = this._readableState.buffer.head;\n\t  var content = '';\n\n\t  while (p !== null) {\n\t    content += decoder.write(p.data);\n\t    p = p.next;\n\t  }\n\n\t  this._readableState.buffer.clear();\n\n\t  if (content !== '') this._readableState.buffer.push(content);\n\t  this._readableState.length = content.length;\n\t  return this;\n\t}; // Don't raise the hwm > 1GB\n\n\n\tvar MAX_HWM = 0x40000000;\n\n\tfunction computeNewHighWaterMark(n) {\n\t  if (n >= MAX_HWM) {\n\t    // TODO(ronag): Throw ERR_VALUE_OUT_OF_RANGE.\n\t    n = MAX_HWM;\n\t  } else {\n\t    // Get the next highest power of 2 to prevent increasing hwm excessively in\n\t    // tiny amounts\n\t    n--;\n\t    n |= n >>> 1;\n\t    n |= n >>> 2;\n\t    n |= n >>> 4;\n\t    n |= n >>> 8;\n\t    n |= n >>> 16;\n\t    n++;\n\t  }\n\n\t  return n;\n\t} // This function is designed to be inlinable, so please take care when making\n\t// changes to the function body.\n\n\n\tfunction howMuchToRead(n, state) {\n\t  if (n <= 0 || state.length === 0 && state.ended) return 0;\n\t  if (state.objectMode) return 1;\n\n\t  if (n !== n) {\n\t    // Only flow one buffer at a time\n\t    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n\t  } // If we're asking for more than the current hwm, then raise the hwm.\n\n\n\t  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n\t  if (n <= state.length) return n; // Don't have enough\n\n\t  if (!state.ended) {\n\t    state.needReadable = true;\n\t    return 0;\n\t  }\n\n\t  return state.length;\n\t} // you can override either this method, or the async _read(n) below.\n\n\n\tReadable.prototype.read = function (n) {\n\t  debug('read', n);\n\t  n = parseInt(n, 10);\n\t  var state = this._readableState;\n\t  var nOrig = n;\n\t  if (n !== 0) state.emittedReadable = false; // if we're doing read(0) to trigger a readable event, but we\n\t  // already have a bunch of data in the buffer, then just trigger\n\t  // the 'readable' event and move on.\n\n\t  if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {\n\t    debug('read: emitReadable', state.length, state.ended);\n\t    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n\t    return null;\n\t  }\n\n\t  n = howMuchToRead(n, state); // if we've ended, and we're now clear, then finish it up.\n\n\t  if (n === 0 && state.ended) {\n\t    if (state.length === 0) endReadable(this);\n\t    return null;\n\t  } // All the actual chunk generation logic needs to be\n\t  // *below* the call to _read.  The reason is that in certain\n\t  // synthetic stream cases, such as passthrough streams, _read\n\t  // may be a completely synchronous operation which may change\n\t  // the state of the read buffer, providing enough data when\n\t  // before there was *not* enough.\n\t  //\n\t  // So, the steps are:\n\t  // 1. Figure out what the state of things will be after we do\n\t  // a read from the buffer.\n\t  //\n\t  // 2. If that resulting state will trigger a _read, then call _read.\n\t  // Note that this may be asynchronous, or synchronous.  Yes, it is\n\t  // deeply ugly to write APIs this way, but that still doesn't mean\n\t  // that the Readable class should behave improperly, as streams are\n\t  // designed to be sync/async agnostic.\n\t  // Take note if the _read call is sync or async (ie, if the read call\n\t  // has returned yet), so that we know whether or not it's safe to emit\n\t  // 'readable' etc.\n\t  //\n\t  // 3. Actually pull the requested chunks out of the buffer and return.\n\t  // if we need a readable event, then we need to do some reading.\n\n\n\t  var doRead = state.needReadable;\n\t  debug('need readable', doRead); // if we currently have less than the highWaterMark, then also read some\n\n\t  if (state.length === 0 || state.length - n < state.highWaterMark) {\n\t    doRead = true;\n\t    debug('length less than watermark', doRead);\n\t  } // however, if we've ended, then there's no point, and if we're already\n\t  // reading, then it's unnecessary.\n\n\n\t  if (state.ended || state.reading) {\n\t    doRead = false;\n\t    debug('reading or ended', doRead);\n\t  } else if (doRead) {\n\t    debug('do read');\n\t    state.reading = true;\n\t    state.sync = true; // if the length is currently zero, then we *need* a readable event.\n\n\t    if (state.length === 0) state.needReadable = true; // call internal read method\n\n\t    this._read(state.highWaterMark);\n\n\t    state.sync = false; // If _read pushed data synchronously, then `reading` will be false,\n\t    // and we need to re-evaluate how much data we can return to the user.\n\n\t    if (!state.reading) n = howMuchToRead(nOrig, state);\n\t  }\n\n\t  var ret;\n\t  if (n > 0) ret = fromList(n, state);else ret = null;\n\n\t  if (ret === null) {\n\t    state.needReadable = state.length <= state.highWaterMark;\n\t    n = 0;\n\t  } else {\n\t    state.length -= n;\n\t    state.awaitDrain = 0;\n\t  }\n\n\t  if (state.length === 0) {\n\t    // If we have nothing in the buffer, then we want to know\n\t    // as soon as we *do* get something into the buffer.\n\t    if (!state.ended) state.needReadable = true; // If we tried to read() past the EOF, then emit end on the next tick.\n\n\t    if (nOrig !== n && state.ended) endReadable(this);\n\t  }\n\n\t  if (ret !== null) this.emit('data', ret);\n\t  return ret;\n\t};\n\n\tfunction onEofChunk(stream, state) {\n\t  debug('onEofChunk');\n\t  if (state.ended) return;\n\n\t  if (state.decoder) {\n\t    var chunk = state.decoder.end();\n\n\t    if (chunk && chunk.length) {\n\t      state.buffer.push(chunk);\n\t      state.length += state.objectMode ? 1 : chunk.length;\n\t    }\n\t  }\n\n\t  state.ended = true;\n\n\t  if (state.sync) {\n\t    // if we are sync, wait until next tick to emit the data.\n\t    // Otherwise we risk emitting data in the flow()\n\t    // the readable code triggers during a read() call\n\t    emitReadable(stream);\n\t  } else {\n\t    // emit 'readable' now to make sure it gets picked up.\n\t    state.needReadable = false;\n\n\t    if (!state.emittedReadable) {\n\t      state.emittedReadable = true;\n\t      emitReadable_(stream);\n\t    }\n\t  }\n\t} // Don't emit readable right away in sync mode, because this can trigger\n\t// another read() call => stack overflow.  This way, it might trigger\n\t// a nextTick recursion warning, but that's not so bad.\n\n\n\tfunction emitReadable(stream) {\n\t  var state = stream._readableState;\n\t  debug('emitReadable', state.needReadable, state.emittedReadable);\n\t  state.needReadable = false;\n\n\t  if (!state.emittedReadable) {\n\t    debug('emitReadable', state.flowing);\n\t    state.emittedReadable = true;\n\t    process.nextTick(emitReadable_, stream);\n\t  }\n\t}\n\n\tfunction emitReadable_(stream) {\n\t  var state = stream._readableState;\n\t  debug('emitReadable_', state.destroyed, state.length, state.ended);\n\n\t  if (!state.destroyed && (state.length || state.ended)) {\n\t    stream.emit('readable');\n\t    state.emittedReadable = false;\n\t  } // The stream needs another readable event if\n\t  // 1. It is not flowing, as the flow mechanism will take\n\t  //    care of it.\n\t  // 2. It is not ended.\n\t  // 3. It is below the highWaterMark, so we can schedule\n\t  //    another readable later.\n\n\n\t  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;\n\t  flow(stream);\n\t} // at this point, the user has presumably seen the 'readable' event,\n\t// and called read() to consume some data.  that may have triggered\n\t// in turn another _read(n) call, in which case reading = true if\n\t// it's in progress.\n\t// However, if we're not ended, or reading, and the length < hwm,\n\t// then go ahead and try to read some more preemptively.\n\n\n\tfunction maybeReadMore(stream, state) {\n\t  if (!state.readingMore) {\n\t    state.readingMore = true;\n\t    process.nextTick(maybeReadMore_, stream, state);\n\t  }\n\t}\n\n\tfunction maybeReadMore_(stream, state) {\n\t  // Attempt to read more data if we should.\n\t  //\n\t  // The conditions for reading more data are (one of):\n\t  // - Not enough data buffered (state.length < state.highWaterMark). The loop\n\t  //   is responsible for filling the buffer with enough data if such data\n\t  //   is available. If highWaterMark is 0 and we are not in the flowing mode\n\t  //   we should _not_ attempt to buffer any extra data. We'll get more data\n\t  //   when the stream consumer calls read() instead.\n\t  // - No data in the buffer, and the stream is in flowing mode. In this mode\n\t  //   the loop below is responsible for ensuring read() is called. Failing to\n\t  //   call read here would abort the flow and there's no other mechanism for\n\t  //   continuing the flow if the stream consumer has just subscribed to the\n\t  //   'data' event.\n\t  //\n\t  // In addition to the above conditions to keep reading data, the following\n\t  // conditions prevent the data from being read:\n\t  // - The stream has ended (state.ended).\n\t  // - There is already a pending 'read' operation (state.reading). This is a\n\t  //   case where the the stream has called the implementation defined _read()\n\t  //   method, but they are processing the call asynchronously and have _not_\n\t  //   called push() with new data. In this case we skip performing more\n\t  //   read()s. The execution ends in this method again after the _read() ends\n\t  //   up calling push() with more data.\n\t  while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {\n\t    var len = state.length;\n\t    debug('maybeReadMore read 0');\n\t    stream.read(0);\n\t    if (len === state.length) // didn't get any data, stop spinning.\n\t      break;\n\t  }\n\n\t  state.readingMore = false;\n\t} // abstract method.  to be overridden in specific implementation classes.\n\t// call cb(er, data) where data is <= n in length.\n\t// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n\t// arbitrary, and perhaps not very meaningful.\n\n\n\tReadable.prototype._read = function (n) {\n\t  errorOrDestroy(this, new ERR_METHOD_NOT_IMPLEMENTED('_read()'));\n\t};\n\n\tReadable.prototype.pipe = function (dest, pipeOpts) {\n\t  var src = this;\n\t  var state = this._readableState;\n\n\t  switch (state.pipesCount) {\n\t    case 0:\n\t      state.pipes = dest;\n\t      break;\n\n\t    case 1:\n\t      state.pipes = [state.pipes, dest];\n\t      break;\n\n\t    default:\n\t      state.pipes.push(dest);\n\t      break;\n\t  }\n\n\t  state.pipesCount += 1;\n\t  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\t  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\t  var endFn = doEnd ? onend : unpipe;\n\t  if (state.endEmitted) process.nextTick(endFn);else src.once('end', endFn);\n\t  dest.on('unpipe', onunpipe);\n\n\t  function onunpipe(readable, unpipeInfo) {\n\t    debug('onunpipe');\n\n\t    if (readable === src) {\n\t      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n\t        unpipeInfo.hasUnpiped = true;\n\t        cleanup();\n\t      }\n\t    }\n\t  }\n\n\t  function onend() {\n\t    debug('onend');\n\t    dest.end();\n\t  } // when the dest drains, it reduces the awaitDrain counter\n\t  // on the source.  This would be more elegant with a .once()\n\t  // handler in flow(), but adding and removing repeatedly is\n\t  // too slow.\n\n\n\t  var ondrain = pipeOnDrain(src);\n\t  dest.on('drain', ondrain);\n\t  var cleanedUp = false;\n\n\t  function cleanup() {\n\t    debug('cleanup'); // cleanup event handlers once the pipe is broken\n\n\t    dest.removeListener('close', onclose);\n\t    dest.removeListener('finish', onfinish);\n\t    dest.removeListener('drain', ondrain);\n\t    dest.removeListener('error', onerror);\n\t    dest.removeListener('unpipe', onunpipe);\n\t    src.removeListener('end', onend);\n\t    src.removeListener('end', unpipe);\n\t    src.removeListener('data', ondata);\n\t    cleanedUp = true; // if the reader is waiting for a drain event from this\n\t    // specific writer, then it would cause it to never start\n\t    // flowing again.\n\t    // So, if this is awaiting a drain, then we just call it now.\n\t    // If we don't know, then assume that we are waiting for one.\n\n\t    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n\t  }\n\n\t  src.on('data', ondata);\n\n\t  function ondata(chunk) {\n\t    debug('ondata');\n\t    var ret = dest.write(chunk);\n\t    debug('dest.write', ret);\n\n\t    if (ret === false) {\n\t      // If the user unpiped during `dest.write()`, it is possible\n\t      // to get stuck in a permanently paused state if that write\n\t      // also returned false.\n\t      // => Check whether `dest` is still a piping destination.\n\t      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n\t        debug('false write response, pause', state.awaitDrain);\n\t        state.awaitDrain++;\n\t      }\n\n\t      src.pause();\n\t    }\n\t  } // if the dest has an error, then stop piping into it.\n\t  // however, don't suppress the throwing behavior for this.\n\n\n\t  function onerror(er) {\n\t    debug('onerror', er);\n\t    unpipe();\n\t    dest.removeListener('error', onerror);\n\t    if (EElistenerCount(dest, 'error') === 0) errorOrDestroy(dest, er);\n\t  } // Make sure our error handler is attached before userland ones.\n\n\n\t  prependListener(dest, 'error', onerror); // Both close and finish should trigger unpipe, but only once.\n\n\t  function onclose() {\n\t    dest.removeListener('finish', onfinish);\n\t    unpipe();\n\t  }\n\n\t  dest.once('close', onclose);\n\n\t  function onfinish() {\n\t    debug('onfinish');\n\t    dest.removeListener('close', onclose);\n\t    unpipe();\n\t  }\n\n\t  dest.once('finish', onfinish);\n\n\t  function unpipe() {\n\t    debug('unpipe');\n\t    src.unpipe(dest);\n\t  } // tell the dest that it's being piped to\n\n\n\t  dest.emit('pipe', src); // start the flow if it hasn't been started already.\n\n\t  if (!state.flowing) {\n\t    debug('pipe resume');\n\t    src.resume();\n\t  }\n\n\t  return dest;\n\t};\n\n\tfunction pipeOnDrain(src) {\n\t  return function pipeOnDrainFunctionResult() {\n\t    var state = src._readableState;\n\t    debug('pipeOnDrain', state.awaitDrain);\n\t    if (state.awaitDrain) state.awaitDrain--;\n\n\t    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n\t      state.flowing = true;\n\t      flow(src);\n\t    }\n\t  };\n\t}\n\n\tReadable.prototype.unpipe = function (dest) {\n\t  var state = this._readableState;\n\t  var unpipeInfo = {\n\t    hasUnpiped: false\n\t  }; // if we're not piping anywhere, then do nothing.\n\n\t  if (state.pipesCount === 0) return this; // just one destination.  most common case.\n\n\t  if (state.pipesCount === 1) {\n\t    // passed in one, but it's not the right one.\n\t    if (dest && dest !== state.pipes) return this;\n\t    if (!dest) dest = state.pipes; // got a match.\n\n\t    state.pipes = null;\n\t    state.pipesCount = 0;\n\t    state.flowing = false;\n\t    if (dest) dest.emit('unpipe', this, unpipeInfo);\n\t    return this;\n\t  } // slow case. multiple pipe destinations.\n\n\n\t  if (!dest) {\n\t    // remove all.\n\t    var dests = state.pipes;\n\t    var len = state.pipesCount;\n\t    state.pipes = null;\n\t    state.pipesCount = 0;\n\t    state.flowing = false;\n\n\t    for (var i = 0; i < len; i++) {\n\t      dests[i].emit('unpipe', this, {\n\t        hasUnpiped: false\n\t      });\n\t    }\n\n\t    return this;\n\t  } // try to find the right one.\n\n\n\t  var index = indexOf(state.pipes, dest);\n\t  if (index === -1) return this;\n\t  state.pipes.splice(index, 1);\n\t  state.pipesCount -= 1;\n\t  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\t  dest.emit('unpipe', this, unpipeInfo);\n\t  return this;\n\t}; // set up data events if they are asked for\n\t// Ensure readable listeners eventually get something\n\n\n\tReadable.prototype.on = function (ev, fn) {\n\t  var res = Stream.prototype.on.call(this, ev, fn);\n\t  var state = this._readableState;\n\n\t  if (ev === 'data') {\n\t    // update readableListening so that resume() may be a no-op\n\t    // a few lines down. This is needed to support once('readable').\n\t    state.readableListening = this.listenerCount('readable') > 0; // Try start flowing on next tick if stream isn't explicitly paused\n\n\t    if (state.flowing !== false) this.resume();\n\t  } else if (ev === 'readable') {\n\t    if (!state.endEmitted && !state.readableListening) {\n\t      state.readableListening = state.needReadable = true;\n\t      state.flowing = false;\n\t      state.emittedReadable = false;\n\t      debug('on readable', state.length, state.reading);\n\n\t      if (state.length) {\n\t        emitReadable(this);\n\t      } else if (!state.reading) {\n\t        process.nextTick(nReadingNextTick, this);\n\t      }\n\t    }\n\t  }\n\n\t  return res;\n\t};\n\n\tReadable.prototype.addListener = Readable.prototype.on;\n\n\tReadable.prototype.removeListener = function (ev, fn) {\n\t  var res = Stream.prototype.removeListener.call(this, ev, fn);\n\n\t  if (ev === 'readable') {\n\t    // We need to check if there is someone still listening to\n\t    // readable and reset the state. However this needs to happen\n\t    // after readable has been emitted but before I/O (nextTick) to\n\t    // support once('readable', fn) cycles. This means that calling\n\t    // resume within the same tick will have no\n\t    // effect.\n\t    process.nextTick(updateReadableListening, this);\n\t  }\n\n\t  return res;\n\t};\n\n\tReadable.prototype.removeAllListeners = function (ev) {\n\t  var res = Stream.prototype.removeAllListeners.apply(this, arguments);\n\n\t  if (ev === 'readable' || ev === undefined) {\n\t    // We need to check if there is someone still listening to\n\t    // readable and reset the state. However this needs to happen\n\t    // after readable has been emitted but before I/O (nextTick) to\n\t    // support once('readable', fn) cycles. This means that calling\n\t    // resume within the same tick will have no\n\t    // effect.\n\t    process.nextTick(updateReadableListening, this);\n\t  }\n\n\t  return res;\n\t};\n\n\tfunction updateReadableListening(self) {\n\t  var state = self._readableState;\n\t  state.readableListening = self.listenerCount('readable') > 0;\n\n\t  if (state.resumeScheduled && !state.paused) {\n\t    // flowing needs to be set to true now, otherwise\n\t    // the upcoming resume will not flow.\n\t    state.flowing = true; // crude way to check if we should resume\n\t  } else if (self.listenerCount('data') > 0) {\n\t    self.resume();\n\t  }\n\t}\n\n\tfunction nReadingNextTick(self) {\n\t  debug('readable nexttick read 0');\n\t  self.read(0);\n\t} // pause() and resume() are remnants of the legacy readable stream API\n\t// If the user uses them, then switch into old mode.\n\n\n\tReadable.prototype.resume = function () {\n\t  var state = this._readableState;\n\n\t  if (!state.flowing) {\n\t    debug('resume'); // we flow only if there is no one listening\n\t    // for readable, but we still have to call\n\t    // resume()\n\n\t    state.flowing = !state.readableListening;\n\t    resume(this, state);\n\t  }\n\n\t  state.paused = false;\n\t  return this;\n\t};\n\n\tfunction resume(stream, state) {\n\t  if (!state.resumeScheduled) {\n\t    state.resumeScheduled = true;\n\t    process.nextTick(resume_, stream, state);\n\t  }\n\t}\n\n\tfunction resume_(stream, state) {\n\t  debug('resume', state.reading);\n\n\t  if (!state.reading) {\n\t    stream.read(0);\n\t  }\n\n\t  state.resumeScheduled = false;\n\t  stream.emit('resume');\n\t  flow(stream);\n\t  if (state.flowing && !state.reading) stream.read(0);\n\t}\n\n\tReadable.prototype.pause = function () {\n\t  debug('call pause flowing=%j', this._readableState.flowing);\n\n\t  if (this._readableState.flowing !== false) {\n\t    debug('pause');\n\t    this._readableState.flowing = false;\n\t    this.emit('pause');\n\t  }\n\n\t  this._readableState.paused = true;\n\t  return this;\n\t};\n\n\tfunction flow(stream) {\n\t  var state = stream._readableState;\n\t  debug('flow', state.flowing);\n\n\t  while (state.flowing && stream.read() !== null) {\n\t    ;\n\t  }\n\t} // wrap an old-style stream as the async data source.\n\t// This is *not* part of the readable stream interface.\n\t// It is an ugly unfortunate mess of history.\n\n\n\tReadable.prototype.wrap = function (stream) {\n\t  var _this = this;\n\n\t  var state = this._readableState;\n\t  var paused = false;\n\t  stream.on('end', function () {\n\t    debug('wrapped end');\n\n\t    if (state.decoder && !state.ended) {\n\t      var chunk = state.decoder.end();\n\t      if (chunk && chunk.length) _this.push(chunk);\n\t    }\n\n\t    _this.push(null);\n\t  });\n\t  stream.on('data', function (chunk) {\n\t    debug('wrapped data');\n\t    if (state.decoder) chunk = state.decoder.write(chunk); // don't skip over falsy values in objectMode\n\n\t    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n\t    var ret = _this.push(chunk);\n\n\t    if (!ret) {\n\t      paused = true;\n\t      stream.pause();\n\t    }\n\t  }); // proxy all the other methods.\n\t  // important when wrapping filters and duplexes.\n\n\t  for (var i in stream) {\n\t    if (this[i] === undefined && typeof stream[i] === 'function') {\n\t      this[i] = function methodWrap(method) {\n\t        return function methodWrapReturnFunction() {\n\t          return stream[method].apply(stream, arguments);\n\t        };\n\t      }(i);\n\t    }\n\t  } // proxy certain important events.\n\n\n\t  for (var n = 0; n < kProxyEvents.length; n++) {\n\t    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n\t  } // when we try to consume some more bytes, simply unpause the\n\t  // underlying stream.\n\n\n\t  this._read = function (n) {\n\t    debug('wrapped _read', n);\n\n\t    if (paused) {\n\t      paused = false;\n\t      stream.resume();\n\t    }\n\t  };\n\n\t  return this;\n\t};\n\n\tif (typeof Symbol === 'function') {\n\t  Readable.prototype[Symbol.asyncIterator] = function () {\n\t    if (createReadableStreamAsyncIterator === undefined) {\n\t      createReadableStreamAsyncIterator = require$$11();\n\t    }\n\n\t    return createReadableStreamAsyncIterator(this);\n\t  };\n\t}\n\n\tObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n\t  // making it explicit this property is not enumerable\n\t  // because otherwise some prototype manipulation in\n\t  // userland will fail\n\t  enumerable: false,\n\t  get: function get() {\n\t    return this._readableState.highWaterMark;\n\t  }\n\t});\n\tObject.defineProperty(Readable.prototype, 'readableBuffer', {\n\t  // making it explicit this property is not enumerable\n\t  // because otherwise some prototype manipulation in\n\t  // userland will fail\n\t  enumerable: false,\n\t  get: function get() {\n\t    return this._readableState && this._readableState.buffer;\n\t  }\n\t});\n\tObject.defineProperty(Readable.prototype, 'readableFlowing', {\n\t  // making it explicit this property is not enumerable\n\t  // because otherwise some prototype manipulation in\n\t  // userland will fail\n\t  enumerable: false,\n\t  get: function get() {\n\t    return this._readableState.flowing;\n\t  },\n\t  set: function set(state) {\n\t    if (this._readableState) {\n\t      this._readableState.flowing = state;\n\t    }\n\t  }\n\t}); // exposed for testing purposes only.\n\n\tReadable._fromList = fromList;\n\tObject.defineProperty(Readable.prototype, 'readableLength', {\n\t  // making it explicit this property is not enumerable\n\t  // because otherwise some prototype manipulation in\n\t  // userland will fail\n\t  enumerable: false,\n\t  get: function get() {\n\t    return this._readableState.length;\n\t  }\n\t}); // Pluck off n bytes from an array of buffers.\n\t// Length is the combined lengths of all the buffers in the list.\n\t// This function is designed to be inlinable, so please take care when making\n\t// changes to the function body.\n\n\tfunction fromList(n, state) {\n\t  // nothing buffered\n\t  if (state.length === 0) return null;\n\t  var ret;\n\t  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n\t    // read it all, truncate the list\n\t    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.first();else ret = state.buffer.concat(state.length);\n\t    state.buffer.clear();\n\t  } else {\n\t    // read part of list\n\t    ret = state.buffer.consume(n, state.decoder);\n\t  }\n\t  return ret;\n\t}\n\n\tfunction endReadable(stream) {\n\t  var state = stream._readableState;\n\t  debug('endReadable', state.endEmitted);\n\n\t  if (!state.endEmitted) {\n\t    state.ended = true;\n\t    process.nextTick(endReadableNT, state, stream);\n\t  }\n\t}\n\n\tfunction endReadableNT(state, stream) {\n\t  debug('endReadableNT', state.endEmitted, state.length); // Check that we didn't get one last unshift.\n\n\t  if (!state.endEmitted && state.length === 0) {\n\t    state.endEmitted = true;\n\t    stream.readable = false;\n\t    stream.emit('end');\n\n\t    if (state.autoDestroy) {\n\t      // In case of duplex streams we need a way to detect\n\t      // if the writable side is ready for autoDestroy as well\n\t      var wState = stream._writableState;\n\n\t      if (!wState || wState.autoDestroy && wState.finished) {\n\t        stream.destroy();\n\t      }\n\t    }\n\t  }\n\t}\n\n\tif (typeof Symbol === 'function') {\n\t  Readable.from = function (iterable, opts) {\n\t    if (from === undefined) {\n\t      from = require$$12();\n\t    }\n\n\t    return from(Readable, iterable, opts);\n\t  };\n\t}\n\n\tfunction indexOf(xs, x) {\n\t  for (var i = 0, l = xs.length; i < l; i++) {\n\t    if (xs[i] === x) return i;\n\t  }\n\n\t  return -1;\n\t}\n\treturn _stream_readable;\n}\n\nexport { require_stream_readable as __require };","start":1670465469392,"end":1670465470187,"order":"normal"},{"name":"polyfill-node","result":"import { default as process } from '\u0000polyfill-node.process';\n\nimport * as commonjsHelpers from \"\u0000commonjsHelpers.js\";\nimport require$$0 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/events@3.3.0/node_modules/events/events.js?commonjs-proxy\";\nimport require$$1 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/lib/internal/streams/stream-browser.js?commonjs-proxy\";\nimport require$$2 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js?commonjs-proxy\";\nimport require$$3 from \"\\u0000__vite-browser-external?commonjs-proxy\";\nimport { __require as require$$4 } from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/lib/internal/streams/buffer_list.js?commonjs-wrapped\";\nimport require$$5 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/lib/internal/streams/destroy.js?commonjs-proxy\";\nimport require$$6 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/lib/internal/streams/state.js?commonjs-proxy\";\nimport require$$7 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/errors-browser.js?commonjs-proxy\";\nimport require$$8 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/inherits@2.0.4/node_modules/inherits/inherits_browser.js?commonjs-proxy\";\nimport { __require as require$$9 } from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/lib/_stream_duplex.js?commonjs-wrapped\";\nimport require$$10 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/string_decoder@1.3.0/node_modules/string_decoder/lib/string_decoder.js?commonjs-proxy\";\nimport { __require as require$$11 } from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/lib/internal/streams/async_iterator.js?commonjs-wrapped\";\nimport { __require as require$$12 } from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/readable-stream@3.6.0/node_modules/readable-stream/lib/internal/streams/from-browser.js?commonjs-wrapped\";\n\nvar _stream_readable;\nvar hasRequired_stream_readable;\n\nfunction require_stream_readable () {\n\tif (hasRequired_stream_readable) return _stream_readable;\n\thasRequired_stream_readable = 1;\n\t// Copyright Joyent, Inc. and other Node contributors.\n\t//\n\t// Permission is hereby granted, free of charge, to any person obtaining a\n\t// copy of this software and associated documentation files (the\n\t// \"Software\"), to deal in the Software without restriction, including\n\t// without limitation the rights to use, copy, modify, merge, publish,\n\t// distribute, sublicense, and/or sell copies of the Software, and to permit\n\t// persons to whom the Software is furnished to do so, subject to the\n\t// following conditions:\n\t//\n\t// The above copyright notice and this permission notice shall be included\n\t// in all copies or substantial portions of the Software.\n\t//\n\t// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n\t// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n\t// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n\t// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n\t// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n\t// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n\t// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\t'use strict';\n\n\t_stream_readable = Readable;\n\t/*<replacement>*/\n\n\tvar Duplex;\n\t/*</replacement>*/\n\n\tReadable.ReadableState = ReadableState;\n\t/*<replacement>*/\n\n\tvar EE = require$$0.EventEmitter;\n\n\tvar EElistenerCount = function EElistenerCount(emitter, type) {\n\t  return emitter.listeners(type).length;\n\t};\n\t/*</replacement>*/\n\n\t/*<replacement>*/\n\n\n\tvar Stream = require$$1;\n\t/*</replacement>*/\n\n\n\tvar Buffer = require$$2.Buffer;\n\n\tvar OurUint8Array = commonjsHelpers.commonjsGlobal.Uint8Array || function () {};\n\n\tfunction _uint8ArrayToBuffer(chunk) {\n\t  return Buffer.from(chunk);\n\t}\n\n\tfunction _isUint8Array(obj) {\n\t  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n\t}\n\t/*<replacement>*/\n\n\n\tvar debugUtil = require$$3;\n\n\tvar debug;\n\n\tif (debugUtil && debugUtil.debuglog) {\n\t  debug = debugUtil.debuglog('stream');\n\t} else {\n\t  debug = function debug() {};\n\t}\n\t/*</replacement>*/\n\n\n\tvar BufferList = require$$4();\n\n\tvar destroyImpl = require$$5;\n\n\tvar _require = require$$6,\n\t    getHighWaterMark = _require.getHighWaterMark;\n\n\tvar _require$codes = require$$7.codes,\n\t    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n\t    ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,\n\t    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n\t    ERR_STREAM_UNSHIFT_AFTER_END_EVENT = _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT; // Lazy loaded to improve the startup performance.\n\n\n\tvar StringDecoder;\n\tvar createReadableStreamAsyncIterator;\n\tvar from;\n\n\trequire$$8(Readable, Stream);\n\n\tvar errorOrDestroy = destroyImpl.errorOrDestroy;\n\tvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\n\tfunction prependListener(emitter, event, fn) {\n\t  // Sadly this is not cacheable as some libraries bundle their own\n\t  // event emitter implementation with them.\n\t  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn); // This is a hack to make sure that our error handler is attached before any\n\t  // userland ones.  NEVER DO THIS. This is here only because this code needs\n\t  // to continue to work with older versions of Node.js that do not include\n\t  // the prependListener() method. The goal is to eventually remove this hack.\n\n\t  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (Array.isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n\t}\n\n\tfunction ReadableState(options, stream, isDuplex) {\n\t  Duplex = Duplex || require$$9();\n\t  options = options || {}; // Duplex streams are both readable and writable, but share\n\t  // the same options object.\n\t  // However, some cases require setting options to different\n\t  // values for the readable and the writable sides of the duplex stream.\n\t  // These options can be provided separately as readableXXX and writableXXX.\n\n\t  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag. Used to make read(n) ignore n and to\n\t  // make all the buffer merging and length checks go away\n\n\t  this.objectMode = !!options.objectMode;\n\t  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode; // the point at which it stops calling _read() to fill the buffer\n\t  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n\n\t  this.highWaterMark = getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex); // A linked list is used to store data chunks instead of an array because the\n\t  // linked list can remove elements from the beginning faster than\n\t  // array.shift()\n\n\t  this.buffer = new BufferList();\n\t  this.length = 0;\n\t  this.pipes = null;\n\t  this.pipesCount = 0;\n\t  this.flowing = null;\n\t  this.ended = false;\n\t  this.endEmitted = false;\n\t  this.reading = false; // a flag to be able to tell if the event 'readable'/'data' is emitted\n\t  // immediately, or on a later tick.  We set this to true at first, because\n\t  // any actions that shouldn't happen until \"later\" should generally also\n\t  // not happen before the first read call.\n\n\t  this.sync = true; // whenever we return null, then we set a flag to say\n\t  // that we're awaiting a 'readable' event emission.\n\n\t  this.needReadable = false;\n\t  this.emittedReadable = false;\n\t  this.readableListening = false;\n\t  this.resumeScheduled = false;\n\t  this.paused = true; // Should close be emitted on destroy. Defaults to true.\n\n\t  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'end' (and potentially 'finish')\n\n\t  this.autoDestroy = !!options.autoDestroy; // has it been destroyed\n\n\t  this.destroyed = false; // Crypto is kind of old and crusty.  Historically, its default string\n\t  // encoding is 'binary' so we have to make this configurable.\n\t  // Everything else in the universe uses 'utf8', though.\n\n\t  this.defaultEncoding = options.defaultEncoding || 'utf8'; // the number of writers that are awaiting a drain event in .pipe()s\n\n\t  this.awaitDrain = 0; // if true, a maybeReadMore has been scheduled\n\n\t  this.readingMore = false;\n\t  this.decoder = null;\n\t  this.encoding = null;\n\n\t  if (options.encoding) {\n\t    if (!StringDecoder) StringDecoder = require$$10.StringDecoder;\n\t    this.decoder = new StringDecoder(options.encoding);\n\t    this.encoding = options.encoding;\n\t  }\n\t}\n\n\tfunction Readable(options) {\n\t  Duplex = Duplex || require$$9();\n\t  if (!(this instanceof Readable)) return new Readable(options); // Checking for a Stream.Duplex instance is faster here instead of inside\n\t  // the ReadableState constructor, at least with V8 6.5\n\n\t  var isDuplex = this instanceof Duplex;\n\t  this._readableState = new ReadableState(options, this, isDuplex); // legacy\n\n\t  this.readable = true;\n\n\t  if (options) {\n\t    if (typeof options.read === 'function') this._read = options.read;\n\t    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\t  }\n\n\t  Stream.call(this);\n\t}\n\n\tObject.defineProperty(Readable.prototype, 'destroyed', {\n\t  // making it explicit this property is not enumerable\n\t  // because otherwise some prototype manipulation in\n\t  // userland will fail\n\t  enumerable: false,\n\t  get: function get() {\n\t    if (this._readableState === undefined) {\n\t      return false;\n\t    }\n\n\t    return this._readableState.destroyed;\n\t  },\n\t  set: function set(value) {\n\t    // we ignore the value if the stream\n\t    // has not been initialized yet\n\t    if (!this._readableState) {\n\t      return;\n\t    } // backward compatibility, the user is explicitly\n\t    // managing destroyed\n\n\n\t    this._readableState.destroyed = value;\n\t  }\n\t});\n\tReadable.prototype.destroy = destroyImpl.destroy;\n\tReadable.prototype._undestroy = destroyImpl.undestroy;\n\n\tReadable.prototype._destroy = function (err, cb) {\n\t  cb(err);\n\t}; // Manually shove something into the read() buffer.\n\t// This returns true if the highWaterMark has not been hit yet,\n\t// similar to how Writable.write() returns true if you should\n\t// write() some more.\n\n\n\tReadable.prototype.push = function (chunk, encoding) {\n\t  var state = this._readableState;\n\t  var skipChunkCheck;\n\n\t  if (!state.objectMode) {\n\t    if (typeof chunk === 'string') {\n\t      encoding = encoding || state.defaultEncoding;\n\n\t      if (encoding !== state.encoding) {\n\t        chunk = Buffer.from(chunk, encoding);\n\t        encoding = '';\n\t      }\n\n\t      skipChunkCheck = true;\n\t    }\n\t  } else {\n\t    skipChunkCheck = true;\n\t  }\n\n\t  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n\t}; // Unshift should *always* be something directly out of read()\n\n\n\tReadable.prototype.unshift = function (chunk) {\n\t  return readableAddChunk(this, chunk, null, true, false);\n\t};\n\n\tfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n\t  debug('readableAddChunk', chunk);\n\t  var state = stream._readableState;\n\n\t  if (chunk === null) {\n\t    state.reading = false;\n\t    onEofChunk(stream, state);\n\t  } else {\n\t    var er;\n\t    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n\n\t    if (er) {\n\t      errorOrDestroy(stream, er);\n\t    } else if (state.objectMode || chunk && chunk.length > 0) {\n\t      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n\t        chunk = _uint8ArrayToBuffer(chunk);\n\t      }\n\n\t      if (addToFront) {\n\t        if (state.endEmitted) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());else addChunk(stream, state, chunk, true);\n\t      } else if (state.ended) {\n\t        errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF());\n\t      } else if (state.destroyed) {\n\t        return false;\n\t      } else {\n\t        state.reading = false;\n\n\t        if (state.decoder && !encoding) {\n\t          chunk = state.decoder.write(chunk);\n\t          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n\t        } else {\n\t          addChunk(stream, state, chunk, false);\n\t        }\n\t      }\n\t    } else if (!addToFront) {\n\t      state.reading = false;\n\t      maybeReadMore(stream, state);\n\t    }\n\t  } // We can push more data if we are below the highWaterMark.\n\t  // Also, if we have no data yet, we can stand some more bytes.\n\t  // This is to work around cases where hwm=0, such as the repl.\n\n\n\t  return !state.ended && (state.length < state.highWaterMark || state.length === 0);\n\t}\n\n\tfunction addChunk(stream, state, chunk, addToFront) {\n\t  if (state.flowing && state.length === 0 && !state.sync) {\n\t    state.awaitDrain = 0;\n\t    stream.emit('data', chunk);\n\t  } else {\n\t    // update the buffer info.\n\t    state.length += state.objectMode ? 1 : chunk.length;\n\t    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\t    if (state.needReadable) emitReadable(stream);\n\t  }\n\n\t  maybeReadMore(stream, state);\n\t}\n\n\tfunction chunkInvalid(state, chunk) {\n\t  var er;\n\n\t  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n\t    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);\n\t  }\n\n\t  return er;\n\t}\n\n\tReadable.prototype.isPaused = function () {\n\t  return this._readableState.flowing === false;\n\t}; // backwards compatibility.\n\n\n\tReadable.prototype.setEncoding = function (enc) {\n\t  if (!StringDecoder) StringDecoder = require$$10.StringDecoder;\n\t  var decoder = new StringDecoder(enc);\n\t  this._readableState.decoder = decoder; // If setEncoding(null), decoder.encoding equals utf8\n\n\t  this._readableState.encoding = this._readableState.decoder.encoding; // Iterate over current buffer to convert already stored Buffers:\n\n\t  var p = this._readableState.buffer.head;\n\t  var content = '';\n\n\t  while (p !== null) {\n\t    content += decoder.write(p.data);\n\t    p = p.next;\n\t  }\n\n\t  this._readableState.buffer.clear();\n\n\t  if (content !== '') this._readableState.buffer.push(content);\n\t  this._readableState.length = content.length;\n\t  return this;\n\t}; // Don't raise the hwm > 1GB\n\n\n\tvar MAX_HWM = 0x40000000;\n\n\tfunction computeNewHighWaterMark(n) {\n\t  if (n >= MAX_HWM) {\n\t    // TODO(ronag): Throw ERR_VALUE_OUT_OF_RANGE.\n\t    n = MAX_HWM;\n\t  } else {\n\t    // Get the next highest power of 2 to prevent increasing hwm excessively in\n\t    // tiny amounts\n\t    n--;\n\t    n |= n >>> 1;\n\t    n |= n >>> 2;\n\t    n |= n >>> 4;\n\t    n |= n >>> 8;\n\t    n |= n >>> 16;\n\t    n++;\n\t  }\n\n\t  return n;\n\t} // This function is designed to be inlinable, so please take care when making\n\t// changes to the function body.\n\n\n\tfunction howMuchToRead(n, state) {\n\t  if (n <= 0 || state.length === 0 && state.ended) return 0;\n\t  if (state.objectMode) return 1;\n\n\t  if (n !== n) {\n\t    // Only flow one buffer at a time\n\t    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n\t  } // If we're asking for more than the current hwm, then raise the hwm.\n\n\n\t  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n\t  if (n <= state.length) return n; // Don't have enough\n\n\t  if (!state.ended) {\n\t    state.needReadable = true;\n\t    return 0;\n\t  }\n\n\t  return state.length;\n\t} // you can override either this method, or the async _read(n) below.\n\n\n\tReadable.prototype.read = function (n) {\n\t  debug('read', n);\n\t  n = parseInt(n, 10);\n\t  var state = this._readableState;\n\t  var nOrig = n;\n\t  if (n !== 0) state.emittedReadable = false; // if we're doing read(0) to trigger a readable event, but we\n\t  // already have a bunch of data in the buffer, then just trigger\n\t  // the 'readable' event and move on.\n\n\t  if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {\n\t    debug('read: emitReadable', state.length, state.ended);\n\t    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n\t    return null;\n\t  }\n\n\t  n = howMuchToRead(n, state); // if we've ended, and we're now clear, then finish it up.\n\n\t  if (n === 0 && state.ended) {\n\t    if (state.length === 0) endReadable(this);\n\t    return null;\n\t  } // All the actual chunk generation logic needs to be\n\t  // *below* the call to _read.  The reason is that in certain\n\t  // synthetic stream cases, such as passthrough streams, _read\n\t  // may be a completely synchronous operation which may change\n\t  // the state of the read buffer, providing enough data when\n\t  // before there was *not* enough.\n\t  //\n\t  // So, the steps are:\n\t  // 1. Figure out what the state of things will be after we do\n\t  // a read from the buffer.\n\t  //\n\t  // 2. If that resulting state will trigger a _read, then call _read.\n\t  // Note that this may be asynchronous, or synchronous.  Yes, it is\n\t  // deeply ugly to write APIs this way, but that still doesn't mean\n\t  // that the Readable class should behave improperly, as streams are\n\t  // designed to be sync/async agnostic.\n\t  // Take note if the _read call is sync or async (ie, if the read call\n\t  // has returned yet), so that we know whether or not it's safe to emit\n\t  // 'readable' etc.\n\t  //\n\t  // 3. Actually pull the requested chunks out of the buffer and return.\n\t  // if we need a readable event, then we need to do some reading.\n\n\n\t  var doRead = state.needReadable;\n\t  debug('need readable', doRead); // if we currently have less than the highWaterMark, then also read some\n\n\t  if (state.length === 0 || state.length - n < state.highWaterMark) {\n\t    doRead = true;\n\t    debug('length less than watermark', doRead);\n\t  } // however, if we've ended, then there's no point, and if we're already\n\t  // reading, then it's unnecessary.\n\n\n\t  if (state.ended || state.reading) {\n\t    doRead = false;\n\t    debug('reading or ended', doRead);\n\t  } else if (doRead) {\n\t    debug('do read');\n\t    state.reading = true;\n\t    state.sync = true; // if the length is currently zero, then we *need* a readable event.\n\n\t    if (state.length === 0) state.needReadable = true; // call internal read method\n\n\t    this._read(state.highWaterMark);\n\n\t    state.sync = false; // If _read pushed data synchronously, then `reading` will be false,\n\t    // and we need to re-evaluate how much data we can return to the user.\n\n\t    if (!state.reading) n = howMuchToRead(nOrig, state);\n\t  }\n\n\t  var ret;\n\t  if (n > 0) ret = fromList(n, state);else ret = null;\n\n\t  if (ret === null) {\n\t    state.needReadable = state.length <= state.highWaterMark;\n\t    n = 0;\n\t  } else {\n\t    state.length -= n;\n\t    state.awaitDrain = 0;\n\t  }\n\n\t  if (state.length === 0) {\n\t    // If we have nothing in the buffer, then we want to know\n\t    // as soon as we *do* get something into the buffer.\n\t    if (!state.ended) state.needReadable = true; // If we tried to read() past the EOF, then emit end on the next tick.\n\n\t    if (nOrig !== n && state.ended) endReadable(this);\n\t  }\n\n\t  if (ret !== null) this.emit('data', ret);\n\t  return ret;\n\t};\n\n\tfunction onEofChunk(stream, state) {\n\t  debug('onEofChunk');\n\t  if (state.ended) return;\n\n\t  if (state.decoder) {\n\t    var chunk = state.decoder.end();\n\n\t    if (chunk && chunk.length) {\n\t      state.buffer.push(chunk);\n\t      state.length += state.objectMode ? 1 : chunk.length;\n\t    }\n\t  }\n\n\t  state.ended = true;\n\n\t  if (state.sync) {\n\t    // if we are sync, wait until next tick to emit the data.\n\t    // Otherwise we risk emitting data in the flow()\n\t    // the readable code triggers during a read() call\n\t    emitReadable(stream);\n\t  } else {\n\t    // emit 'readable' now to make sure it gets picked up.\n\t    state.needReadable = false;\n\n\t    if (!state.emittedReadable) {\n\t      state.emittedReadable = true;\n\t      emitReadable_(stream);\n\t    }\n\t  }\n\t} // Don't emit readable right away in sync mode, because this can trigger\n\t// another read() call => stack overflow.  This way, it might trigger\n\t// a nextTick recursion warning, but that's not so bad.\n\n\n\tfunction emitReadable(stream) {\n\t  var state = stream._readableState;\n\t  debug('emitReadable', state.needReadable, state.emittedReadable);\n\t  state.needReadable = false;\n\n\t  if (!state.emittedReadable) {\n\t    debug('emitReadable', state.flowing);\n\t    state.emittedReadable = true;\n\t    process.nextTick(emitReadable_, stream);\n\t  }\n\t}\n\n\tfunction emitReadable_(stream) {\n\t  var state = stream._readableState;\n\t  debug('emitReadable_', state.destroyed, state.length, state.ended);\n\n\t  if (!state.destroyed && (state.length || state.ended)) {\n\t    stream.emit('readable');\n\t    state.emittedReadable = false;\n\t  } // The stream needs another readable event if\n\t  // 1. It is not flowing, as the flow mechanism will take\n\t  //    care of it.\n\t  // 2. It is not ended.\n\t  // 3. It is below the highWaterMark, so we can schedule\n\t  //    another readable later.\n\n\n\t  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;\n\t  flow(stream);\n\t} // at this point, the user has presumably seen the 'readable' event,\n\t// and called read() to consume some data.  that may have triggered\n\t// in turn another _read(n) call, in which case reading = true if\n\t// it's in progress.\n\t// However, if we're not ended, or reading, and the length < hwm,\n\t// then go ahead and try to read some more preemptively.\n\n\n\tfunction maybeReadMore(stream, state) {\n\t  if (!state.readingMore) {\n\t    state.readingMore = true;\n\t    process.nextTick(maybeReadMore_, stream, state);\n\t  }\n\t}\n\n\tfunction maybeReadMore_(stream, state) {\n\t  // Attempt to read more data if we should.\n\t  //\n\t  // The conditions for reading more data are (one of):\n\t  // - Not enough data buffered (state.length < state.highWaterMark). The loop\n\t  //   is responsible for filling the buffer with enough data if such data\n\t  //   is available. If highWaterMark is 0 and we are not in the flowing mode\n\t  //   we should _not_ attempt to buffer any extra data. We'll get more data\n\t  //   when the stream consumer calls read() instead.\n\t  // - No data in the buffer, and the stream is in flowing mode. In this mode\n\t  //   the loop below is responsible for ensuring read() is called. Failing to\n\t  //   call read here would abort the flow and there's no other mechanism for\n\t  //   continuing the flow if the stream consumer has just subscribed to the\n\t  //   'data' event.\n\t  //\n\t  // In addition to the above conditions to keep reading data, the following\n\t  // conditions prevent the data from being read:\n\t  // - The stream has ended (state.ended).\n\t  // - There is already a pending 'read' operation (state.reading). This is a\n\t  //   case where the the stream has called the implementation defined _read()\n\t  //   method, but they are processing the call asynchronously and have _not_\n\t  //   called push() with new data. In this case we skip performing more\n\t  //   read()s. The execution ends in this method again after the _read() ends\n\t  //   up calling push() with more data.\n\t  while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {\n\t    var len = state.length;\n\t    debug('maybeReadMore read 0');\n\t    stream.read(0);\n\t    if (len === state.length) // didn't get any data, stop spinning.\n\t      break;\n\t  }\n\n\t  state.readingMore = false;\n\t} // abstract method.  to be overridden in specific implementation classes.\n\t// call cb(er, data) where data is <= n in length.\n\t// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n\t// arbitrary, and perhaps not very meaningful.\n\n\n\tReadable.prototype._read = function (n) {\n\t  errorOrDestroy(this, new ERR_METHOD_NOT_IMPLEMENTED('_read()'));\n\t};\n\n\tReadable.prototype.pipe = function (dest, pipeOpts) {\n\t  var src = this;\n\t  var state = this._readableState;\n\n\t  switch (state.pipesCount) {\n\t    case 0:\n\t      state.pipes = dest;\n\t      break;\n\n\t    case 1:\n\t      state.pipes = [state.pipes, dest];\n\t      break;\n\n\t    default:\n\t      state.pipes.push(dest);\n\t      break;\n\t  }\n\n\t  state.pipesCount += 1;\n\t  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\t  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\t  var endFn = doEnd ? onend : unpipe;\n\t  if (state.endEmitted) process.nextTick(endFn);else src.once('end', endFn);\n\t  dest.on('unpipe', onunpipe);\n\n\t  function onunpipe(readable, unpipeInfo) {\n\t    debug('onunpipe');\n\n\t    if (readable === src) {\n\t      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n\t        unpipeInfo.hasUnpiped = true;\n\t        cleanup();\n\t      }\n\t    }\n\t  }\n\n\t  function onend() {\n\t    debug('onend');\n\t    dest.end();\n\t  } // when the dest drains, it reduces the awaitDrain counter\n\t  // on the source.  This would be more elegant with a .once()\n\t  // handler in flow(), but adding and removing repeatedly is\n\t  // too slow.\n\n\n\t  var ondrain = pipeOnDrain(src);\n\t  dest.on('drain', ondrain);\n\t  var cleanedUp = false;\n\n\t  function cleanup() {\n\t    debug('cleanup'); // cleanup event handlers once the pipe is broken\n\n\t    dest.removeListener('close', onclose);\n\t    dest.removeListener('finish', onfinish);\n\t    dest.removeListener('drain', ondrain);\n\t    dest.removeListener('error', onerror);\n\t    dest.removeListener('unpipe', onunpipe);\n\t    src.removeListener('end', onend);\n\t    src.removeListener('end', unpipe);\n\t    src.removeListener('data', ondata);\n\t    cleanedUp = true; // if the reader is waiting for a drain event from this\n\t    // specific writer, then it would cause it to never start\n\t    // flowing again.\n\t    // So, if this is awaiting a drain, then we just call it now.\n\t    // If we don't know, then assume that we are waiting for one.\n\n\t    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n\t  }\n\n\t  src.on('data', ondata);\n\n\t  function ondata(chunk) {\n\t    debug('ondata');\n\t    var ret = dest.write(chunk);\n\t    debug('dest.write', ret);\n\n\t    if (ret === false) {\n\t      // If the user unpiped during `dest.write()`, it is possible\n\t      // to get stuck in a permanently paused state if that write\n\t      // also returned false.\n\t      // => Check whether `dest` is still a piping destination.\n\t      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n\t        debug('false write response, pause', state.awaitDrain);\n\t        state.awaitDrain++;\n\t      }\n\n\t      src.pause();\n\t    }\n\t  } // if the dest has an error, then stop piping into it.\n\t  // however, don't suppress the throwing behavior for this.\n\n\n\t  function onerror(er) {\n\t    debug('onerror', er);\n\t    unpipe();\n\t    dest.removeListener('error', onerror);\n\t    if (EElistenerCount(dest, 'error') === 0) errorOrDestroy(dest, er);\n\t  } // Make sure our error handler is attached before userland ones.\n\n\n\t  prependListener(dest, 'error', onerror); // Both close and finish should trigger unpipe, but only once.\n\n\t  function onclose() {\n\t    dest.removeListener('finish', onfinish);\n\t    unpipe();\n\t  }\n\n\t  dest.once('close', onclose);\n\n\t  function onfinish() {\n\t    debug('onfinish');\n\t    dest.removeListener('close', onclose);\n\t    unpipe();\n\t  }\n\n\t  dest.once('finish', onfinish);\n\n\t  function unpipe() {\n\t    debug('unpipe');\n\t    src.unpipe(dest);\n\t  } // tell the dest that it's being piped to\n\n\n\t  dest.emit('pipe', src); // start the flow if it hasn't been started already.\n\n\t  if (!state.flowing) {\n\t    debug('pipe resume');\n\t    src.resume();\n\t  }\n\n\t  return dest;\n\t};\n\n\tfunction pipeOnDrain(src) {\n\t  return function pipeOnDrainFunctionResult() {\n\t    var state = src._readableState;\n\t    debug('pipeOnDrain', state.awaitDrain);\n\t    if (state.awaitDrain) state.awaitDrain--;\n\n\t    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n\t      state.flowing = true;\n\t      flow(src);\n\t    }\n\t  };\n\t}\n\n\tReadable.prototype.unpipe = function (dest) {\n\t  var state = this._readableState;\n\t  var unpipeInfo = {\n\t    hasUnpiped: false\n\t  }; // if we're not piping anywhere, then do nothing.\n\n\t  if (state.pipesCount === 0) return this; // just one destination.  most common case.\n\n\t  if (state.pipesCount === 1) {\n\t    // passed in one, but it's not the right one.\n\t    if (dest && dest !== state.pipes) return this;\n\t    if (!dest) dest = state.pipes; // got a match.\n\n\t    state.pipes = null;\n\t    state.pipesCount = 0;\n\t    state.flowing = false;\n\t    if (dest) dest.emit('unpipe', this, unpipeInfo);\n\t    return this;\n\t  } // slow case. multiple pipe destinations.\n\n\n\t  if (!dest) {\n\t    // remove all.\n\t    var dests = state.pipes;\n\t    var len = state.pipesCount;\n\t    state.pipes = null;\n\t    state.pipesCount = 0;\n\t    state.flowing = false;\n\n\t    for (var i = 0; i < len; i++) {\n\t      dests[i].emit('unpipe', this, {\n\t        hasUnpiped: false\n\t      });\n\t    }\n\n\t    return this;\n\t  } // try to find the right one.\n\n\n\t  var index = indexOf(state.pipes, dest);\n\t  if (index === -1) return this;\n\t  state.pipes.splice(index, 1);\n\t  state.pipesCount -= 1;\n\t  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\t  dest.emit('unpipe', this, unpipeInfo);\n\t  return this;\n\t}; // set up data events if they are asked for\n\t// Ensure readable listeners eventually get something\n\n\n\tReadable.prototype.on = function (ev, fn) {\n\t  var res = Stream.prototype.on.call(this, ev, fn);\n\t  var state = this._readableState;\n\n\t  if (ev === 'data') {\n\t    // update readableListening so that resume() may be a no-op\n\t    // a few lines down. This is needed to support once('readable').\n\t    state.readableListening = this.listenerCount('readable') > 0; // Try start flowing on next tick if stream isn't explicitly paused\n\n\t    if (state.flowing !== false) this.resume();\n\t  } else if (ev === 'readable') {\n\t    if (!state.endEmitted && !state.readableListening) {\n\t      state.readableListening = state.needReadable = true;\n\t      state.flowing = false;\n\t      state.emittedReadable = false;\n\t      debug('on readable', state.length, state.reading);\n\n\t      if (state.length) {\n\t        emitReadable(this);\n\t      } else if (!state.reading) {\n\t        process.nextTick(nReadingNextTick, this);\n\t      }\n\t    }\n\t  }\n\n\t  return res;\n\t};\n\n\tReadable.prototype.addListener = Readable.prototype.on;\n\n\tReadable.prototype.removeListener = function (ev, fn) {\n\t  var res = Stream.prototype.removeListener.call(this, ev, fn);\n\n\t  if (ev === 'readable') {\n\t    // We need to check if there is someone still listening to\n\t    // readable and reset the state. However this needs to happen\n\t    // after readable has been emitted but before I/O (nextTick) to\n\t    // support once('readable', fn) cycles. This means that calling\n\t    // resume within the same tick will have no\n\t    // effect.\n\t    process.nextTick(updateReadableListening, this);\n\t  }\n\n\t  return res;\n\t};\n\n\tReadable.prototype.removeAllListeners = function (ev) {\n\t  var res = Stream.prototype.removeAllListeners.apply(this, arguments);\n\n\t  if (ev === 'readable' || ev === undefined) {\n\t    // We need to check if there is someone still listening to\n\t    // readable and reset the state. However this needs to happen\n\t    // after readable has been emitted but before I/O (nextTick) to\n\t    // support once('readable', fn) cycles. This means that calling\n\t    // resume within the same tick will have no\n\t    // effect.\n\t    process.nextTick(updateReadableListening, this);\n\t  }\n\n\t  return res;\n\t};\n\n\tfunction updateReadableListening(self) {\n\t  var state = self._readableState;\n\t  state.readableListening = self.listenerCount('readable') > 0;\n\n\t  if (state.resumeScheduled && !state.paused) {\n\t    // flowing needs to be set to true now, otherwise\n\t    // the upcoming resume will not flow.\n\t    state.flowing = true; // crude way to check if we should resume\n\t  } else if (self.listenerCount('data') > 0) {\n\t    self.resume();\n\t  }\n\t}\n\n\tfunction nReadingNextTick(self) {\n\t  debug('readable nexttick read 0');\n\t  self.read(0);\n\t} // pause() and resume() are remnants of the legacy readable stream API\n\t// If the user uses them, then switch into old mode.\n\n\n\tReadable.prototype.resume = function () {\n\t  var state = this._readableState;\n\n\t  if (!state.flowing) {\n\t    debug('resume'); // we flow only if there is no one listening\n\t    // for readable, but we still have to call\n\t    // resume()\n\n\t    state.flowing = !state.readableListening;\n\t    resume(this, state);\n\t  }\n\n\t  state.paused = false;\n\t  return this;\n\t};\n\n\tfunction resume(stream, state) {\n\t  if (!state.resumeScheduled) {\n\t    state.resumeScheduled = true;\n\t    process.nextTick(resume_, stream, state);\n\t  }\n\t}\n\n\tfunction resume_(stream, state) {\n\t  debug('resume', state.reading);\n\n\t  if (!state.reading) {\n\t    stream.read(0);\n\t  }\n\n\t  state.resumeScheduled = false;\n\t  stream.emit('resume');\n\t  flow(stream);\n\t  if (state.flowing && !state.reading) stream.read(0);\n\t}\n\n\tReadable.prototype.pause = function () {\n\t  debug('call pause flowing=%j', this._readableState.flowing);\n\n\t  if (this._readableState.flowing !== false) {\n\t    debug('pause');\n\t    this._readableState.flowing = false;\n\t    this.emit('pause');\n\t  }\n\n\t  this._readableState.paused = true;\n\t  return this;\n\t};\n\n\tfunction flow(stream) {\n\t  var state = stream._readableState;\n\t  debug('flow', state.flowing);\n\n\t  while (state.flowing && stream.read() !== null) {\n\t    ;\n\t  }\n\t} // wrap an old-style stream as the async data source.\n\t// This is *not* part of the readable stream interface.\n\t// It is an ugly unfortunate mess of history.\n\n\n\tReadable.prototype.wrap = function (stream) {\n\t  var _this = this;\n\n\t  var state = this._readableState;\n\t  var paused = false;\n\t  stream.on('end', function () {\n\t    debug('wrapped end');\n\n\t    if (state.decoder && !state.ended) {\n\t      var chunk = state.decoder.end();\n\t      if (chunk && chunk.length) _this.push(chunk);\n\t    }\n\n\t    _this.push(null);\n\t  });\n\t  stream.on('data', function (chunk) {\n\t    debug('wrapped data');\n\t    if (state.decoder) chunk = state.decoder.write(chunk); // don't skip over falsy values in objectMode\n\n\t    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n\t    var ret = _this.push(chunk);\n\n\t    if (!ret) {\n\t      paused = true;\n\t      stream.pause();\n\t    }\n\t  }); // proxy all the other methods.\n\t  // important when wrapping filters and duplexes.\n\n\t  for (var i in stream) {\n\t    if (this[i] === undefined && typeof stream[i] === 'function') {\n\t      this[i] = function methodWrap(method) {\n\t        return function methodWrapReturnFunction() {\n\t          return stream[method].apply(stream, arguments);\n\t        };\n\t      }(i);\n\t    }\n\t  } // proxy certain important events.\n\n\n\t  for (var n = 0; n < kProxyEvents.length; n++) {\n\t    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n\t  } // when we try to consume some more bytes, simply unpause the\n\t  // underlying stream.\n\n\n\t  this._read = function (n) {\n\t    debug('wrapped _read', n);\n\n\t    if (paused) {\n\t      paused = false;\n\t      stream.resume();\n\t    }\n\t  };\n\n\t  return this;\n\t};\n\n\tif (typeof Symbol === 'function') {\n\t  Readable.prototype[Symbol.asyncIterator] = function () {\n\t    if (createReadableStreamAsyncIterator === undefined) {\n\t      createReadableStreamAsyncIterator = require$$11();\n\t    }\n\n\t    return createReadableStreamAsyncIterator(this);\n\t  };\n\t}\n\n\tObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n\t  // making it explicit this property is not enumerable\n\t  // because otherwise some prototype manipulation in\n\t  // userland will fail\n\t  enumerable: false,\n\t  get: function get() {\n\t    return this._readableState.highWaterMark;\n\t  }\n\t});\n\tObject.defineProperty(Readable.prototype, 'readableBuffer', {\n\t  // making it explicit this property is not enumerable\n\t  // because otherwise some prototype manipulation in\n\t  // userland will fail\n\t  enumerable: false,\n\t  get: function get() {\n\t    return this._readableState && this._readableState.buffer;\n\t  }\n\t});\n\tObject.defineProperty(Readable.prototype, 'readableFlowing', {\n\t  // making it explicit this property is not enumerable\n\t  // because otherwise some prototype manipulation in\n\t  // userland will fail\n\t  enumerable: false,\n\t  get: function get() {\n\t    return this._readableState.flowing;\n\t  },\n\t  set: function set(state) {\n\t    if (this._readableState) {\n\t      this._readableState.flowing = state;\n\t    }\n\t  }\n\t}); // exposed for testing purposes only.\n\n\tReadable._fromList = fromList;\n\tObject.defineProperty(Readable.prototype, 'readableLength', {\n\t  // making it explicit this property is not enumerable\n\t  // because otherwise some prototype manipulation in\n\t  // userland will fail\n\t  enumerable: false,\n\t  get: function get() {\n\t    return this._readableState.length;\n\t  }\n\t}); // Pluck off n bytes from an array of buffers.\n\t// Length is the combined lengths of all the buffers in the list.\n\t// This function is designed to be inlinable, so please take care when making\n\t// changes to the function body.\n\n\tfunction fromList(n, state) {\n\t  // nothing buffered\n\t  if (state.length === 0) return null;\n\t  var ret;\n\t  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n\t    // read it all, truncate the list\n\t    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.first();else ret = state.buffer.concat(state.length);\n\t    state.buffer.clear();\n\t  } else {\n\t    // read part of list\n\t    ret = state.buffer.consume(n, state.decoder);\n\t  }\n\t  return ret;\n\t}\n\n\tfunction endReadable(stream) {\n\t  var state = stream._readableState;\n\t  debug('endReadable', state.endEmitted);\n\n\t  if (!state.endEmitted) {\n\t    state.ended = true;\n\t    process.nextTick(endReadableNT, state, stream);\n\t  }\n\t}\n\n\tfunction endReadableNT(state, stream) {\n\t  debug('endReadableNT', state.endEmitted, state.length); // Check that we didn't get one last unshift.\n\n\t  if (!state.endEmitted && state.length === 0) {\n\t    state.endEmitted = true;\n\t    stream.readable = false;\n\t    stream.emit('end');\n\n\t    if (state.autoDestroy) {\n\t      // In case of duplex streams we need a way to detect\n\t      // if the writable side is ready for autoDestroy as well\n\t      var wState = stream._writableState;\n\n\t      if (!wState || wState.autoDestroy && wState.finished) {\n\t        stream.destroy();\n\t      }\n\t    }\n\t  }\n\t}\n\n\tif (typeof Symbol === 'function') {\n\t  Readable.from = function (iterable, opts) {\n\t    if (from === undefined) {\n\t      from = require$$12();\n\t    }\n\n\t    return from(Readable, iterable, opts);\n\t  };\n\t}\n\n\tfunction indexOf(xs, x) {\n\t  for (var i = 0, l = xs.length; i < l; i++) {\n\t    if (xs[i] === x) return i;\n\t  }\n\n\t  return -1;\n\t}\n\treturn _stream_readable;\n}\n\nexport { require_stream_readable as __require };","start":1670465470187,"end":1670465470203,"order":"normal"}]}
