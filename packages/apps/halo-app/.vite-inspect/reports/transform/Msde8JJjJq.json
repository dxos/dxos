{"resolvedId":"/home/jdw/Code/dxos/dxos/node_modules/.pnpm/hypercore@9.12.0/node_modules/hypercore/lib/storage.js","transforms":[{"name":"vite:load-fallback","result":"var uint64be = require('uint64be')\nvar flat = require('flat-tree')\nvar createCache = require('./cache')\n\nmodule.exports = Storage\n\nvar noarr = []\n\nfunction Storage (create, opts) {\n  if (!(this instanceof Storage)) return new Storage(create, opts)\n\n  const cache = createCache(opts)\n\n  this.treeCache = cache.tree || null\n  this.dataCache = cache.data || null\n  this.key = null\n  this.secretKey = null\n  this.tree = null\n  this.data = null\n  this.bitfield = null\n  this.signatures = null\n  this.create = create\n}\n\nStorage.prototype.putData = function (index, data, nodes, cb) {\n  if (!cb) cb = noop\n  var self = this\n  if (!data.length) return cb(null)\n  this.dataOffset(index, nodes, function (err, offset, size) {\n    if (err) return cb(err)\n    if (size !== data.length) return cb(new Error('Unexpected data size'))\n    self.data.write(offset, data, cb)\n  })\n}\n\nStorage.prototype.getData = function (index, cb) {\n  var self = this\n  var cached = this.dataCache && this.dataCache.get(index)\n  if (cached) return process.nextTick(cb, null, cached)\n  this.dataOffset(index, noarr, function (err, offset, size) {\n    if (err) return cb(err)\n    self.data.read(offset, size, (err, data) => {\n      if (err) return cb(err)\n      if (self.dataCache) self.dataCache.set(index, data)\n      return cb(null, data)\n    })\n  })\n}\n\nStorage.prototype.nextSignature = function (index, cb) {\n  var self = this\n\n  this._getSignature(index, function (err, signature) {\n    if (err) return cb(err)\n    if (isBlank(signature)) return self.nextSignature(index + 1, cb)\n    cb(null, { index: index, signature: signature })\n  })\n}\n\nStorage.prototype.getSignature = function (index, cb) {\n  this._getSignature(index, function (err, signature) {\n    if (err) return cb(err)\n    if (isBlank(signature)) return cb(new Error('No signature found'))\n    cb(null, signature)\n  })\n}\n\n// Caching not enabled for signatures because they are rarely reused.\nStorage.prototype._getSignature = function (index, cb) {\n  this.signatures.read(32 + 64 * index, 64, cb)\n}\n\nStorage.prototype.putSignature = function (index, signature, cb) {\n  this.signatures.write(32 + 64 * index, signature, cb)\n}\n\nStorage.prototype.deleteSignatures = function (start, end, cb) {\n  this.signatures.del(32 + 64 * start, (end - start) * 64, cb)\n}\n\nStorage.prototype.dataOffset = function (index, cachedNodes, cb) {\n  var roots = flat.fullRoots(2 * index)\n  var self = this\n  var offset = 0\n  var pending = roots.length\n  var error = null\n  var blk = 2 * index\n\n  if (!pending) {\n    pending = 1\n    onnode(null, null)\n    return\n  }\n\n  for (var i = 0; i < roots.length; i++) {\n    var node = findNode(cachedNodes, roots[i])\n    if (node) onnode(null, node)\n    else this.getNode(roots[i], onnode)\n  }\n\n  function onlast (err, node) {\n    if (err) return cb(err)\n    cb(null, offset, node.size)\n  }\n\n  function onnode (err, node) {\n    if (err) error = err\n    if (node) offset += node.size\n    if (--pending) return\n\n    if (error) return cb(error)\n\n    var last = findNode(cachedNodes, blk)\n    if (last) onlast(null, last)\n    else self.getNode(blk, onlast)\n  }\n}\n\n// Caching not enabled for batch reads because they'd be complicated to batch and they're rarely used.\nStorage.prototype.getDataBatch = function (start, n, cb) {\n  var result = new Array(n)\n  var sizes = new Array(n)\n  var self = this\n\n  this.dataOffset(start, noarr, function (err, offset, size) {\n    if (err) return cb(err)\n\n    start++\n    n--\n\n    if (n <= 0) return ontree(null, null)\n    self.tree.read(32 + 80 * start, 80 * n - 40, ontree)\n\n    function ontree (err, buf) {\n      if (err) return cb(err)\n\n      var total = sizes[0] = size\n\n      if (buf) {\n        for (var i = 1; i < sizes.length; i++) {\n          sizes[i] = uint64be.decode(buf, 32 + (i - 1) * 80)\n          total += sizes[i]\n        }\n      }\n\n      self.data.read(offset, total, ondata)\n    }\n\n    function ondata (err, buf) {\n      if (err) return cb(err)\n      var total = 0\n      for (var i = 0; i < result.length; i++) {\n        result[i] = buf.slice(total, total += sizes[i])\n      }\n\n      cb(null, result)\n    }\n  })\n}\n\nStorage.prototype.getNode = function (index, cb) {\n  if (this.treeCache) {\n    var cached = this.treeCache.get(index)\n    if (cached) return cb(null, cached)\n  }\n\n  var self = this\n\n  this.tree.read(32 + 40 * index, 40, function (err, buf) {\n    if (err) return cb(err)\n\n    var hash = buf.slice(0, 32)\n    var size = uint64be.decode(buf, 32)\n\n    if (!size && isBlank(hash)) return cb(new Error('No node found'))\n\n    var val = new Node(index, self.treeCache ? copyMaybe(hash, 40) : hash, size, null)\n    if (self.treeCache) self.treeCache.set(index, val)\n    cb(null, val)\n  })\n}\n\nStorage.prototype.putNodeBatch = function (index, nodes, cb) {\n  if (!cb) cb = noop\n\n  var buf = Buffer.alloc(nodes.length * 40)\n\n  for (var i = 0; i < nodes.length; i++) {\n    var offset = i * 40\n    var node = nodes[i]\n    if (!node) continue\n    node.hash.copy(buf, offset)\n    uint64be.encode(node.size, buf, 32 + offset)\n  }\n\n  this.tree.write(32 + 40 * index, buf, cb)\n}\n\nStorage.prototype.putNode = function (index, node, cb) {\n  if (!cb) cb = noop\n\n  // TODO: re-enable put cache. currently this causes a memleak\n  // because node.hash is a slice of the big data buffer on replicate\n  // if (this.cache) this.cache.set(index, node)\n\n  var buf = Buffer.allocUnsafe(40)\n\n  node.hash.copy(buf, 0)\n  uint64be.encode(node.size, buf, 32)\n  this.tree.write(32 + 40 * index, buf, cb)\n}\n\nStorage.prototype.putBitfield = function (offset, data, cb) {\n  this.bitfield.write(32 + offset, data, cb)\n}\n\nStorage.prototype.close = function (cb) {\n  if (!cb) cb = noop\n  var missing = 6\n  var error = null\n\n  close(this.bitfield, done)\n  close(this.tree, done)\n  close(this.data, done)\n  close(this.key, done)\n  close(this.secretKey, done)\n  close(this.signatures, done)\n\n  function done (err) {\n    if (err) error = err\n    if (--missing) return\n    cb(error)\n  }\n}\n\nStorage.prototype.destroy = function (cb) {\n  if (!cb) cb = noop\n  var missing = 6\n  var error = null\n\n  destroy(this.bitfield, done)\n  destroy(this.tree, done)\n  destroy(this.data, done)\n  destroy(this.key, done)\n  destroy(this.secretKey, done)\n  destroy(this.signatures, done)\n\n  function done (err) {\n    if (err) error = err\n    if (--missing) return\n    cb(error)\n  }\n}\n\nStorage.prototype.openKey = function (opts, cb) {\n  if (typeof opts === 'function') return this.openKey({}, opts)\n  if (!this.key) this.key = this.create('key', opts)\n  this.key.read(0, 32, cb)\n}\n\nStorage.prototype.open = function (opts, cb) {\n  if (typeof opts === 'function') return this.open({}, opts)\n\n  var self = this\n  var error = null\n  var missing = 5\n\n  if (!this.key) this.key = this.create('key', opts)\n  if (!this.secretKey) this.secretKey = this.create('secret_key', opts)\n  if (!this.tree) this.tree = this.create('tree', opts)\n  if (!this.data) this.data = this.create('data', opts)\n  if (!this.bitfield) this.bitfield = this.create('bitfield', opts)\n  if (!this.signatures) this.signatures = this.create('signatures', opts)\n\n  var result = {\n    bitfield: [],\n    bitfieldPageSize: 3584, // we upgraded the page size to fix a bug\n    secretKey: null,\n    key: null\n  }\n\n  this.bitfield.read(0, 32, function (err, h) {\n    if (err && err.code === 'ELOCKED') return cb(err)\n    if (h) result.bitfieldPageSize = h.readUInt16BE(5)\n    self.bitfield.write(0, header(0, result.bitfieldPageSize, null), function (err) {\n      if (err) return cb(err)\n      readAll(self.bitfield, 32, result.bitfieldPageSize, function (err, pages) {\n        if (pages) result.bitfield = pages\n        done(err)\n      })\n    })\n  })\n\n  this.signatures.write(0, header(1, 64, 'Ed25519'), done)\n  this.tree.write(0, header(2, 40, 'BLAKE2b'), done)\n\n  // TODO: Improve the error handling here.\n  // I.e. if secretKey length === 64 and it fails, error\n\n  this.secretKey.read(0, 64, function (_, data) {\n    if (data) result.secretKey = data\n    done(null)\n  })\n\n  this.key.read(0, 32, function (_, data) {\n    if (data) result.key = data\n    done(null)\n  })\n\n  function done (err) {\n    if (err) error = err\n    if (--missing) return\n    if (error) cb(error)\n    else cb(null, result)\n  }\n}\n\nStorage.Node = Node\n\nfunction noop () {}\n\nfunction copyMaybe (buf, maxSize) {\n  if (buf.buffer.byteLength <= maxSize) return buf\n  const cpy = Buffer.alloc(buf.byteLength)\n  buf.copy(cpy)\n  return cpy\n}\n\nfunction header (type, size, name) {\n  var buf = Buffer.alloc(32)\n\n  // magic number\n  buf[0] = 5\n  buf[1] = 2\n  buf[2] = 87\n  buf[3] = type\n\n  // version\n  buf[4] = 0\n\n  // block size\n  buf.writeUInt16BE(size, 5)\n\n  if (name) {\n    // algo name\n    buf[7] = name.length\n    buf.write(name, 8)\n  }\n\n  return buf\n}\n\nfunction Node (index, hash, size) {\n  this.index = index\n  this.hash = hash\n  this.size = size\n}\n\nfunction findNode (nodes, index) {\n  for (var i = 0; i < nodes.length; i++) {\n    if (nodes[i].index === index) return nodes[i]\n  }\n  return null\n}\n\nfunction isBlank (buf) {\n  for (var i = 0; i < buf.length; i++) {\n    if (buf[i]) return false\n  }\n  return true\n}\n\nfunction close (st, cb) {\n  if (st.close) st.close(cb)\n  else cb()\n}\n\nfunction destroy (st, cb) {\n  if (st.destroy) st.destroy(cb)\n  else cb()\n}\n\nfunction statAndReadAll (st, offset, pageSize, cb) {\n  st.stat(function (err, stat) {\n    if (err) return cb(null, [])\n\n    var result = []\n\n    loop(null, null)\n\n    function loop (err, batch) {\n      if (err) return cb(err)\n\n      if (batch) {\n        offset += batch.length\n        for (var i = 0; i < batch.length; i += pageSize) {\n          result.push(batch.slice(i, i + pageSize))\n        }\n      }\n\n      var next = Math.min(stat.size - offset, 32 * pageSize)\n      if (!next) return cb(null, result)\n\n      st.read(offset, next, loop)\n    }\n  })\n}\n\nfunction readAll (st, offset, pageSize, cb) {\n  if (st.statable === true) return statAndReadAll(st, offset, pageSize, cb)\n\n  var bufs = []\n\n  st.read(offset, pageSize, loop)\n\n  function loop (err, buf) {\n    if (err) return cb(null, bufs)\n    bufs.push(buf)\n    st.read(offset + bufs.length * pageSize, pageSize, loop)\n  }\n}\n","start":1670465469169,"end":1670465469241},{"name":"vite:react-babel","result":"var uint64be = require('uint64be')\nvar flat = require('flat-tree')\nvar createCache = require('./cache')\n\nmodule.exports = Storage\n\nvar noarr = []\n\nfunction Storage (create, opts) {\n  if (!(this instanceof Storage)) return new Storage(create, opts)\n\n  const cache = createCache(opts)\n\n  this.treeCache = cache.tree || null\n  this.dataCache = cache.data || null\n  this.key = null\n  this.secretKey = null\n  this.tree = null\n  this.data = null\n  this.bitfield = null\n  this.signatures = null\n  this.create = create\n}\n\nStorage.prototype.putData = function (index, data, nodes, cb) {\n  if (!cb) cb = noop\n  var self = this\n  if (!data.length) return cb(null)\n  this.dataOffset(index, nodes, function (err, offset, size) {\n    if (err) return cb(err)\n    if (size !== data.length) return cb(new Error('Unexpected data size'))\n    self.data.write(offset, data, cb)\n  })\n}\n\nStorage.prototype.getData = function (index, cb) {\n  var self = this\n  var cached = this.dataCache && this.dataCache.get(index)\n  if (cached) return process.nextTick(cb, null, cached)\n  this.dataOffset(index, noarr, function (err, offset, size) {\n    if (err) return cb(err)\n    self.data.read(offset, size, (err, data) => {\n      if (err) return cb(err)\n      if (self.dataCache) self.dataCache.set(index, data)\n      return cb(null, data)\n    })\n  })\n}\n\nStorage.prototype.nextSignature = function (index, cb) {\n  var self = this\n\n  this._getSignature(index, function (err, signature) {\n    if (err) return cb(err)\n    if (isBlank(signature)) return self.nextSignature(index + 1, cb)\n    cb(null, { index: index, signature: signature })\n  })\n}\n\nStorage.prototype.getSignature = function (index, cb) {\n  this._getSignature(index, function (err, signature) {\n    if (err) return cb(err)\n    if (isBlank(signature)) return cb(new Error('No signature found'))\n    cb(null, signature)\n  })\n}\n\n// Caching not enabled for signatures because they are rarely reused.\nStorage.prototype._getSignature = function (index, cb) {\n  this.signatures.read(32 + 64 * index, 64, cb)\n}\n\nStorage.prototype.putSignature = function (index, signature, cb) {\n  this.signatures.write(32 + 64 * index, signature, cb)\n}\n\nStorage.prototype.deleteSignatures = function (start, end, cb) {\n  this.signatures.del(32 + 64 * start, (end - start) * 64, cb)\n}\n\nStorage.prototype.dataOffset = function (index, cachedNodes, cb) {\n  var roots = flat.fullRoots(2 * index)\n  var self = this\n  var offset = 0\n  var pending = roots.length\n  var error = null\n  var blk = 2 * index\n\n  if (!pending) {\n    pending = 1\n    onnode(null, null)\n    return\n  }\n\n  for (var i = 0; i < roots.length; i++) {\n    var node = findNode(cachedNodes, roots[i])\n    if (node) onnode(null, node)\n    else this.getNode(roots[i], onnode)\n  }\n\n  function onlast (err, node) {\n    if (err) return cb(err)\n    cb(null, offset, node.size)\n  }\n\n  function onnode (err, node) {\n    if (err) error = err\n    if (node) offset += node.size\n    if (--pending) return\n\n    if (error) return cb(error)\n\n    var last = findNode(cachedNodes, blk)\n    if (last) onlast(null, last)\n    else self.getNode(blk, onlast)\n  }\n}\n\n// Caching not enabled for batch reads because they'd be complicated to batch and they're rarely used.\nStorage.prototype.getDataBatch = function (start, n, cb) {\n  var result = new Array(n)\n  var sizes = new Array(n)\n  var self = this\n\n  this.dataOffset(start, noarr, function (err, offset, size) {\n    if (err) return cb(err)\n\n    start++\n    n--\n\n    if (n <= 0) return ontree(null, null)\n    self.tree.read(32 + 80 * start, 80 * n - 40, ontree)\n\n    function ontree (err, buf) {\n      if (err) return cb(err)\n\n      var total = sizes[0] = size\n\n      if (buf) {\n        for (var i = 1; i < sizes.length; i++) {\n          sizes[i] = uint64be.decode(buf, 32 + (i - 1) * 80)\n          total += sizes[i]\n        }\n      }\n\n      self.data.read(offset, total, ondata)\n    }\n\n    function ondata (err, buf) {\n      if (err) return cb(err)\n      var total = 0\n      for (var i = 0; i < result.length; i++) {\n        result[i] = buf.slice(total, total += sizes[i])\n      }\n\n      cb(null, result)\n    }\n  })\n}\n\nStorage.prototype.getNode = function (index, cb) {\n  if (this.treeCache) {\n    var cached = this.treeCache.get(index)\n    if (cached) return cb(null, cached)\n  }\n\n  var self = this\n\n  this.tree.read(32 + 40 * index, 40, function (err, buf) {\n    if (err) return cb(err)\n\n    var hash = buf.slice(0, 32)\n    var size = uint64be.decode(buf, 32)\n\n    if (!size && isBlank(hash)) return cb(new Error('No node found'))\n\n    var val = new Node(index, self.treeCache ? copyMaybe(hash, 40) : hash, size, null)\n    if (self.treeCache) self.treeCache.set(index, val)\n    cb(null, val)\n  })\n}\n\nStorage.prototype.putNodeBatch = function (index, nodes, cb) {\n  if (!cb) cb = noop\n\n  var buf = Buffer.alloc(nodes.length * 40)\n\n  for (var i = 0; i < nodes.length; i++) {\n    var offset = i * 40\n    var node = nodes[i]\n    if (!node) continue\n    node.hash.copy(buf, offset)\n    uint64be.encode(node.size, buf, 32 + offset)\n  }\n\n  this.tree.write(32 + 40 * index, buf, cb)\n}\n\nStorage.prototype.putNode = function (index, node, cb) {\n  if (!cb) cb = noop\n\n  // TODO: re-enable put cache. currently this causes a memleak\n  // because node.hash is a slice of the big data buffer on replicate\n  // if (this.cache) this.cache.set(index, node)\n\n  var buf = Buffer.allocUnsafe(40)\n\n  node.hash.copy(buf, 0)\n  uint64be.encode(node.size, buf, 32)\n  this.tree.write(32 + 40 * index, buf, cb)\n}\n\nStorage.prototype.putBitfield = function (offset, data, cb) {\n  this.bitfield.write(32 + offset, data, cb)\n}\n\nStorage.prototype.close = function (cb) {\n  if (!cb) cb = noop\n  var missing = 6\n  var error = null\n\n  close(this.bitfield, done)\n  close(this.tree, done)\n  close(this.data, done)\n  close(this.key, done)\n  close(this.secretKey, done)\n  close(this.signatures, done)\n\n  function done (err) {\n    if (err) error = err\n    if (--missing) return\n    cb(error)\n  }\n}\n\nStorage.prototype.destroy = function (cb) {\n  if (!cb) cb = noop\n  var missing = 6\n  var error = null\n\n  destroy(this.bitfield, done)\n  destroy(this.tree, done)\n  destroy(this.data, done)\n  destroy(this.key, done)\n  destroy(this.secretKey, done)\n  destroy(this.signatures, done)\n\n  function done (err) {\n    if (err) error = err\n    if (--missing) return\n    cb(error)\n  }\n}\n\nStorage.prototype.openKey = function (opts, cb) {\n  if (typeof opts === 'function') return this.openKey({}, opts)\n  if (!this.key) this.key = this.create('key', opts)\n  this.key.read(0, 32, cb)\n}\n\nStorage.prototype.open = function (opts, cb) {\n  if (typeof opts === 'function') return this.open({}, opts)\n\n  var self = this\n  var error = null\n  var missing = 5\n\n  if (!this.key) this.key = this.create('key', opts)\n  if (!this.secretKey) this.secretKey = this.create('secret_key', opts)\n  if (!this.tree) this.tree = this.create('tree', opts)\n  if (!this.data) this.data = this.create('data', opts)\n  if (!this.bitfield) this.bitfield = this.create('bitfield', opts)\n  if (!this.signatures) this.signatures = this.create('signatures', opts)\n\n  var result = {\n    bitfield: [],\n    bitfieldPageSize: 3584, // we upgraded the page size to fix a bug\n    secretKey: null,\n    key: null\n  }\n\n  this.bitfield.read(0, 32, function (err, h) {\n    if (err && err.code === 'ELOCKED') return cb(err)\n    if (h) result.bitfieldPageSize = h.readUInt16BE(5)\n    self.bitfield.write(0, header(0, result.bitfieldPageSize, null), function (err) {\n      if (err) return cb(err)\n      readAll(self.bitfield, 32, result.bitfieldPageSize, function (err, pages) {\n        if (pages) result.bitfield = pages\n        done(err)\n      })\n    })\n  })\n\n  this.signatures.write(0, header(1, 64, 'Ed25519'), done)\n  this.tree.write(0, header(2, 40, 'BLAKE2b'), done)\n\n  // TODO: Improve the error handling here.\n  // I.e. if secretKey length === 64 and it fails, error\n\n  this.secretKey.read(0, 64, function (_, data) {\n    if (data) result.secretKey = data\n    done(null)\n  })\n\n  this.key.read(0, 32, function (_, data) {\n    if (data) result.key = data\n    done(null)\n  })\n\n  function done (err) {\n    if (err) error = err\n    if (--missing) return\n    if (error) cb(error)\n    else cb(null, result)\n  }\n}\n\nStorage.Node = Node\n\nfunction noop () {}\n\nfunction copyMaybe (buf, maxSize) {\n  if (buf.buffer.byteLength <= maxSize) return buf\n  const cpy = Buffer.alloc(buf.byteLength)\n  buf.copy(cpy)\n  return cpy\n}\n\nfunction header (type, size, name) {\n  var buf = Buffer.alloc(32)\n\n  // magic number\n  buf[0] = 5\n  buf[1] = 2\n  buf[2] = 87\n  buf[3] = type\n\n  // version\n  buf[4] = 0\n\n  // block size\n  buf.writeUInt16BE(size, 5)\n\n  if (name) {\n    // algo name\n    buf[7] = name.length\n    buf.write(name, 8)\n  }\n\n  return buf\n}\n\nfunction Node (index, hash, size) {\n  this.index = index\n  this.hash = hash\n  this.size = size\n}\n\nfunction findNode (nodes, index) {\n  for (var i = 0; i < nodes.length; i++) {\n    if (nodes[i].index === index) return nodes[i]\n  }\n  return null\n}\n\nfunction isBlank (buf) {\n  for (var i = 0; i < buf.length; i++) {\n    if (buf[i]) return false\n  }\n  return true\n}\n\nfunction close (st, cb) {\n  if (st.close) st.close(cb)\n  else cb()\n}\n\nfunction destroy (st, cb) {\n  if (st.destroy) st.destroy(cb)\n  else cb()\n}\n\nfunction statAndReadAll (st, offset, pageSize, cb) {\n  st.stat(function (err, stat) {\n    if (err) return cb(null, [])\n\n    var result = []\n\n    loop(null, null)\n\n    function loop (err, batch) {\n      if (err) return cb(err)\n\n      if (batch) {\n        offset += batch.length\n        for (var i = 0; i < batch.length; i += pageSize) {\n          result.push(batch.slice(i, i + pageSize))\n        }\n      }\n\n      var next = Math.min(stat.size - offset, 32 * pageSize)\n      if (!next) return cb(null, result)\n\n      st.read(offset, next, loop)\n    }\n  })\n}\n\nfunction readAll (st, offset, pageSize, cb) {\n  if (st.statable === true) return statAndReadAll(st, offset, pageSize, cb)\n\n  var bufs = []\n\n  st.read(offset, pageSize, loop)\n\n  function loop (err, buf) {\n    if (err) return cb(null, bufs)\n    bufs.push(buf)\n    st.read(offset + bufs.length * pageSize, pageSize, loop)\n  }\n}\n","start":1670465469241,"end":1670465469241,"order":"pre"},{"name":"commonjs","result":"import * as commonjsHelpers from \"\u0000commonjsHelpers.js\";\nimport require$$0 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/uint64be@2.0.2/node_modules/uint64be/index.js?commonjs-proxy\";\nimport require$$1 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/flat-tree@1.9.0/node_modules/flat-tree/index.js?commonjs-proxy\";\nimport require$$2 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/hypercore@9.12.0/node_modules/hypercore/lib/cache.js?commonjs-proxy\";\n\nvar uint64be = require$$0\nvar flat = require$$1\nvar createCache = require$$2\n\nvar storage = Storage\n\nvar noarr = []\n\nfunction Storage (create, opts) {\n  if (!(this instanceof Storage)) return new Storage(create, opts)\n\n  const cache = createCache(opts)\n\n  this.treeCache = cache.tree || null\n  this.dataCache = cache.data || null\n  this.key = null\n  this.secretKey = null\n  this.tree = null\n  this.data = null\n  this.bitfield = null\n  this.signatures = null\n  this.create = create\n}\n\nStorage.prototype.putData = function (index, data, nodes, cb) {\n  if (!cb) cb = noop\n  var self = this\n  if (!data.length) return cb(null)\n  this.dataOffset(index, nodes, function (err, offset, size) {\n    if (err) return cb(err)\n    if (size !== data.length) return cb(new Error('Unexpected data size'))\n    self.data.write(offset, data, cb)\n  })\n}\n\nStorage.prototype.getData = function (index, cb) {\n  var self = this\n  var cached = this.dataCache && this.dataCache.get(index)\n  if (cached) return process.nextTick(cb, null, cached)\n  this.dataOffset(index, noarr, function (err, offset, size) {\n    if (err) return cb(err)\n    self.data.read(offset, size, (err, data) => {\n      if (err) return cb(err)\n      if (self.dataCache) self.dataCache.set(index, data)\n      return cb(null, data)\n    })\n  })\n}\n\nStorage.prototype.nextSignature = function (index, cb) {\n  var self = this\n\n  this._getSignature(index, function (err, signature) {\n    if (err) return cb(err)\n    if (isBlank(signature)) return self.nextSignature(index + 1, cb)\n    cb(null, { index: index, signature: signature })\n  })\n}\n\nStorage.prototype.getSignature = function (index, cb) {\n  this._getSignature(index, function (err, signature) {\n    if (err) return cb(err)\n    if (isBlank(signature)) return cb(new Error('No signature found'))\n    cb(null, signature)\n  })\n}\n\n// Caching not enabled for signatures because they are rarely reused.\nStorage.prototype._getSignature = function (index, cb) {\n  this.signatures.read(32 + 64 * index, 64, cb)\n}\n\nStorage.prototype.putSignature = function (index, signature, cb) {\n  this.signatures.write(32 + 64 * index, signature, cb)\n}\n\nStorage.prototype.deleteSignatures = function (start, end, cb) {\n  this.signatures.del(32 + 64 * start, (end - start) * 64, cb)\n}\n\nStorage.prototype.dataOffset = function (index, cachedNodes, cb) {\n  var roots = flat.fullRoots(2 * index)\n  var self = this\n  var offset = 0\n  var pending = roots.length\n  var error = null\n  var blk = 2 * index\n\n  if (!pending) {\n    pending = 1\n    onnode(null, null)\n    return\n  }\n\n  for (var i = 0; i < roots.length; i++) {\n    var node = findNode(cachedNodes, roots[i])\n    if (node) onnode(null, node)\n    else this.getNode(roots[i], onnode)\n  }\n\n  function onlast (err, node) {\n    if (err) return cb(err)\n    cb(null, offset, node.size)\n  }\n\n  function onnode (err, node) {\n    if (err) error = err\n    if (node) offset += node.size\n    if (--pending) return\n\n    if (error) return cb(error)\n\n    var last = findNode(cachedNodes, blk)\n    if (last) onlast(null, last)\n    else self.getNode(blk, onlast)\n  }\n}\n\n// Caching not enabled for batch reads because they'd be complicated to batch and they're rarely used.\nStorage.prototype.getDataBatch = function (start, n, cb) {\n  var result = new Array(n)\n  var sizes = new Array(n)\n  var self = this\n\n  this.dataOffset(start, noarr, function (err, offset, size) {\n    if (err) return cb(err)\n\n    start++\n    n--\n\n    if (n <= 0) return ontree(null, null)\n    self.tree.read(32 + 80 * start, 80 * n - 40, ontree)\n\n    function ontree (err, buf) {\n      if (err) return cb(err)\n\n      var total = sizes[0] = size\n\n      if (buf) {\n        for (var i = 1; i < sizes.length; i++) {\n          sizes[i] = uint64be.decode(buf, 32 + (i - 1) * 80)\n          total += sizes[i]\n        }\n      }\n\n      self.data.read(offset, total, ondata)\n    }\n\n    function ondata (err, buf) {\n      if (err) return cb(err)\n      var total = 0\n      for (var i = 0; i < result.length; i++) {\n        result[i] = buf.slice(total, total += sizes[i])\n      }\n\n      cb(null, result)\n    }\n  })\n}\n\nStorage.prototype.getNode = function (index, cb) {\n  if (this.treeCache) {\n    var cached = this.treeCache.get(index)\n    if (cached) return cb(null, cached)\n  }\n\n  var self = this\n\n  this.tree.read(32 + 40 * index, 40, function (err, buf) {\n    if (err) return cb(err)\n\n    var hash = buf.slice(0, 32)\n    var size = uint64be.decode(buf, 32)\n\n    if (!size && isBlank(hash)) return cb(new Error('No node found'))\n\n    var val = new Node(index, self.treeCache ? copyMaybe(hash, 40) : hash, size, null)\n    if (self.treeCache) self.treeCache.set(index, val)\n    cb(null, val)\n  })\n}\n\nStorage.prototype.putNodeBatch = function (index, nodes, cb) {\n  if (!cb) cb = noop\n\n  var buf = Buffer.alloc(nodes.length * 40)\n\n  for (var i = 0; i < nodes.length; i++) {\n    var offset = i * 40\n    var node = nodes[i]\n    if (!node) continue\n    node.hash.copy(buf, offset)\n    uint64be.encode(node.size, buf, 32 + offset)\n  }\n\n  this.tree.write(32 + 40 * index, buf, cb)\n}\n\nStorage.prototype.putNode = function (index, node, cb) {\n  if (!cb) cb = noop\n\n  // TODO: re-enable put cache. currently this causes a memleak\n  // because node.hash is a slice of the big data buffer on replicate\n  // if (this.cache) this.cache.set(index, node)\n\n  var buf = Buffer.allocUnsafe(40)\n\n  node.hash.copy(buf, 0)\n  uint64be.encode(node.size, buf, 32)\n  this.tree.write(32 + 40 * index, buf, cb)\n}\n\nStorage.prototype.putBitfield = function (offset, data, cb) {\n  this.bitfield.write(32 + offset, data, cb)\n}\n\nStorage.prototype.close = function (cb) {\n  if (!cb) cb = noop\n  var missing = 6\n  var error = null\n\n  close(this.bitfield, done)\n  close(this.tree, done)\n  close(this.data, done)\n  close(this.key, done)\n  close(this.secretKey, done)\n  close(this.signatures, done)\n\n  function done (err) {\n    if (err) error = err\n    if (--missing) return\n    cb(error)\n  }\n}\n\nStorage.prototype.destroy = function (cb) {\n  if (!cb) cb = noop\n  var missing = 6\n  var error = null\n\n  destroy(this.bitfield, done)\n  destroy(this.tree, done)\n  destroy(this.data, done)\n  destroy(this.key, done)\n  destroy(this.secretKey, done)\n  destroy(this.signatures, done)\n\n  function done (err) {\n    if (err) error = err\n    if (--missing) return\n    cb(error)\n  }\n}\n\nStorage.prototype.openKey = function (opts, cb) {\n  if (typeof opts === 'function') return this.openKey({}, opts)\n  if (!this.key) this.key = this.create('key', opts)\n  this.key.read(0, 32, cb)\n}\n\nStorage.prototype.open = function (opts, cb) {\n  if (typeof opts === 'function') return this.open({}, opts)\n\n  var self = this\n  var error = null\n  var missing = 5\n\n  if (!this.key) this.key = this.create('key', opts)\n  if (!this.secretKey) this.secretKey = this.create('secret_key', opts)\n  if (!this.tree) this.tree = this.create('tree', opts)\n  if (!this.data) this.data = this.create('data', opts)\n  if (!this.bitfield) this.bitfield = this.create('bitfield', opts)\n  if (!this.signatures) this.signatures = this.create('signatures', opts)\n\n  var result = {\n    bitfield: [],\n    bitfieldPageSize: 3584, // we upgraded the page size to fix a bug\n    secretKey: null,\n    key: null\n  }\n\n  this.bitfield.read(0, 32, function (err, h) {\n    if (err && err.code === 'ELOCKED') return cb(err)\n    if (h) result.bitfieldPageSize = h.readUInt16BE(5)\n    self.bitfield.write(0, header(0, result.bitfieldPageSize, null), function (err) {\n      if (err) return cb(err)\n      readAll(self.bitfield, 32, result.bitfieldPageSize, function (err, pages) {\n        if (pages) result.bitfield = pages\n        done(err)\n      })\n    })\n  })\n\n  this.signatures.write(0, header(1, 64, 'Ed25519'), done)\n  this.tree.write(0, header(2, 40, 'BLAKE2b'), done)\n\n  // TODO: Improve the error handling here.\n  // I.e. if secretKey length === 64 and it fails, error\n\n  this.secretKey.read(0, 64, function (_, data) {\n    if (data) result.secretKey = data\n    done(null)\n  })\n\n  this.key.read(0, 32, function (_, data) {\n    if (data) result.key = data\n    done(null)\n  })\n\n  function done (err) {\n    if (err) error = err\n    if (--missing) return\n    if (error) cb(error)\n    else cb(null, result)\n  }\n}\n\nStorage.Node = Node\n\nfunction noop () {}\n\nfunction copyMaybe (buf, maxSize) {\n  if (buf.buffer.byteLength <= maxSize) return buf\n  const cpy = Buffer.alloc(buf.byteLength)\n  buf.copy(cpy)\n  return cpy\n}\n\nfunction header (type, size, name) {\n  var buf = Buffer.alloc(32)\n\n  // magic number\n  buf[0] = 5\n  buf[1] = 2\n  buf[2] = 87\n  buf[3] = type\n\n  // version\n  buf[4] = 0\n\n  // block size\n  buf.writeUInt16BE(size, 5)\n\n  if (name) {\n    // algo name\n    buf[7] = name.length\n    buf.write(name, 8)\n  }\n\n  return buf\n}\n\nfunction Node (index, hash, size) {\n  this.index = index\n  this.hash = hash\n  this.size = size\n}\n\nfunction findNode (nodes, index) {\n  for (var i = 0; i < nodes.length; i++) {\n    if (nodes[i].index === index) return nodes[i]\n  }\n  return null\n}\n\nfunction isBlank (buf) {\n  for (var i = 0; i < buf.length; i++) {\n    if (buf[i]) return false\n  }\n  return true\n}\n\nfunction close (st, cb) {\n  if (st.close) st.close(cb)\n  else cb()\n}\n\nfunction destroy (st, cb) {\n  if (st.destroy) st.destroy(cb)\n  else cb()\n}\n\nfunction statAndReadAll (st, offset, pageSize, cb) {\n  st.stat(function (err, stat) {\n    if (err) return cb(null, [])\n\n    var result = []\n\n    loop(null, null)\n\n    function loop (err, batch) {\n      if (err) return cb(err)\n\n      if (batch) {\n        offset += batch.length\n        for (var i = 0; i < batch.length; i += pageSize) {\n          result.push(batch.slice(i, i + pageSize))\n        }\n      }\n\n      var next = Math.min(stat.size - offset, 32 * pageSize)\n      if (!next) return cb(null, result)\n\n      st.read(offset, next, loop)\n    }\n  })\n}\n\nfunction readAll (st, offset, pageSize, cb) {\n  if (st.statable === true) return statAndReadAll(st, offset, pageSize, cb)\n\n  var bufs = []\n\n  st.read(offset, pageSize, loop)\n\n  function loop (err, buf) {\n    if (err) return cb(null, bufs)\n    bufs.push(buf)\n    st.read(offset + bufs.length * pageSize, pageSize, loop)\n  }\n}\n\nexport default storage;\nexport { storage as __moduleExports };","start":1670465469241,"end":1670465470886,"order":"normal"},{"name":"polyfill-node","result":"import { default as process } from '\u0000polyfill-node.process';\n\nimport { Buffer as Buffer } from '\u0000polyfill-node.buffer';\n\nimport * as commonjsHelpers from \"\u0000commonjsHelpers.js\";\nimport require$$0 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/uint64be@2.0.2/node_modules/uint64be/index.js?commonjs-proxy\";\nimport require$$1 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/flat-tree@1.9.0/node_modules/flat-tree/index.js?commonjs-proxy\";\nimport require$$2 from \"\\u0000/home/jdw/Code/dxos/dxos/node_modules/.pnpm/hypercore@9.12.0/node_modules/hypercore/lib/cache.js?commonjs-proxy\";\n\nvar uint64be = require$$0\nvar flat = require$$1\nvar createCache = require$$2\n\nvar storage = Storage\n\nvar noarr = []\n\nfunction Storage (create, opts) {\n  if (!(this instanceof Storage)) return new Storage(create, opts)\n\n  const cache = createCache(opts)\n\n  this.treeCache = cache.tree || null\n  this.dataCache = cache.data || null\n  this.key = null\n  this.secretKey = null\n  this.tree = null\n  this.data = null\n  this.bitfield = null\n  this.signatures = null\n  this.create = create\n}\n\nStorage.prototype.putData = function (index, data, nodes, cb) {\n  if (!cb) cb = noop\n  var self = this\n  if (!data.length) return cb(null)\n  this.dataOffset(index, nodes, function (err, offset, size) {\n    if (err) return cb(err)\n    if (size !== data.length) return cb(new Error('Unexpected data size'))\n    self.data.write(offset, data, cb)\n  })\n}\n\nStorage.prototype.getData = function (index, cb) {\n  var self = this\n  var cached = this.dataCache && this.dataCache.get(index)\n  if (cached) return process.nextTick(cb, null, cached)\n  this.dataOffset(index, noarr, function (err, offset, size) {\n    if (err) return cb(err)\n    self.data.read(offset, size, (err, data) => {\n      if (err) return cb(err)\n      if (self.dataCache) self.dataCache.set(index, data)\n      return cb(null, data)\n    })\n  })\n}\n\nStorage.prototype.nextSignature = function (index, cb) {\n  var self = this\n\n  this._getSignature(index, function (err, signature) {\n    if (err) return cb(err)\n    if (isBlank(signature)) return self.nextSignature(index + 1, cb)\n    cb(null, { index: index, signature: signature })\n  })\n}\n\nStorage.prototype.getSignature = function (index, cb) {\n  this._getSignature(index, function (err, signature) {\n    if (err) return cb(err)\n    if (isBlank(signature)) return cb(new Error('No signature found'))\n    cb(null, signature)\n  })\n}\n\n// Caching not enabled for signatures because they are rarely reused.\nStorage.prototype._getSignature = function (index, cb) {\n  this.signatures.read(32 + 64 * index, 64, cb)\n}\n\nStorage.prototype.putSignature = function (index, signature, cb) {\n  this.signatures.write(32 + 64 * index, signature, cb)\n}\n\nStorage.prototype.deleteSignatures = function (start, end, cb) {\n  this.signatures.del(32 + 64 * start, (end - start) * 64, cb)\n}\n\nStorage.prototype.dataOffset = function (index, cachedNodes, cb) {\n  var roots = flat.fullRoots(2 * index)\n  var self = this\n  var offset = 0\n  var pending = roots.length\n  var error = null\n  var blk = 2 * index\n\n  if (!pending) {\n    pending = 1\n    onnode(null, null)\n    return\n  }\n\n  for (var i = 0; i < roots.length; i++) {\n    var node = findNode(cachedNodes, roots[i])\n    if (node) onnode(null, node)\n    else this.getNode(roots[i], onnode)\n  }\n\n  function onlast (err, node) {\n    if (err) return cb(err)\n    cb(null, offset, node.size)\n  }\n\n  function onnode (err, node) {\n    if (err) error = err\n    if (node) offset += node.size\n    if (--pending) return\n\n    if (error) return cb(error)\n\n    var last = findNode(cachedNodes, blk)\n    if (last) onlast(null, last)\n    else self.getNode(blk, onlast)\n  }\n}\n\n// Caching not enabled for batch reads because they'd be complicated to batch and they're rarely used.\nStorage.prototype.getDataBatch = function (start, n, cb) {\n  var result = new Array(n)\n  var sizes = new Array(n)\n  var self = this\n\n  this.dataOffset(start, noarr, function (err, offset, size) {\n    if (err) return cb(err)\n\n    start++\n    n--\n\n    if (n <= 0) return ontree(null, null)\n    self.tree.read(32 + 80 * start, 80 * n - 40, ontree)\n\n    function ontree (err, buf) {\n      if (err) return cb(err)\n\n      var total = sizes[0] = size\n\n      if (buf) {\n        for (var i = 1; i < sizes.length; i++) {\n          sizes[i] = uint64be.decode(buf, 32 + (i - 1) * 80)\n          total += sizes[i]\n        }\n      }\n\n      self.data.read(offset, total, ondata)\n    }\n\n    function ondata (err, buf) {\n      if (err) return cb(err)\n      var total = 0\n      for (var i = 0; i < result.length; i++) {\n        result[i] = buf.slice(total, total += sizes[i])\n      }\n\n      cb(null, result)\n    }\n  })\n}\n\nStorage.prototype.getNode = function (index, cb) {\n  if (this.treeCache) {\n    var cached = this.treeCache.get(index)\n    if (cached) return cb(null, cached)\n  }\n\n  var self = this\n\n  this.tree.read(32 + 40 * index, 40, function (err, buf) {\n    if (err) return cb(err)\n\n    var hash = buf.slice(0, 32)\n    var size = uint64be.decode(buf, 32)\n\n    if (!size && isBlank(hash)) return cb(new Error('No node found'))\n\n    var val = new Node(index, self.treeCache ? copyMaybe(hash, 40) : hash, size, null)\n    if (self.treeCache) self.treeCache.set(index, val)\n    cb(null, val)\n  })\n}\n\nStorage.prototype.putNodeBatch = function (index, nodes, cb) {\n  if (!cb) cb = noop\n\n  var buf = Buffer.alloc(nodes.length * 40)\n\n  for (var i = 0; i < nodes.length; i++) {\n    var offset = i * 40\n    var node = nodes[i]\n    if (!node) continue\n    node.hash.copy(buf, offset)\n    uint64be.encode(node.size, buf, 32 + offset)\n  }\n\n  this.tree.write(32 + 40 * index, buf, cb)\n}\n\nStorage.prototype.putNode = function (index, node, cb) {\n  if (!cb) cb = noop\n\n  // TODO: re-enable put cache. currently this causes a memleak\n  // because node.hash is a slice of the big data buffer on replicate\n  // if (this.cache) this.cache.set(index, node)\n\n  var buf = Buffer.allocUnsafe(40)\n\n  node.hash.copy(buf, 0)\n  uint64be.encode(node.size, buf, 32)\n  this.tree.write(32 + 40 * index, buf, cb)\n}\n\nStorage.prototype.putBitfield = function (offset, data, cb) {\n  this.bitfield.write(32 + offset, data, cb)\n}\n\nStorage.prototype.close = function (cb) {\n  if (!cb) cb = noop\n  var missing = 6\n  var error = null\n\n  close(this.bitfield, done)\n  close(this.tree, done)\n  close(this.data, done)\n  close(this.key, done)\n  close(this.secretKey, done)\n  close(this.signatures, done)\n\n  function done (err) {\n    if (err) error = err\n    if (--missing) return\n    cb(error)\n  }\n}\n\nStorage.prototype.destroy = function (cb) {\n  if (!cb) cb = noop\n  var missing = 6\n  var error = null\n\n  destroy(this.bitfield, done)\n  destroy(this.tree, done)\n  destroy(this.data, done)\n  destroy(this.key, done)\n  destroy(this.secretKey, done)\n  destroy(this.signatures, done)\n\n  function done (err) {\n    if (err) error = err\n    if (--missing) return\n    cb(error)\n  }\n}\n\nStorage.prototype.openKey = function (opts, cb) {\n  if (typeof opts === 'function') return this.openKey({}, opts)\n  if (!this.key) this.key = this.create('key', opts)\n  this.key.read(0, 32, cb)\n}\n\nStorage.prototype.open = function (opts, cb) {\n  if (typeof opts === 'function') return this.open({}, opts)\n\n  var self = this\n  var error = null\n  var missing = 5\n\n  if (!this.key) this.key = this.create('key', opts)\n  if (!this.secretKey) this.secretKey = this.create('secret_key', opts)\n  if (!this.tree) this.tree = this.create('tree', opts)\n  if (!this.data) this.data = this.create('data', opts)\n  if (!this.bitfield) this.bitfield = this.create('bitfield', opts)\n  if (!this.signatures) this.signatures = this.create('signatures', opts)\n\n  var result = {\n    bitfield: [],\n    bitfieldPageSize: 3584, // we upgraded the page size to fix a bug\n    secretKey: null,\n    key: null\n  }\n\n  this.bitfield.read(0, 32, function (err, h) {\n    if (err && err.code === 'ELOCKED') return cb(err)\n    if (h) result.bitfieldPageSize = h.readUInt16BE(5)\n    self.bitfield.write(0, header(0, result.bitfieldPageSize, null), function (err) {\n      if (err) return cb(err)\n      readAll(self.bitfield, 32, result.bitfieldPageSize, function (err, pages) {\n        if (pages) result.bitfield = pages\n        done(err)\n      })\n    })\n  })\n\n  this.signatures.write(0, header(1, 64, 'Ed25519'), done)\n  this.tree.write(0, header(2, 40, 'BLAKE2b'), done)\n\n  // TODO: Improve the error handling here.\n  // I.e. if secretKey length === 64 and it fails, error\n\n  this.secretKey.read(0, 64, function (_, data) {\n    if (data) result.secretKey = data\n    done(null)\n  })\n\n  this.key.read(0, 32, function (_, data) {\n    if (data) result.key = data\n    done(null)\n  })\n\n  function done (err) {\n    if (err) error = err\n    if (--missing) return\n    if (error) cb(error)\n    else cb(null, result)\n  }\n}\n\nStorage.Node = Node\n\nfunction noop () {}\n\nfunction copyMaybe (buf, maxSize) {\n  if (buf.buffer.byteLength <= maxSize) return buf\n  const cpy = Buffer.alloc(buf.byteLength)\n  buf.copy(cpy)\n  return cpy\n}\n\nfunction header (type, size, name) {\n  var buf = Buffer.alloc(32)\n\n  // magic number\n  buf[0] = 5\n  buf[1] = 2\n  buf[2] = 87\n  buf[3] = type\n\n  // version\n  buf[4] = 0\n\n  // block size\n  buf.writeUInt16BE(size, 5)\n\n  if (name) {\n    // algo name\n    buf[7] = name.length\n    buf.write(name, 8)\n  }\n\n  return buf\n}\n\nfunction Node (index, hash, size) {\n  this.index = index\n  this.hash = hash\n  this.size = size\n}\n\nfunction findNode (nodes, index) {\n  for (var i = 0; i < nodes.length; i++) {\n    if (nodes[i].index === index) return nodes[i]\n  }\n  return null\n}\n\nfunction isBlank (buf) {\n  for (var i = 0; i < buf.length; i++) {\n    if (buf[i]) return false\n  }\n  return true\n}\n\nfunction close (st, cb) {\n  if (st.close) st.close(cb)\n  else cb()\n}\n\nfunction destroy (st, cb) {\n  if (st.destroy) st.destroy(cb)\n  else cb()\n}\n\nfunction statAndReadAll (st, offset, pageSize, cb) {\n  st.stat(function (err, stat) {\n    if (err) return cb(null, [])\n\n    var result = []\n\n    loop(null, null)\n\n    function loop (err, batch) {\n      if (err) return cb(err)\n\n      if (batch) {\n        offset += batch.length\n        for (var i = 0; i < batch.length; i += pageSize) {\n          result.push(batch.slice(i, i + pageSize))\n        }\n      }\n\n      var next = Math.min(stat.size - offset, 32 * pageSize)\n      if (!next) return cb(null, result)\n\n      st.read(offset, next, loop)\n    }\n  })\n}\n\nfunction readAll (st, offset, pageSize, cb) {\n  if (st.statable === true) return statAndReadAll(st, offset, pageSize, cb)\n\n  var bufs = []\n\n  st.read(offset, pageSize, loop)\n\n  function loop (err, buf) {\n    if (err) return cb(null, bufs)\n    bufs.push(buf)\n    st.read(offset + bufs.length * pageSize, pageSize, loop)\n  }\n}\n\nexport default storage;\nexport { storage as __moduleExports };","start":1670465470886,"end":1670465470899,"order":"normal"}]}
